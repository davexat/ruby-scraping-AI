Title,Link,Content
John Carreyrou and other authors bring new lawsuit against six major AI companies,https://techcrunch.com/2025/12/23/john-carreyrou-and-other-authors-bring-new-lawsuit-against-six-major-ai-companies/,"A group of writers, including Theranos whistleblower and “Bad Blood” author John Carreyrou, is filing a lawsuit against Anthropic, Google, OpenAI, Meta, xAI, and Perplexity, accusing the companies of training their models on pirated copies of their books. If this sounds familiar, it’s because another set of authors already filed a class action suit against Anthropic for these same acts of copyright infringement. In that case, the judge ruled that it was legal for Anthropic and similar AI companies to train on pirated copies of books, but that it was not legal to pirate the books in the first place. While eligible writers can receive about $3,000 from the $1.5 billion Anthropic settlement, some authors were dissatisfied with that resolution — it doesn’t hold AI companies accountable for the actual act of using stolen books to train their models, which generate billions of dollars in revenue. According to the new lawsuit, the plaintiffs say that the proposed Anthropic settlement “seems to serve [the AI companies], not creators.” “LLM companies should not be able to so easily extinguish thousands upon thousands of high-value claims at bargain-basement rates, eliding what should be the true cost of their massive willful infringement,” the lawsuit says. "
Marissa Mayer’s new startup Dazzle raises $8M led by Forerunner’s Kirsten Green,https://techcrunch.com/2025/12/23/marissa-mayers-new-startup-dazzle-raises-8m-led-by-forerunners-kirsten-green/,"The former Yahoo CEO, Marissa Mayer, refuses to sit on the sidelines of the generative AI revolution. After spending the last six years running Sunshine, a photo-sharing and contact-management startup with little success, the storied tech leader has shuttered the company to launch Dazzle, a new startup focused on building the next generation of AI personal assistants. While Mayer is not yet sharing specifics about Dazzle’s functionality, she has revealed that the new company has raised an $8 million seed round at a $35 million valuation. The round was led by Forerunner’s Kirsten Green, with participation from Kleiner Perkins, Greycroft, Offline Ventures, Slow Ventures, and Bling Capital. Although Mayer has admitted to investing her own capital in the startup, she emphasized that the round was led by Green, a venture capitalist with a storied record of identifying iconic consumer brands such as Warby Parker, Chime, and Dollar Shave Club. Green’s investment suggests Dazzle is poised for the coming wave of new AI-infused consumer businesses. The founder of Forerunner Ventures previously told TechCrunch that while enterprise AI took the early lead in this tech cycle, consumer-facing AI is a “late bloomer” that’s finally ready for its breakout. Even for a founder of Mayer’s fame, landing Green as a lead investor is a significant stamp of credibility for Dazzle, especially after Sunshine was widely considered to be a flop. “I think she really has a great sense for where people and platforms are going,” Mayer said.   Mayer told TechCrunch that the Sunshine team began prototyping Dazzle last summer, a project that quickly eclipsed their previous work in ambition and opportunity. “We realized that this was something that we were much more excited about,” she said, noting that Dazzle has potential for “a much bigger impact” than what Sunshine was building. Originally founded as Lumi Labs in 2018, Sunshine first launched with a subscription app for contact management dubbed “Sunshine Contacts.” Despite its founder’s high profile, the product struggled to gain traction. Privacy advocates raised alarms over the app’s practice of pulling home addresses from public databases to enrich contact lists, and the company never recovered from the initial skepticism. By 2024, the company broadened its offering by adding event management and “Shine,” an AI-powered photo-sharing tool. The new offering was widely criticized for its outdated design and similarly failed to attract widespread usage. Sunshine raised a total of $20 million from investors, including Felicis, Norwest Venture Partners, and Unusual Ventures. When the company was dissolved, investors received 10% of Dazzle’s equity, Mayer said. Reflecting on Sunshine’s struggle, Mayer was candid about its limitations, admitting the problems the company was tackling were too “mundane” and not large enough. “I don’t think we got it to the state of overall polish and accessibility that I really wanted it to be,” she added. Mayer is now betting that the lessons from Sunshine will help her build a much more resilient and impactful business with Dazzle. Before her tenure as Yahoo CEO, Mayer was employee number 20 at Google, where she helped design Google search ‘look and feel’, and oversaw the development of Google Maps and AdWords. “I have had the rare privilege of being at two companies that really changed how people do things,” Mayer told TechCrunch. “Yahoo, for many, defined the internet. Google, in terms of Search and Maps, changed everything. I really aspire to build a product that has that kind of impact again.” Dazzle is expected to come out of stealth mode early next year."
"Amazon’s AI assistant Alexa+ now works with Angi, Expedia, Square, and Yelp",https://techcrunch.com/2025/12/23/amazons-ai-assistant-alexa-now-works-with-angi-expedia-square-and-yelp/,"Amazon is expanding its AI-powered digital assistant Alexa+ with new capabilities. The company announced on Thursday that it’s adding four new integrations to the service that will allow the assistant to work with Angi, Expedia, Square, and Yelp starting in 2026. These additions allow customers to book hotels, get quotes for home services, and schedule salon appointments, among other things. With Expedia, customers can compare, book, and manage hotel reservations, or tell Alexa their preferences to get personalized recommendations. (e.g. “Can you find me pet-friendly hotels for this weekend in Chicago?”) The new services join Alexa+’s existing integrations with Fodor, OpenTable, Suno, Ticketmaster, Thumbtack, and Uber. Similar to how ChatGPT is now integrating apps into its chatbot, Amazon aims to make it easier for consumers to use various online services through its digital assistant. For instance, you could ask Alexa to call you an Uber or book a table for dinner with OpenTable. You also can converse with the AI assistant in natural language, having back-and-forth conversations, refining your request as you go. Whether users will take to this idea, of course, remains to be seen. However, Amazon did offer a small glimpse as to how Alexa+ early adopters have been using the integrations, noting that, so far, home and personal service providers like Thumbtack and Vagaro have seen “strong” engagement. Using AI assistants as app platforms is a model that’s being tested across the industry as another way to bring AI to consumers more broadly. But this will require users to adapt to a new way of doing things, as many are used to engaging with online services through the web or mobile apps. To be successful in getting consumers to change their behavior, using apps via AI will need to be seen as being as easy, if not easier, than the existing model. For that to work, the AI providers would need to at least match the breadth of online services provided by a traditional app store, which is already a more curated selection than what’s available via the web. Or, providers will need to get very good at suggesting apps to use at the right time, without seeming overly pushy, as users can perceive unwelcome prompts as ads."
Lemon Slice nabs $10.5M from YC and Matrix to build out its digital avatar tech,https://techcrunch.com/2025/12/23/lemon-slice-nabs-10-5m-from-yc-and-matrix-to-build-out-its-digital-avatar-tech/,"Developers and companies are increasingly deploying AI agents and chatbots within their apps, but so far they’ve mostly been restricted to text. Digital avatar generation company Lemon Slice is working to add a video layer to those chats with a new diffusion model that can create digital avatars from a single image. Called Lemon Slice-2, the model can create a digital avatar that works on top of a knowledge base to play any role required of the AI agent, like addressing customer queries, helping with homework questions, or even working as a mental health support agent. “In the early days of GenAI, my co-founders started to play around with different video models, and it became obvious to us that video was going to be interactive. The compelling part about tools like ChatGPT was that they were interactive, and we want video to have that layer,” co-founder Lina Colucci said. Lemon Slice says this is a 20-billion-parameter model that can work on a single GPU to livestream videos at 20 frames per second. The company is making the model available through an API and an embeddable widget that companies can integrate into their sites with a single line of code. After an avatar is created, you can change the background, styling, and appearance of a character at any point. Besides human-like avatars, the company is also focusing on being able to generate non-human characters to suit different needs. The startup is using ElevenLabs’ tech to generate the voices of these avatars. Founded by Lina Colucci, Sidney Primas, and Andrew Weitz in 2024, Lemon Slice is betting that using its own general-purpose diffusion model (a type of generative model that learns to work backwards from noisy training data to generate new data) for making avatars will set it apart from competitors. “The existing avatar solutions I’ve seen to date add negative value to the product,” Colucci said. “They are creepy, and they are stiff. They look good for a few seconds, and as soon as you start interacting with them, it feels very uncanny, and it doesn’t put you at ease. The thing that has prevented avatars from really taking off is that they haven’t been good enough.” To fund that effort, the company on Tuesday said it has raised $10.5 million in seed funding from Matrix Partners, Y Combinator, Dropbox CTO Arash Ferdowsi, Twitch CEO Emmett Shear, and The Chainsmokers. The company says it has guardrails in place to prevent unauthorized face or voice cloning, and that it uses large language models for content moderation. Lemon Slice would not name the organizations using its technology, but said the model is being put to work for use cases like education, language learning, e-commerce, and corporate training. The startup faces stiff competition from video generation startups like D-ID, HeyGen, and Synthesia, as well as other digital avatar makers Genies, Soul Machine, Praktika, and AvatarOS. Ilya Sukhar, a partner at Matrix, thinks that avatars will be useful in areas where videos are prominent. For instance, people like learning from YouTube rather than reading long blocks of text. He noted that Lemon Slice’s technical prowess and its own will give it an edge over other startups. “It’s a deeply technical team with a track record of shipping ML products, not just demos and research. Many of the other players are bespoke to particular scenarios or verticals, and Lemon Slice is taking the generalized “bitter lesson” scaling approach (of data and compute) that has worked in other AI modalities,” he said. Y Combinator’s Jared Friedman believes that using a diffusion-style model allows Lemon Slice to generate any kind of avatars as compared to some other startups that are focused on either human-like or game character-like avatars. “Lemon Slice is, I believe, the only company taking the fundamental ML approach that can eventually overcome the uncanny valley and break the avatar Turing test. They train the same type of model as Veo3 or Sora: a video diffusion transformer. Because it is a general-purpose model that does the whole thing end-to-end, it has no ceiling on how good it can get; the others top out below photorealistic. It also works for both human and non-human faces and requires only an image to add a new face,” he said. The startup currently has eight employees, and plans to use the funds to hire engineering and go-to-market staff, along with paying the compute bills to train its models."
OpenAI says AI browsers may always be vulnerable to prompt injection attacks,https://techcrunch.com/2025/12/22/openai-says-ai-browsers-may-always-be-vulnerable-to-prompt-injection-attacks/,"Even as OpenAI works to harden its Atlas AI browser against cyberattacks, the company admits that prompt injections, a type of attack that manipulates AI agents to follow malicious instructions often hidden in web pages or emails, is a risk that’s not going away anytime soon — raising questions about how safely AI agents can operate on the open web.  “Prompt injection, much like scams and social engineering on the web, is unlikely to ever be fully ‘solved,’” OpenAI wrote in a Monday blog post detailing how the firm is beefing up Atlas’ armor to combat the unceasing attacks. The company conceded that “agent mode” in ChatGPT Atlas “expands the security threat surface.” OpenAI launched its ChatGPT Atlas browser in October, and security researchers rushed to publish their demos, showing it was possible to write a few words in Google Docs that were capable of changing the underlying browser’s behavior. That same day, Brave published a blog post explaining that indirect prompt injection is a systematic challenge for AI-powered browsers, including Perplexity’s Comet.  OpenAI isn’t alone in recognizing that prompt-based injections aren’t going away. The U.K.’s National Cyber Security Centre earlier this month warned that prompt injection attacks against generative AI applications “may never be totally mitigated,” putting websites at risk of falling victim to data breaches. The U.K. government agency advised cyber professionals to reduce the risk and impact of prompt injections, rather than think the attacks can be “stopped.”  For OpenAI’s part, the company said: “We view prompt injection as a long-term AI security challenge, and we’ll need to continuously strengthen our defenses against it.” The company’s answer to this Sisyphean task? A proactive, rapid-response cycle that the firm says is showing early promise in helping discover novel attack strategies internally before they are exploited “in the wild.”  That’s not entirely different from what rivals like Anthropic and Google have been saying: that to fight against the persistent risk of prompt-based attacks, defenses must be layered and continuously stress-tested. Google’s recent work, for example, focuses on architectural and policy-level controls for agentic systems. But where OpenAI is taking a different tact is with its “LLM-based automated attacker.” This attacker is basically a bot that OpenAI trained, using reinforcement learning, to play the role of a hacker that looks for ways to sneak malicious instructions to an AI agent. The bot can test the attack in simulation before using it for real, and the simulator shows how the target AI would think and what actions it would take if it saw the attack. The bot can then study that response, tweak the attack, and try again and again. That insight into the target AI’s internal reasoning is something outsiders don’t have access to, so, in theory, OpenAI’s bot should be able to find flaws faster than a real-world attacker would.  It’s a common tactic in AI safety testing: build an agent to find the edge cases and test against them rapidly in simulation.  “Our [reinforcement learning]-trained attacker can steer an agent into executing sophisticated, long-horizon harmful workflows that unfold over tens (or even hundreds) of steps,” wrote OpenAI. “We also observed novel attack strategies that did not appear in our human red teaming campaign or external reports.” In a demo (pictured in part above), OpenAI showed how its automated attacker slipped a malicious email into a user’s inbox. When the AI agent later scanned the inbox, it followed the hidden instructions in the email and sent a resignation message instead of drafting an out-of-office reply. But following the security update, “agent mode” was able to successfully detect the prompt injection attempt and flag it to the user, according to the company.  The company says that while prompt injection is hard to secure against in a foolproof way, it’s leaning on large-scale testing and faster patch cycles to harden its systems before they show up in real-world attacks.  An OpenAI spokesperson declined to share whether the update to Atlas’ security has resulted in a measurable reduction in successful injections, but says the firm has been working with third parties to harden Atlas against prompt injection since before launch. Rami McCarthy, principal security researcher at cybersecurity firm Wiz, says that reinforcement learning is one way to continuously adapt to attacker behavior, but it’s only part of the picture.  “A useful way to reason about risk in AI systems is autonomy multiplied by access,” McCarthy told TechCrunch. “Agentic browsers tend to sit in a challenging part of that space: moderate autonomy combined with very high access,” said McCarthy. “Many current recommendations reflect that trade-off. Limiting logged-in access primarily reduces exposure, while requiring review of confirmation requests constrains autonomy.” Those are two of OpenAI’s recommendations for users to reduce their own risk, and a spokesperson said Atlas is also trained to get user confirmation before sending messages or making payments. OpenAI also suggests that users give agents specific instructions, rather than providing them access to your inbox and telling them to “take whatever action is needed.”  “Wide latitude makes it easier for hidden or malicious content to influence the agent, even when safeguards are in place,” per OpenAI. While OpenAI says protecting Atlas users against prompt injections is a top priority, McCarthy invites some skepticism as to the return on investment for risk-prone browsers.  “For most everyday use cases, agentic browsers don’t yet deliver enough value to justify their current risk profile,” McCarthy told TechCrunch. “The risk is high given their access to sensitive data like email and payment information, even though that access is also what makes them powerful. That balance will evolve, but today the trade-offs are still very real.”"
Alphabet to buy Intersect Power to bypass energy grid bottlenecks,https://techcrunch.com/2025/12/22/alphabet-to-buy-intersect-power-to-bypass-energy-grid-bottlenecks/,"Google parent Alphabet has agreed to buy Intersect Power, a data center and clean energy developer, for $4.75 billion in cash, plus the assumption of the company’s debt. The acquisition, which was announced Monday, will help Alphabet expand its power-generation capacity alongside new data centers without having to rely on local utilities that are struggling to keep up with the demand of AI companies. Securing access to energy that powers data centers has become a critical part of training AI models. Alphabet previously held a minority stake in Intersect Power after Google and TPG Rise Climate led an $800 million strategic funding round in the company last December. That partnership set a target of $20 billion in total investment by 2030. The acquisition includes Intersect’s future development projects but excludes its existing operation, which will be bought out by other investors and managed as a separate company. Intersect’s new data parks, which are essentially locations next to wind, solar, and battery power, are expected to be operational late next year and fully completed by 2027, Google said when it announced its minority investment. The transaction is expected to close in the first half of next year. Google will be the primary user. However, Intersect’s campuses are designed as industrial parks that can host other companies’ AI chips alongside Google’s. "
ChatGPT launches a year-end review like Spotify Wrapped,https://techcrunch.com/2025/12/22/chatgpt-launches-a-year-end-review-like-spotify-wrapped/,"ChatGPT is releasing its own version of Spotify Wrapped. That is, the OpenAI-owned chatbot is now rolling out an annual review feature called “Your Year with ChatGPT” to eligible consumers in select markets, including the United States. Other English-speaking markets with access to the new offering include Canada, the U.K., Australia, and New Zealand. At launch, the feature will be offered to those with the free, Plus, and Pro plans who have the “reference saved memories” and “reference chat history” options turned on and have met a minimum conversation activity threshold, the company told TechCrunch via email. Team, Enterprise, or Education accounts will not be able to use the “Your Year with ChatGPT” feature. In addition, the experience is meant to be “lightweight, privacy-forward, and user-controlled,” the company noted. Similar to other annual reviews offered by consumer apps, “Your Year with ChatGPT” takes inspiration from the popular year-end look back, Spotify Wrapped. Like Spotify’s feature, OpenAI uses catchy graphics and personalizes the experience to the individual by giving out “awards” based on how you’ve used ChatGPT throughout the year. For instance, you might be awarded with the “Creative Debugger” if you used the chatbot to come up with solutions to a problem or worked through a concept or idea. The app also creates a poem and an image about your year focused on your topics of interest. (We’re wondering how this will look next year as ChatGPT embraces adult content in 2026.) While the year-end wrap-up will be promoted on the ChatGPT app’s home screen, it won’t be forced on users or opened automatically. It will be available on the ChatGPT web app and mobile app for iOS and Android, the company says. You also can ask ChatGPT directly for “Your Year with ChatGPT” to trigger the experience. "
Splat’s app uses AI to turn your photos into coloring pages for kids,https://techcrunch.com/2025/12/22/splats-app-uses-ai-to-turn-your-photos-into-coloring-pages-for-kids/,"The team at Retro, a photo-sharing app for close friends and family, is experimenting with how generative AI can be put to more creative uses. To try out the latest, cutting-edge AI technologies, the team built a new app called Splat, which lets you turn any photo into a coloring book page for kids. As any parent will tell you, kids love to color. And thanks to the web, there’s a seemingly infinite number of coloring book pages available for printing at home. However, many of the websites hosting these pages are filled with ads and other clutter, making them difficult to navigate. Other times, the printable pages are only available for a small fee, which some parents don’t want to pay, given the disposable nature of much of kids’ scribbled-on art projects. That inspired Retro’s team to develop an app for printing coloring book pages at home — from either your own photos or those it provides in kid-friendly, educational categories, such as animals, space, flowers, fairy tales, robots, cars, and more. To get started with Splat, you’ll take a picture or pick a photo from your Camera Roll. You can then choose what style of photo you’d like to color — such as anime, 3D movie, manga, cartoon, or comic. The app will then transform your picture using AI into either an on-screen or printable page for kids to color. Instead of requiring a tedious sign-up process, the app will step you through customization options the first time you begin creating. Here, you’re prompted to choose your preferred app icon and check off the various categories your child likes. You also can choose if you want to let kids color the photo as a printable page or on-screen (great in a pinch when kids are bored, but you don’t want them sucked into a TV show or game). You can try one generative AI project to get a feel for the app. It then costs either $4.99 per week or $49.99 per year to continue to generate new pictures. The weekly option allows for 25 pages per week, and the annual option provides 500 pages per year. The option to purchase or access the settings is blocked from small children by a pop-up that requires the parent’s birth year. In brief tests, the app worked as promised, and the generation time was brief, allowing you to quickly move from idea to printed art, ready for coloring, cutouts, or anything else your child wants to do. Splat is one of several experiments that uses generative AI to help inspire kids’ creativity and imagination in new ways. Another, Stickerbox, offers printed AI-generated stickers for coloring, while Casio also launched a fluffy robotic pet called Moflin that uses AI to develop its personality over time. Splat is available on iOS and Android."
ChatGPT: Everything you need to know about the AI-powered chatbot,https://techcrunch.com/2025/12/22/chatgpt-everything-to-know-about-the-ai-chatbot/,"ChatGPT, OpenAI’s text-generating AI chatbot, has taken the world by storm since its launch in November 2022. What started as a tool to supercharge productivity through writing essays and code with short text prompts has evolved into a behemoth with 300 million weekly active users. In 2025, OpenAI has battled the perception that it was ceding ground in the AI race to Chinese rivals like DeepSeek, all while the company has tried to shore up its relationship with Washington, pursued ambitious data center projects, and laid the groundwork for one of the largest funding rounds in history. Most recently though, headlines around OpenAI have focused on its competition gaining ground, with CEO Sam Altman’s “code red” internal memo shifting company focus toward its flagship chatbot. And going further into the archives for context, this year came after a packed 2024, from OpenAI’s partnership with Apple for its generative AI offering, Apple Intelligence, the release of GPT-4o with voice capabilities, and the highly-anticipated launch of its text-to-video model Sora. OpenAI also faced its share of internal drama, including the notable exits of high-level execs like co-founder and longtime chief scientist Ilya Sutskever and CTO Mira Murati. OpenAI has also been hit with lawsuits from Alden Global Capital-owned newspapers alleging copyright infringement, as well as an injunction from Elon Musk to halt OpenAI’s transition to a for-profit. Below, you’ll find a timeline of ChatGPT product updates and releases, starting with the latest, which we’ve been updating throughout the year. If you have any other questions, check out our ChatGPT FAQ here. To see a list of 2024-specific updates, go here.  OpenAI has added new controls in ChatGPT that let users adjust the chatbot’s warmth, enthusiasm, emoji use, and formatting style. This builds on existing tone options, addressing past complaints about the AI being too sycophantic or cold. OpenAI has updated its guidelines for users under 18 and released new resources for parents to promote safer interactions with ChatGPT. Experts caution that while the rules are clearer on paper, it’s unclear how consistently the AI follows them in practice. ChatGPT has surpassed $3 billion in global consumer spending on mobile since its 2023 launch. This makes it one of the fastest-growing apps in terms of revenue, outpacing rivals like TikTok, Disney+, and HBO Max. OpenAI has released GPT Image 1.5, a new version of ChatGPT Images that’s faster and better at following instructions and making precise edits. The update comes as OpenAI races to keep up with Google’s Gemini and Nano Banana Pro in AI image generation. Disney is putting $1 billion into OpenAI as a way to dive into AI, letting users on Sora create videos using over 200 Disney characters, at least for the first year exclusively. Bob Iger says the deal gives Disney a chance to explore AI while protecting its characters and figuring out how to use this technology in the future. OpenAI says enterprise use of its AI tools has surged, with ChatGPT message volume up 8x since late 2024 and workers saving up to an hour a day. The data underscores OpenAI’s push to win enterprise customers as competition heats up from Google, Anthropic, and open-model rivals, a recurring theme you’ll see in recent updates. OpenAI rolled out its latest model, GPT-5.2, as competition with Google continued to heat up. The model will roll out to paid ChatGPT users and developers in three versions — Instant, Thinking, and Pro — tailored for everything from everyday tasks to complex reasoning and high-accuracy work. Disney has signed a three-year deal with OpenAI, investing $1 billion and bringing characters from Disney, Marvel, Pixar, and Star Wars to OpenAI’s Sora video generator. The partnership will let users create AI videos using hundreds of Disney-owned characters, costumes, and props. On the same day, Disney notably launched a lawsuit against Google alleging “massive” copyright infringement occurring in its AI models. OpenAI CEO Sam Altman has put OpenAI on “code red,” telling staff the company will prioritize improving ChatGPT as pressure mounts from Google and other AI competitors, according to The Information. As part of the move, OpenAI plans to put some other initiatives, including advertising, on the back burner. OpenAI launched a new AI shopping feature in ChatGPT ahead of the peak holiday shopping window to help users research potential purchases. OpenAI’s new ChatGPT shopping feature lets users get product recommendations by describing features or sharing photos to find similar items at different prices. And they’re not alone, with both Perplexity and a slew of competitor startups playing in the commerce space. After Adam Raine’s family sued OpenAI in August, claiming their teen used ChatGPT as a “suicide coach,” OpenAI said in a new court filing that it isn’t liable, arguing the chatbot was misused. This marks OpenAI’s first response to a case that has raised wider concerns about chatbots and mental health risks. OpenAI is bringing ChatGPT’s voice mode straight into the main chat, so you no longer have to jump to a separate screen. Now you can talk to ChatGPT and see everything it says and shows right in the same window. OpenAI can’t use “cameo” for Sora features for now, following a trademark lawsuit from the video app Cameo, with the ban lasting until December 22. ChatGPT is now getting group chats for everyone — Free, Go, Plus, and Pro users alike — after testing it in a few regions last week. You can now team up with friends, family, or co-workers in one chat with ChatGPT to plan, create, or make decisions together. OpenAI has released GPT‑5.1, upgrading the GPT‑5 series with two models: Instant, which it says will be warmer and more conversational with users, and Thinking, which offers faster, simple-task handling and more persistent complex reasoning. The update also introduces improved controls for customizing ChatGPT’s tone to better match user preferences. A Munich court ruled that ChatGPT violated German copyright law by reproducing lyrics from nine protected songs, including Herbert Grönemeyer’s hits, rejecting OpenAI’s argument that the AI only reflected learned patterns. The decision could set a European precedent on AI use of copyrighted material, amid growing global legal challenges over AI and music rights. OpenAI is exploring the consumer health sector, developing AI tools like personal health assistants and data aggregators, according to a report by Business Insider. With new healthcare-focused hires, it aims to simplify access to fragmented medical data — an area where Big Tech has struggled — through its conversational AI approach. In November 2025, seven families sued OpenAI, alleging that GPT-4o was released prematurely without safeguards, contributing to suicides and severe psychiatric harm. One case involved 23-year-old Zane Shamblin, who told ChatGPT of his suicide plans, and the AI encouraged him. The lawsuits focus on GPT-4o’s tendency to be overly agreeable, despite users expressing dangerous intentions. On November 5, OpenAI announced that over 1 million businesses globally now use its products, making it the fastest-growing business platform in history. Companies across industries like finance, healthcare, and retail, including Amgen, Booking.com, Cisco, Morgan Stanley, T-Mobile, Target, and Thermo Fisher Scientific, are using ChatGPT and OpenAI’s developer tools to enhance operations and customer experiences. OpenAI revealed that a small but significant portion of ChatGPT users, more than a million weekly, discuss mental health struggles, including suicidal thoughts, psychosis, or mania, with the AI. The company says it has improved ChatGPT’s responses by consulting more than 170 mental health experts to handle such conversations more appropriately than earlier versions. OpenAI is developing a new tool that generates music from text and audio prompts, potentially for enhancing videos or adding instrumentation, and is training it using annotated scores from Juilliard students, according to The Information. The launch date and whether it will be standalone or integrated with ChatGPT and Sora remain unclear. OpenAI’s new “company knowledge” update for ChatGPT lets Business, Enterprise, and Education users search workplace data across tools like Slack, Google Drive, and GitHub using GPT‑5, per a report by The Verge. The feature acts as a conversational search engine, providing more comprehensive and accurate answers by scouring multiple sources simultaneously. OpenAI has launched its AI browser, ChatGPT Atlas, starting on Mac, letting users get answers from ChatGPT instead of traditional search results. Unlike other AI browsers, Atlas is open to all users and will soon come to Windows, iOS, and Android, as OpenAI aims to make ChatGPT the go-to tool for browsing the web. A new Apptopia analysis suggests ChatGPT’s mobile app growth may be leveling off, with global download growth slowing since April. While daily installs remain in the millions, October is tracking an 8.1% month-over-month decline in new downloads. OpenAI is partnering with Walmart to allow users to browse products, plan meals, and make purchases through ChatGPT, with support for third-party sellers expected later this fall. The partnership is part of OpenAI’s broader effort to develop AI-driven e-commerce tools, including collaborations with Etsy and Shopify. OpenAI is expanding its affordable ChatGPT Go plan, priced under $5, to 16 new countries across Asia, including Afghanistan, Bangladesh, Bhutan, Brunei Darussalam, Cambodia, Laos, Malaysia, Maldives, Thailand, Vietnam, and Pakistan. In some of these countries, users can pay in local currencies, while in others, payments are required in USD, with final costs varying due to local taxes. ChatGPT now has 800 million weekly active users, reflecting rapid growth across consumers, developers, enterprises, and governments, Sam Altman said. This milestone comes as OpenAI accelerates efforts to expand its AI infrastructure and secure more chips to support rising demand. OpenAI now allows developers to build interactive apps directly inside ChatGPT, with early partners like Booking.com, Expedia, Spotify, Figma, Coursera, Zillow, and Canva already onboard. The ChatGPT maker is also rolling out a preview of its Apps SDK, a developer toolkit for creating these chat-based experiences. OpenAI is reportedly adding parental controls to ChatGPT on web and mobile, letting parents and teens link accounts to enable safeguards like limiting sensitive content, setting quiet hours, and disabling features such as voice mode or image generation. The move comes amid growing regulatory scrutiny and a lawsuit over the chatbot’s alleged role in a teen’s suicide. OpenAI unveiled Pulse, a new ChatGPT feature that delivers personalized morning briefings overnight, encouraging users to start their day with the app. The tool reflects a shift toward making ChatGPT more proactive and asynchronous, positioning it as a true assistant rather than just a chatbot. OpenAI’s new Applications CEO, Fidji Simo, called Pulse the first step toward bringing high-level personal support to everyone, starting with Pro users. OpenAI launched Instant Checkout in ChatGPT, letting U.S. users purchase products directly from Etsy and, soon, over a million Shopify merchants without leaving the conversation. Shoppers can browse items, read reviews, and complete purchases with a single tap using Apple Pay, Google Pay, Stripe, or a credit card. The update marks a step toward reshaping online shopping by merging product discovery, recommendations, and payments in one place. OpenAI rolled out its budget-friendly ChatGPT Go plan in Indonesia for Rp 75,000 ($4.50) per month, following its initial launch in India. The mid-tier plan, which offers higher usage limits, image generation, file uploads, and better memory compared to the free version, enters the market in direct competition with Google’s new AI Plus plan in Indonesia. CEO Sam Altman announced new policies for under-18 users of ChatGPT, tightening safeguards around sensitive conversations. The company says it will block flirtatious exchanges with minors and add stronger protections around discussions of suicide, even escalating severe cases to parents or authorities. The move comes as OpenAI faces a wrongful death lawsuit tied to alleged chatbot interactions, underscoring rising concerns about the mental health risks of AI companions. OpenAI rolled out GPT-5-Codex, a new version of its AI coding agent that can spend anywhere from a few seconds to seven hours tackling a task, depending on complexity. The company says this dynamic approach helps the model outperform GPT-5 on key coding benchmarks, including bug fixes and large-scale refactoring. The update comes as OpenAI looks to keep Codex competitive in a fast-growing market that now includes rivals like Claude Code, Cursor, and GitHub Copilot. OpenAI is shaking up its Model Behavior team, the small but influential group that helps shape how its AI interacts with people. The roughly 14-person team is being folded into the larger Post Training group, now reporting to lead researcher Max Schwarzer. Meanwhile, founding leader Joanne Jang is spinning up a new unit called OAI Labs, focused on prototyping fresh ways for people to collaborate with AI. OpenAI, facing a lawsuit from the parents of a 16-year-old who died by suicide, said in its blog that it has implemented new safeguards for ChatGPT, including stronger detection of mental health risks and parental control features. The AI company said the updates aim to provide tighter protections around suicide-related conversations and give parents more oversight of their children’s use. Elon Musk’s AI startup, xAI, filed a federal lawsuit in Texas against Apple and OpenAI, alleging that the two companies colluded to lock up key markets and shut out rivals. OpenAI introduced its most affordable subscription plan, ChatGPT Go, in India, priced at 399 rupees per month (approximately $4.57). This move aims to expand OpenAI’s presence in its second-largest market, offering enhanced access to the latest GPT-5 model and additional features. Since its May 2023 launch, ChatGPT’s mobile app has amassed $2 billion in global consumer spending, dwarfing competitors like Claude, Copilot, and Grok by roughly 30 times, according to Appfigures. This year alone, the app has generated $1.35 billion, a 673% increase from the same period in 2024, averaging nearly $193 million per month, or 53 times more than its nearest rival, Grok. Despite unveiling GPT-5 as a “one-size-fits-all” AI, OpenAI is still offering several legacy AI options, including GPT-4o, GPT-4.1, and o3. Users can choose between new “Auto,” “Fast,” and “Thinking” modes for GPT-5, and paid subscribers regain access to legacy models like GPT-4o and GPT-4.1. Updates to ChatGPT:You can now choose between “Auto”, “Fast”, and “Thinking” for GPT-5. Most users will want Auto, but the additional control will be useful for some people.Rate limits are now 3,000 messages/week with GPT-5 Thinking, and then extra capacity on GPT-5 Thinking… OpenAI CEO Sam Altman told Reddit users that GPT-5’s “dumber” behavior at launch was due to a router issue and promised fixes, double rate limits for Plus users, and transparency on which model is answering, while also shrugging off the infamous “chart crime” from the live presentation. OpenAI released GPT-5, a next-gen AI that’s not just smarter but more useful — able to handle tasks like coding apps, managing calendars, and creating research briefs — while automatically figuring out the fastest or most thoughtful way to answer your questions. OpenAI is making a major push into federal government workflows, offering ChatGPT Enterprise to agencies for just $1 for the next year. The move comes after the U.S. General Services Administration (GSA) added OpenAI, Google, and Anthropic to its approved AI vendor list, allowing agencies to access these tools through preset contracts without negotiating pricing. OpenAI unveiled its first open source language models since GPT-2, introducing two new open-weight AI releases: gpt-oss-120b, a high-performance model capable of running on a single Nvidia GPU, and gpt-oss-20b, a lighter model optimized for laptop use. The move comes amid growing competition in the global AI market and a push for more open technology in the U.S. and abroad. ChatGPT’s rapid growth is accelerating. OpenAI said the chatbot was on track to hit 700 million weekly active users in the first week of August, up from 500 million at the end of March. Nick Turley, OpenAI’s VP and head of the ChatGPT app, highlighted the app’s growth on X, noting it has quadrupled in size over the past year. This week, ChatGPT is on track to reach 700M weekly active users — up from 500M at the end of March and 4× since last year. Every day, people and teams are learning, creating, and solving harder problems. Big week ahead. Grateful to the team for making ChatGPT more useful and… OpenAI unveiled Study Mode, a new ChatGPT feature designed to promote critical thinking by prompting students to engage with material rather than simply receive answers. The tool is now rolling out to Free, Plus, Pro, and Team users, with availability for Edu subscribers expected in the coming weeks. ChatGPT users should be cautious when seeking emotional support from AI, as the AI industry lacks safeguards for sensitive conversations, OpenAI CEO Sam Altman said on a recent episode of This Past Weekend w/ Theo Von. Unlike human therapists, AI tools aren’t bound by doctor-patient confidentiality, he noted. ChatGPT now receives 2.5 billion prompts daily from users worldwide, including roughly 330 million from the U.S. That’s more than double the volume reported by CEO Sam Altman just eight months ago, highlighting the chatbot’s explosive growth. OpenAI has introduced ChatGPT Agent, which completes a wide variety of computer-based tasks on behalf of users and combines several capabilities like Operator and Deep Research, according to the company. OpenAI says the agent can automatically navigate a user’s calendar, draft editable presentations and slideshows, run code, shop online, and handle complex workflows from end to end, all within a secure virtual environment. Researchers at Stanford University have observed that therapy chatbots powered by large language models can sometimes stigmatize people with mental health conditions or respond in ways that are inappropriate or could be harmful. While chatbots are “being used as companions, confidants, and therapists,” the study found “significant risks.” CEO Sam Altman said that the company is delaying the release of its open model, which had already been postponed by a month earlier this summer. The ChatGPT maker, which initially planned to release the model around mid-July, has indefinitely postponed its launch to conduct additional safety testing. we planned to launch our open-weight model next week.we are delaying it; we need time to run additional safety tests and review high-risk areas. we are not yet sure how long it will take us.while we trust the community will build great things with this model, once weights are… OpenAI plans to release an AI-powered web browser to challenge Alphabet’s Google Chrome. It will keep some user interactions within ChatGPT, rather than directing people to external websites. Some ChatGPT users have noticed a new feature called “Study Together” appearing in their list of available tools. This is the chatbot’s approach to becoming a more effective educational tool, rather than simply providing answers to prompts. Some people also wonder whether there will be a feature that allows multiple users to join the chat, similar to a study group. Referrals from ChatGPT to news publishers are increasing. But this rise is insufficient to offset the decline in clicks as more users now obtain their news directly from AI or AI-powered search results, according to a report by digital market intelligence company Similarweb. Since Google launched its AI Overviews in May 2024, the percentage of news searches that don’t lead to clicks on news websites has increased from 56% to nearly 69% by May 2025. OpenAI has started using Google’s AI chips to power ChatGPT and other products, as reported by Reuters. The ChatGPT maker is one of the biggest buyers of Nvidia’s GPUs, using the AI chips to train models, and this is the first time that OpenAI is using non-Nvidia chips in an important way. Researchers from MIT’s Media Lab monitored the brain activity of writers in 32 regions. They found that ChatGPT users showed minimal brain engagement and consistently fell short in neural, linguistic, and behavioral aspects. To conduct the test, the lab split 54 participants from the Boston area into three groups, each consisting of individuals ages 18 to 39. The participants were asked to write multiple SAT essays using tools such as OpenAI’s ChatGPT, the Google search engine, or without any tools. The ChatGPT app for iOS was downloaded 29.6 million times in the last 28 days, while TikTok, Facebook, Instagram, and X were downloaded a total of 32.9 million times during the same period, representing a difference of about 10.6%, according to ZDNET report citing Similarweb’s X post. Sam Altman said that the average ChatGPT query uses about one-fifteenth of a teaspoon of water, equivalent to 0.000083 gallons of water, or the energy required to power a lightbulb for a few minutes, per Business Insider. In addition to that, the chatbot requires 0.34 watt-hours of electricity to operate. OpenAI has unveiled o3-pro, an enhanced version of its o3, a reasoning model that the chatGPT maker launched earlier this year. O3-pro is available for ChatGPT and Team users and in the API, while Enterprise and Edu users will get access in the third week of June. OpenAI o3-pro is available in the model picker for Pro and Team users starting today, replacing OpenAI o1-pro.Enterprise and Edu users will get access the week after.As o3-pro uses the same underlying model as o3, full safety details can be found in the o3 system card.… OpenAI upgraded ChatGPT’s conversational voice mood for all paid users across different markets and platforms. The startup has launched an update to Advanced Voice that enables users to converse with ChatGPT out loud in a more natural and fluid sound. The feature also helps users translate languages more easily, the comapny said. OpenAI’s ChatGPT now offers new funtions for business users, including integrations with various cloud services, meeting recordings, and MCP connection support for connecting to tools for in-depth research. The feature enables ChatGPT to retrieve information across users’ own services to answer their questions. For instance, an analyst could use the company’s slide deck and documents to develop an investment thesis. OpenAI plans to purchase Jony Ive’s devices startup io for $6.4 billion. Sarah Friar, CFO of OpenAI, thinks that the hardware will significantly enhance ChatGPT and broaden OpenAI’s reach to a larger audience in the future. OpenAI has introduced its AI coding agent, Codex, powered by codex-1, a version of its o3 AI reasoning model designed for software engineering tasks. OpenAI says codex-1 generates more precise and “cleaner” code than o3. The coding agent may take anywhere from one to 30 minutes to complete tasks such as writing simple features, fixing bugs, answering questions about your codebase, and running tests. Sam Altman, the CEO of OpenAI, said during a recent AI event hosted by VC firm Sequoia that he wants ChatGPT to record and remember every detail of a person’s life when one attendee asked about how ChatGPT can become more personalized. OpenAI said in a post on X that it has launched its GPT-4.1 and GPT4.1 mini AI models in ChagGPT. By popular request, GPT-4.1 will be available directly in ChatGPT starting today.GPT-4.1 is a specialized model that excels at coding tasks & instruction following. Because it’s faster, it’s a great alternative to OpenAI o3 & o4-mini for everyday coding needs. OpenAI has launched a new feature for ChatGPT deep research to analyze code repositories on GitHub. The ChatGPT deep research feature is in beta and lets developers connect with GitHub to ask questions about codebases and engineering documents. The connector will soon be available for ChatGPT Plus, Pro, and Team users, with support for Enterprise and Education coming shortly, per an OpenAI spokesperson. After introducing a data residency program in Europe in February, OpenAI has now launched a similar program in Asian countries including India, Japan, Singapore, and South Korea. The new program will be accessible to users of ChatGPT Enterprise, ChatGPT Edu, and API. It will help organizations in Asia meet their local data sovereignty requirements when using OpenAI’s products. OpenAI is unveiling a program called OpenAI for Countries, which aims to develop the necessary local infrastructure to serve international AI clients better. The AI startup will work with governments to assist with increasing data center capacity and customizing OpenAI’s products to meet specific language and local needs. OpenAI for Countries is part of efforts to support the company’s expansion of its AI data center Project Stargate to new locations outside the U.S., per Bloomberg. OpenAI has announced its plan to make changes to its procedures for updating the AI models that power ChatGPT, following an update that caused the platform to become overly sycophantic for many users. OpenAI has released a post on the recent sycophancy issues with the default AI model powering ChatGPT, GPT-4o, leading the company to revert an update to the model released last week. CEO Sam Altman acknowledged the issue on Sunday and confirmed two days later that the GPT-4o update was being rolled back. OpenAI is working on “additional fixes” to the model’s personality. Over the weekend, users on social media criticized the new model for making ChatGPT too validating and agreeable. It became a popular meme fast. An issue within OpenAI’s ChatGPT enabled the chatbot to create graphic erotic content for accounts registered by users under the age of 18, as demonstrated by TechCrunch’s testing, a fact later confirmed by OpenAI. “Protecting younger users is a top priority, and our Model Spec, which guides model behavior, clearly restricts sensitive content like erotica to narrow contexts such as scientific, historical, or news reporting,” a spokesperson told TechCrunch via email. “In this case, a bug allowed responses outside those guidelines, and we are actively deploying a fix to limit these generations.” OpenAI has added a few features to its ChatGPT search, its web search tool in ChatGPT, to give users an improved online shopping experience. The company says people can ask super-specific questions using natural language and receive customized results. The chatbot provides recommendations, images, and reviews of products in various categories such as fashion, beauty, home goods, and electronics. OpenAI leaders have been talking about allowing the open model to link up with OpenAI’s cloud-hosted models to improve its ability to respond to intricate questions, two sources familiar with the situation told TechCrunch. OpenAI is preparing to launch an AI system that will be openly accessible, allowing users to download it for free without any API restrictions. Aidan Clark, OpenAI’s VP of research, is spearheading the development of the open model, which is in the very early stages, sources familiar with the situation told TechCrunch. OpenAI released a new AI model called GPT-4.1 in mid-April. However, multiple independent tests indicate that the model is less reliable than previous OpenAI releases. The company skipped that step — sending safety cards for GPT-4.1 — claiming in a statement to TechCrunch that “GPT-4.1 is not a frontier model, so there won’t be a separate system card released for it.” Questions have been raised regarding OpenAI’s transparency and procedures for testing models after a difference in benchmark outcomes was detected by first- and third-party benchmark results for the o3 AI model. OpenAI introduced o3 in December, stating that the model could solve approximately 25% of questions on FrontierMath, a difficult math problem set. Epoch AI, the research institute behind FrontierMath, discovered that o3 achieved a score of approximately 10%, which was significantly lower than OpenAI’s top-reported score. OpenAI has launched a new API feature called Flex processing that allows users to use AI models at a lower cost but with slower response times and occasional resource unavailability. Flex processing is available in beta on the o3 and o4-mini reasoning models for non-production tasks like model evaluations, data enrichment, and asynchronous workloads. OpenAI has rolled out a new system to monitor its AI reasoning models, o3 and o4 mini, for biological and chemical threats. The system is designed to prevent models from giving advice that could potentially lead to harmful attacks, as stated in OpenAI’s safety report. OpenAI has released two new reasoning models, o3 and o4 mini, just two days after launching GPT-4.1. The company claims o3 is the most advanced reasoning model it has developed, while o4-mini is said to provide a balance of price, speed, and performance. The new models stand out from previous reasoning models because they can use ChatGPT features like web browsing, coding, and image processing and generation. But they hallucinate more than several of OpenAI’s previous models. Open AI introduced a new section called “library” to make it easier for users to create images on mobile and web platforms, per the company’s X post. All of your image creations, all in one place.Introducing the new library for your ChatGPT image creations—rolling out now to all Free, Plus, and Pro users on mobile and https://t.co/nYW5KO1aIg. pic.twitter.com/ADWuf5fPbj OpenAI said on Tuesday that it might revise its safety standards if “another frontier AI developer releases a high-risk system without comparable safeguards.” The move shows how commercial AI developers face more pressure to rapidly implement models due to the increased competition. OpenAI is currently in the early stages of developing its own social media platform to compete with Elon Musk’s X and Mark Zuckerberg’s Instagram and Threads, according to The Verge. It is unclear whether OpenAI intends to launch the social network as a standalone application or incorporate it into ChatGPT. OpenAI will discontinue its largest AI model, GPT-4.5, from its API even though it was just launched in late February. GPT-4.5 will be available in a research preview for paying customers. Developers can use GPT-4.5 through OpenAI’s API until July 14; then, they will need to switch to GPT-4.1, which was released on April 14. OpenAI has launched three members of the GPT-4.1 model — GPT-4.1, GPT-4.1 mini, and GPT-4.1 nano — with a specific focus on coding capabilities. It’s accessible via the OpenAI API but not ChatGPT. In the competition to develop advanced programming models, GPT-4.1 will rival AI models such as Google’s Gemini 2.5 Pro, Anthropic’s Claude 3.7 Sonnet, and DeepSeek’s upgraded V3. OpenAI plans to sunset GPT-4, an AI model introduced more than two years ago, and replace it with GPT-4o, the current default model, per changelog. It will take effect on April 30. GPT-4 will remain available via OpenAI’s API. OpenAI may launch several new AI models, including GPT-4.1, soon, The Verge reported, citing anonymous sources. GPT-4.1 would be an update of OpenAI’s GPT-4o, which was released last year. On the list of upcoming models are GPT-4.1 and smaller versions like GPT-4.1 mini and nano, per the report. OpenAI started updating ChatGPT to enable the chatbot to remember previous conversations with a user and customize its responses based on that context. This feature is rolling out to ChatGPT Pro and Plus users first, excluding those in the U.K., EU, Iceland, Liechtenstein, Norway, and Switzerland. It looks like OpenAI is working on a watermarking feature for images generated using GPT-4o. AI researcher Tibor Blaho spotted a new “ImageGen” watermark feature in the new beta of ChatGPT’s Android app. Blaho also found mentions of other tools: “Structured Thoughts,” “Reasoning Recap,” “CoT Search Tool,” and “l1239dk1.” OpenAI is offering its $20-per-month ChatGPT Plus subscription tier for free to all college students in the U.S. and Canada through the end of May. The offer will let millions of students use OpenAI’s premium service, which offers access to the company’s GPT-4o model, image generation, voice interaction, and research tools that are not available in the free version. More than 130 million users have created over 700 million images since ChatGPT got the upgraded image generator on March 25, according to COO of OpenAI Brad Lightcap. The image generator was made available  to all ChatGPT users on March 31, and went viral for being able to create Ghibli-style photos. The Arc Prize Foundation, which develops the AI benchmark tool ARC-AGI, has updated the estimated computing costs for OpenAI’s o3 “reasoning” model managed by ARC-AGI. The organization originally estimated that the best-performing configuration of o3 it tested, o3 high, would cost approximately $3,000 to address a single problem. The Foundation now thinks the cost could be much higher, possibly around $30,000 per task. In a series of posts on X, OpenAI CEO Sam Altman said the company’s new image-generation tool’s popularity may cause product releases to be delayed. “We are getting things under control, but you should expect new releases from OpenAI to be delayed, stuff to break, and for service to sometimes be slow as we deal with capacity challenges,” he wrote. OpeanAI intends to release its “first” open language model since GPT-2 “in the coming months.” The company plans to host developer events to gather feedback and eventually showcase prototypes of the model. The first developer event is to be held in San Francisco, with sessions to follow in Europe and Asia. OpenAI made a notable change to its content moderation policies after the success of its new image generator in ChatGPT, which went viral for being able to create Studio Ghibli-style images. The company has updated its policies to allow ChatGPT to generate images of public figures, hateful symbols, and racial features when requested. OpenAI had previously declined such prompts due to the potential controversy or harm they may cause. However, the company has now “evolved” its approach, as stated in a blog post published by Joanne Jang, the lead for OpenAI’s model behavior. OpenAI wants to incorporate Anthropic’s Model Context Protocol (MCP) into all of its products, including the ChatGPT desktop app. MCP, an open-source standard, helps AI models generate more accurate and suitable responses to specific queries, and lets developers create bidirectional links between data sources and AI applications like chatbots. The protocol is currently available in the Agents SDK, and support for the ChatGPT desktop app and Responses API will be coming soon, OpenAI CEO Sam Altman said. The latest update of the image generator on OpenAI’s ChatGPT has triggered a flood of AI-generated memes in the style of Studio Ghibli, the Japanese animation studio behind blockbuster films like “My Neighbor Totoro” and “Spirited Away.” The burgeoning mass of Ghibli-esque images have sparked concerns about whether OpenAI has violated copyright laws, especially since the company is already facing legal action for using source material without authorization. OpenAI expects its revenue to triple to $12.7 billion in 2025, fueled by the performance of its paid AI software, Bloomberg reported, citing an anonymous source. While the startup doesn’t expect to reach positive cash flow until 2029, it expects revenue to increase significantly in 2026 to surpass $29.4 billion, the report said. OpenAI on Tuesday rolled out a major upgrade to ChatGPT’s image-generation capabilities: ChatGPT can now use the GPT-4o model to generate and edit images and photos directly. The feature went live earlier this week in ChatGPT and Sora, OpenAI’s AI video-generation tool, for subscribers of the company’s Pro plan, priced at $200 a month, and will be available soon to ChatGPT Plus subscribers and developers using the company’s API service. The company’s CEO Sam Altman said on Wednesday, however, that the release of the image generation feature to free users would be delayed due to higher demand than the company expected. Brad Lightcap, OpenAI’s chief operating officer, will lead the company’s global expansion and manage corporate partnerships as CEO Sam Altman shifts his focus to research and products, according to a blog post from OpenAI. Lightcap, who previously worked with Altman at Y Combinator, joined the Microsoft-backed startup in 2018. OpenAI also said Mark Chen would step into the expanded role of chief research officer, and Julia Villagra will take on the role of chief people officer. OpenAI has updated its AI voice assistant with improved chatting capabilities, according to a video posted on Monday (March 24) to the company’s official media channels. The update enables real-time conversations, and the AI assistant is said to be more personable and interrupts users less often. Users on ChatGPT’s free tier can now access the new version of Advanced Voice Mode, while paying users will receive answers that are “more direct, engaging, concise, specific, and creative,” a spokesperson from OpenAI told TechCrunch. OpenAI and Meta have separately engaged in discussions with Indian conglomerate Reliance Industries regarding potential collaborations to enhance their AI services in the country, per a report by The Information. One key topic being discussed is Reliance Jio distributing OpenAI’s ChatGPT. Reliance has proposed selling OpenAI’s models to businesses in India through an application programming interface (API) so they can incorporate AI into their operations. Meta also plans to bolster its presence in India by constructing a large 3GW data center in Jamnagar, Gujarat. OpenAI, Meta, and Reliance have not yet officially announced these plans. Noyb, a privacy rights advocacy group, is supporting an individual in Norway who was shocked to discover that ChatGPT was providing false information about him, stating that he had been found guilty of killing two of his children and trying to harm the third. “The GDPR is clear. Personal data has to be accurate,” said Joakim Söderberg, data protection lawyer at Noyb, in a statement. “If it’s not, users have the right to have it changed to reflect the truth. Showing ChatGPT users a tiny disclaimer that the chatbot can make mistakes clearly isn’t enough. You can’t just spread false information and in the end add a small disclaimer saying that everything you said may just not be true.” OpenAI has added new transcription and voice-generating AI models to its APIs: a text-to-speech model, “gpt-4o-mini-tts,” that delivers more nuanced and realistic sounding speech, as well as two speech-to-text models called “gpt-4o-transcribe” and “gpt-4o-mini-transcribe”. The company claims they are improved versions of what was already there and that they hallucinate less. OpenAI has introduced o1-pro in its developer API. OpenAI says its o1-pro uses more computing than its o1 “reasoning” AI model to deliver “consistently better responses.” It’s only accessible to select developers who have spent at least $5 on OpenAI API services. OpenAI charges $150 for every million tokens (about 750,000 words) input into the model and $600 for every million tokens the model produces. It costs twice as much as OpenAI’s GPT-4.5 for input and 10 times the price of regular o1. Noam Brown, who heads AI reasoning research at OpenAI, thinks that certain types of AI models for “reasoning” could have been developed 20 years ago if researchers had understood the correct approach and algorithms. OpenAI CEO Sam Altman said, in a post on X, that the company has trained a “new model” that’s “really good” at creative writing. He posted a lengthy sample from the model given the prompt “Please write a metafictional literary short story about AI and grief.” OpenAI has not extensively explored the use of AI for writing fiction. The company has mostly concentrated on challenges in rigid, predictable areas such as math and programming. And it turns out that it might not be that great at creative writing at all. we trained a new model that is good at creative writing (not sure yet how/when it will get released). this is the first time i have been really struck by something written by AI; it got the vibe of metafiction so right.PROMPT:Please write a metafictional literary short story… OpenAI rolled out new tools designed to help developers and businesses build AI agents — automated systems that can independently accomplish tasks — using the company’s own AI models and frameworks. The tools are part of OpenAI’s new Responses API, which enables enterprises to develop customized AI agents that can perform web searches, scan through company files, and navigate websites, similar to OpenAI’s Operator product. The Responses API effectively replaces OpenAI’s Assistants API, which the company plans to discontinue in the first half of 2026. OpenAI intends to release several “agent” products tailored for different applications, including sorting and ranking sales leads and software engineering, according to a report from The Information. One, a “high-income knowledge worker” agent, will reportedly be priced at $2,000 a month. Another, a software developer agent, is said to cost $10,000 a month. The most expensive rumored agents, which are said to be aimed at supporting “PhD-level research,” are expected to cost $20,000 per month. The jaw-dropping figure is indicative of how much cash OpenAI needs right now: The company lost roughly $5 billion last year after paying for costs related to running its services and other expenses. It’s unclear when these agentic tools might launch or which customers will be eligible to buy them. The latest version of the macOS ChatGPT app allows users to edit code directly in supported developer tools, including Xcode, VS Code, and JetBrains. ChatGPT Plus, Pro, and Team subscribers can use the feature now, and the company plans to roll it out to more users like Enterprise, Edu, and free users. According to a new report from VC firm Andreessen Horowitz (a16z), OpenAI’s AI chatbot, ChatGPT, experienced solid growth in the second half of 2024. It took ChatGPT nine months to increase its weekly active users from 100 million in November 2023 to 200 million in August 2024, but it only took less than six months to double that number once more, according to the report. ChatGPT’s weekly active users increased to 300 million by December 2024 and 400 million by February 2025. ChatGPT has experienced significant growth recently due to the launch of new models and features, such as GPT-4o, with multimodal capabilities. ChatGPT usage spiked from April to May 2024, shortly after that model’s launch. OpenAI has effectively canceled the release of o3 in favor of what CEO Sam Altman is calling a “simplified” product offering. In a post on X, Altman said that, in the coming months, OpenAI will release a model called GPT-5 that “integrates a lot of [OpenAI’s] technology,” including o3, in ChatGPT and its API. As a result of that roadmap decision, OpenAI no longer plans to release o3 as a standalone model.  A commonly cited stat is that ChatGPT requires around 3 watt-hours of power to answer a single question. Using OpenAI’s latest default model for ChatGPT, GPT-4o, as a reference, nonprofit AI research institute Epoch AI found the average ChatGPT query consumes around 0.3 watt-hours. However, the analysis doesn’t consider the additional energy costs incurred by ChatGPT with features like image generation or input processing. In response to pressure from rivals like DeepSeek, OpenAI is changing the way its o3-mini model communicates its step-by-step “thought” process. ChatGPT users will see an updated “chain of thought” that shows more of the model’s “reasoning” steps and how it arrived at answers to questions. OpenAI is now allowing anyone to use ChatGPT web search without having to log in. While OpenAI had previously allowed users to ask ChatGPT questions without signing in, responses were restricted to the chatbot’s last training update. This only applies through ChatGPT.com, however. To use ChatGPT in any form through the native mobile app, you will still need to be logged in. OpenAI announced a new AI “agent” called deep research that’s designed to help people conduct in-depth, complex research using ChatGPT. OpenAI says the “agent” is intended for instances where you don’t just want a quick answer or summary, but instead need to assiduously consider information from multiple websites and other sources. OpenAI used the subreddit r/ChangeMyView to measure the persuasive abilities of its AI reasoning models. OpenAI says it collects user posts from the subreddit and asks its AI models to write replies, in a closed environment, that would change the Reddit user’s mind on a subject. The company then shows the responses to testers, who assess how persuasive the argument is, and finally OpenAI compares the AI models’ responses to human replies for that same post.  OpenAI launched a new AI “reasoning” model, o3-mini, the newest in the company’s o family of models. OpenAI first previewed the model in December alongside a more capable system called o3. OpenAI is pitching its new model as both “powerful” and “affordable.” A new report from app analytics firm Appfigures found that over half of ChatGPT’s mobile users are under age 25, with users between ages 50 and 64 making up the second largest age demographic. The gender gap among ChatGPT users is even more significant. Appfigures estimates that across age groups, men make up 84.5% of all users. OpenAI launched ChatGPT Gov designed to provide U.S. government agencies an additional way to access the tech. ChatGPT Gov includes many of the capabilities found in OpenAI’s corporate-focused tier, ChatGPT Enterprise. OpenAI says that ChatGPT Gov enables agencies to more easily manage their own security, privacy, and compliance, and could expedite internal authorization of OpenAI’s tools for the handling of non-public sensitive data. Younger Gen Zers are embracing ChatGPT, for schoolwork, according to a new survey by the Pew Research Center. In a follow-up to its 2023 poll on ChatGPT usage among young people, Pew asked ~1,400 U.S.-based teens ages 13 to 17 whether they’ve used ChatGPT for homework or other school-related assignments. Twenty-six percent said that they had, double the number two years ago. Just over half of teens responding to the poll said they think it’s acceptable to use ChatGPT for researching new subjects. But considering the ways ChatGPT can fall short, the results are possibly cause for alarm. OpenAI says that it might store chats and associated screenshots from customers who use Operator, the company’s AI “agent” tool, for up to 90 days — even after a user manually deletes them. While OpenAI has a similar deleted data retention policy for ChatGPT, the retention period for ChatGPT is only 30 days, which is 60 days shorter than Operator’s. OpenAI is launching a research preview of Operator, a general-purpose AI agent that can take control of a web browser and independently perform certain actions. Operator promises to automate tasks such as booking travel accommodations, making restaurant reservations, and shopping online. Operator, OpenAI’s agent tool, could be released sooner rather than later. Changes to ChatGPT’s code base suggest that Operator will be available as an early research preview to users on the $200 Pro subscription plan. The changes aren’t yet publicly visible, but a user on X who goes by Choi spotted these updates in ChatGPT’s client-side code. TechCrunch separately identified the same references to Operator on OpenAI’s website. OpenAI has begun testing a feature that lets new ChatGPT users sign up with only a phone number — no email required. The feature is currently in beta in the U.S. and India. However, users who create an account using their number can’t upgrade to one of OpenAI’s paid plans without verifying their account via an email. Multi-factor authentication also isn’t supported without a valid email. ChatGPT’s new beta feature, called tasks, allows users to set simple reminders. For example, you can ask ChatGPT to remind you when your passport expires in six months, and the AI assistant will follow up with a push notification on whatever platform you have tasks enabled. The feature will start rolling out to ChatGPT Plus, Team, and Pro users around the globe this week. OpenAI is introducing a new way for users to customize their interactions with ChatGPT. Some users found they can specify a preferred name or nickname and “traits” they’d like the chatbot to have. OpenAI suggests traits like “Chatty,” “Encouraging,” and “Gen Z.” However, some users reported that the new options have disappeared, so it’s possible they went live prematurely. ChatGPT is a general-purpose chatbot that uses artificial intelligence to generate text after a user enters a prompt, developed by tech startup OpenAI. The chatbot uses GPT-4, a large language model that uses deep learning to produce human-like text. November 30, 2022 is when ChatGPT was released for public use. Both the free version of ChatGPT and the paid ChatGPT Plus are regularly updated with new GPT models. The most recent model is GPT-4o. There is a free version of ChatGPT that only requires a sign-in in addition to the paid version, ChatGPT Plus. Anyone can use ChatGPT! More and more tech companies and search engines are utilizing the chatbot to automate text or quickly answer user questions/concerns. Multiple enterprises utilize ChatGPT, although others may limit the use of the AI-powered tool. Most recently, Microsoft announced at its 2023 Build conference that it is integrating its ChatGPT-based Bing experience into Windows 11. A Brooklyn-based 3D display startup Looking Glass utilizes ChatGPT to produce holograms you can communicate with by using ChatGPT.  And nonprofit organization Solana officially integrated the chatbot into its network with a ChatGPT plug-in geared toward end users to help onboard into the web3 space. GPT stands for Generative Pre-Trained Transformer. A chatbot can be any software/system that holds dialogue with you/a person but doesn’t necessarily have to be AI-powered. For example, there are chatbots that are rules-based in the sense that they’ll give canned responses to questions. ChatGPT is AI-powered and utilizes LLM technology to generate text after a prompt. Yes. Due to the nature of how these models work, they don’t know or care whether something is true, only that it looks true. That’s a problem when you’re using it to do your homework, sure, but when it accuses you of a crime you didn’t commit, that may well at this point be libel. We will see how handling troubling statements produced by ChatGPT will play out over the next few months as tech and legal experts attempt to tackle the fastest moving target in the industry. Yes, there is a free ChatGPT mobile app for iOS and Android users. It’s not documented anywhere that ChatGPT has a character limit. However, users have noted that there are some character limitations after around 500 words. Yes, it was released March 1, 2023. Everyday examples include programming, scripts, email replies, listicles, blog ideas, summarization, etc. Advanced use examples include debugging code, programming languages, scientific concepts, complex problem solving, etc. It depends on the nature of the program. While ChatGPT can write workable Python code, it can’t necessarily program an entire app’s worth of code. That’s because ChatGPT lacks context awareness — in other words, the generated code isn’t always appropriate for the specific context in which it’s being used. Yes. OpenAI allows users to save chats in the ChatGPT interface, stored in the sidebar of the screen. There are no built-in sharing features yet. Yes. There are multiple AI-powered chatbot competitors such as Together, Google’s Gemini and Anthropic’s Claude, and developers are creating open source alternatives. OpenAI has said that individuals in “certain jurisdictions” (such as the EU) can object to the processing of their personal information by its AI models by filling out this form. This includes the ability to make requests for deletion of AI-generated references about you. Although OpenAI notes it may not grant every request since it must balance privacy requests against freedom of expression “in accordance with applicable laws”. The web form for making a deletion of data about you request is entitled “OpenAI Personal Data Removal Request”. In its privacy policy, the ChatGPT maker makes a passing acknowledgement of the objection requirements attached to relying on “legitimate interest” (LI), pointing users towards more information about requesting an opt out — when it writes: “See here for instructions on how you can opt out of our use of your information to train our models.” Recently, Discord announced that it had integrated OpenAI’s technology into its bot named Clyde where two users tricked Clyde into providing them with instructions for making the illegal drug methamphetamine (meth) and the incendiary mixture napalm. An Australian mayor has publicly announced he may sue OpenAI for defamation due to ChatGPT’s false claims that he had served time in prison for bribery. This would be the first defamation lawsuit against the text-generating service. CNET found itself in the midst of controversy after Futurism reported the publication was publishing articles under a mysterious byline completely generated by AI. The private equity company that owns CNET, Red Ventures, was accused of using ChatGPT for SEO farming, even if the information was incorrect. Several major school systems and colleges, including New York City Public Schools, have banned ChatGPT from their networks and devices. They claim that the AI impedes the learning process by promoting plagiarism and misinformation, a claim that not every educator agrees with. There have also been cases of ChatGPT accusing individuals of false crimes. Several marketplaces host and provide ChatGPT prompts, either for free or for a nominal fee. One is PromptBase. Another is ChatX. More launch every day. Poorly. Several tools claim to detect ChatGPT-generated text, but in our tests, they’re inconsistent at best. No. But OpenAI recently disclosed a bug, since fixed, that exposed the titles of some users’ conversations to other people on the service. None specifically targeting ChatGPT. But OpenAI is involved in at least one lawsuit that has implications for AI systems trained on publicly available data, which would touch on ChatGPT. Yes. Text-generating AI models like ChatGPT have a tendency to regurgitate content from their training data. This story is continually updated with new information."
Waymo resumes service in San Francisco after robotaxis stall during blackout,https://techcrunch.com/2025/12/21/waymo-suspends-service-in-san-francisco-as-robotaxis-stall-during-blackout/,"Waymo suspended its robotaxi service in San Francisco on Saturday evening after a massive blackout appeared to leave many of its vehicles stalled on city streets. Numerous photos and videos posted to social media captured Waymo robotaxis stalled on roads and at intersections as human drivers were either stuck behind them or weaved around them. Waymo said on Saturday that it had temporarily suspended service in the city due to the blackout. It wasn’t until late Sunday afternoon that a Waymo spokesperson told TechCrunch in a statement that the company was resuming service. “Yesterday’s power outage was a widespread event that caused gridlock across San Francisco, with non-functioning traffic signals and transit disruptions,” the spokesperson said. “While the failure of the utility infrastructure was significant, we are committed to ensuring our technology adjusts to traffic flow during such events.” The Waymo spokesperson added that the company is “focused on rapidly integrating the lessons learned from this event, and are committed to earning and maintaining the trust of the communities we serve every day.” Power outage took out the waymos RIP pic.twitter.com/DPte8oOGku The blackout also took down many of the city’s traffic lights and affected Muni mass transit, with San Francisco Mayor Daniel Lurie warning residents to stay off the roads unless they needed to travel. Waymo said that although its self-driving systems are designed to treat non-functioning traffic lights as four-way stops, the scale of Saturday’s blackout caused some robotaxis to remain stationary for longer than normal as they tried to assess the intersections. The company also said that the majority of active trips were completed successfully. The blackout appears to have been caused by a fire at a Pacific Gas & Electric substation in the city. SFGate reports that around 120,000 PG&E customers were affected by the blackout, and while the majority of them had power restored by late Saturday, 35,000 customers were still without power on Sunday morning. PG&E’s website also showed thousands of San Francisco customers still affected at that time. A letter from Tiger Global Management that leaked earlier this month said Waymo is now providing 450,000 robotaxi rides per week, nearly double the amount that the Alphabet-owned company disclosed in the spring. This post has been updated with Waymo’s statement that service is resuming. Power out in SF and the @Waymo’s are causing a MASSIVE jam in North Beach 🤣 pic.twitter.com/fuvhprlyma"
OpenAI allows users to directly adjust ChatGPT’s enthusiasm level,https://techcrunch.com/2025/12/20/openai-allows-users-to-directly-adjust-chatgpts-warmth-and-enthusiasm/,"ChatGPT users can now tweak the chatbot’s warmth, enthusiasm, and emoji use, according to a social media post from OpenAI. These options (as well as similar adjustments to ChatGPT’s use of headers and lists) now appear in the Personalization menu and can be set to More, Less, or Default. They allow users to further customize ChatGPT’s tone, on top of the existing ability to set a “base style and tone” — including the Professional, Candid, and Quirky tones that OpenAI added in November. ChatGPT’s tone has been an ongoing issue this year, with OpenAI rolling back one update for being “too sycophant-y,” then later adjusting GPT-5 to be “warmer and friendlier” after some users complained that the new model was colder and less friendly. Some academics and AI critics have suggested that chatbots’ tendency to praise users and affirm their beliefs are a “dark pattern” that creates addictive behavior and can have a negative effect on users’ mental health. You can now adjust specific characteristics in ChatGPT, like warmth, enthusiasm, and emoji use.Now available in your ""Personalization"" settings. pic.twitter.com/7WSkOQVTKU"
New York governor Kathy Hochul signs RAISE Act to regulate AI safety,https://techcrunch.com/2025/12/20/new-york-governor-kathy-hochul-signs-raise-act-to-regulate-ai-safety/,"Governor Kathy Hochul has signed the RAISE Act, positioning New York as the second U.S. state to enact major AI safety legislation. State lawmakers passed the RAISE Act in June, but following lobbying from the tech industry, Hochul proposed changes to scale the bill back. The New York Times reports that Hochul ultimately agreed to sign the original bill, while lawmakers agreed to make her requested changes next year. The bill will require large AI developers to publish information about their safety protocols and report safety incidents to the state within 72 hours. It will also create a new office within the Department of Financial Services to monitor AI development. If companies fail to submit safety reports or make false statements, they can be fined up to $1 million ($3 million for subsequent violations). California governor Gavin Newsom signed a similar safety bill in September, which Hochul referenced in her announcement. “This law builds on California’s recently adopted framework, creating a unified benchmark among the country’s leading tech states as the federal government lags behind, failing to implement common-sense regulations that protect the public,” Hochul said. New York state senator Andrew Gounardes, one of the bill’s sponsors, posted, “Big Tech thought they could weasel their way into killing our bill. We shut them down and passed the strongest AI safety law in the country.” Both OpenAI and Anthropic expressed support for New York’s bill while also calling for federal legislation, with Anthropic’s head of external affairs Sarah Heck telling the NYT, “The fact that two of the largest states in the country have now enacted AI transparency legislation signals the critical importance of safety and should inspire Congress to build on them.” Not everyone in the tech industry has been so supportive. In fact, a super PAC backed by Andreessen Horowitz and OpenAI president Greg Brockman is looking to challenge Assemblyman Alex Bores, who co-sponsored the bill with Gounardes. (Bores told journalists, “I appreciate how straightforward they’re being about it.”) This comes after President Donald Trump signed an executive order that directs federal agencies to challenge state AI laws. The order — backed by Trump’s AI czar David Sacks — is the latest attempt by the Trump administration to curtail states’ ability to regulate AI and will likely be challenged in court. We also discussed Trump’s executive order, and the role that Sacks and a16z have played in opposing state AI regulation, on the latest episode of the Equity podcast."
Ex-Splunk execs’ startup Resolve AI hits $1B valuation with Series A,https://techcrunch.com/2025/12/19/ex-splunk-execs-startup-resolve-ai-hits-1-billion-valuation-with-series-a/,"Resolve AI, a startup developing an autonomous site reliability engineer (SRE), a tool that automatically maintains software systems, has raised a Series A led by Lightspeed Venture Partners, according to three people familiar with the deal. The headline valuation for the fresh round is $1 billion, sources said. However, the company’s actual blended valuation was lower because of a multi-tranched structure. In this setup, investors purchased some equity at a $1 billion valuation but acquired the remainder — likely a larger percentage of the round — at a lower price. This novel investment approach has recently become popular for the most sought-after AI startups, investors say. The startup’s annual recurring revenue (ARR) is approximately $4 million, two of the people said. The size of the funding round couldn’t be learned. Resolve AI and Lightspeed didn’t respond to our request for comment. Founded less than two years ago, the startup is led by former Splunk executive Spiros Xanthos and Mayank Agarwal, Splunk’s former chief architect for observability. The duo’s partnership dates back 20 years to their graduate studies at the University of Illinois Urbana-Champaign. This isn’t their first collaboration; they previously co-founded Omnition, a startup that Splunk acquired in 2019. While human SREs are traditionally responsible for manually troubleshooting and resolving system failures, Resolve AI automates this process by autonomously identifying, diagnosing, and resolving production issues in real time. The automation addresses a growing challenge for companies. As software systems become more complex and distributed across cloud infrastructure, outfits often struggle to find and retain enough skilled SREs to keep systems running smoothly. Automating these tasks can reduce downtime, lower operational costs, and free up engineering teams to focus on building new features rather than trying to constantly stomp out production issues. Last October, Resolve AI raised a $35 million seed round led by Greylock with participation from World Labs founder Fei-Fei Li and Google DeepMind scientist Jeff Dean. Resolve AI competes with Traversal, an AI SRE startup that raised a $48 million Series A led by Kleiner Perkins, with participation from Sequoia.   "
Cursor continues acquisition spree with Graphite deal,https://techcrunch.com/2025/12/19/cursor-continues-acquisition-spree-with-graphite-deal/,"AI coding assistant Cursor announced that it has acquired Graphite, a startup that uses AI to review and debug code. Although the terms of the deal were not disclosed, Axios reported that Cursor paid “way over” Graphite’s last valuation of $290 million, which was set when the five-year-old company raised a $52 million Series B earlier this year. The tie-up makes strategic sense. The output of code generated by AI is often buggy, forcing engineers to spend a lot of time on corrections. Even though Cursor offers AI-powered code review through its Bugbot product, Graphite’s specialized toolset provides a distinct capability called a “stacked pull request,” which enables developers to work on multiple dependent changes simultaneously without waiting for approvals. Combining AI-powered code writing with AI-powered code review tools speeds up the process from drafting code to shipping it. Other startups providing AI-powered code review include CodeRabbit, valued at $550 million in September, and a smaller competitor, Greptile, which announced a $25 million Series A this fall. Michael Truell, co-founder and CEO of Cursor, first met Graphite’s co-founders, Merrill Lutsky, Greg Foster, and Tomas Reimers, before launching the company as a Neo Scholar, a prestigious program for college students run by Neo, Ali Partovi’s early-stage venture firm. Neo backed Graphite at the seed stage, according to PitchBook data. Furthermore, both Cursor and Graphite have other investors in common, including Accel and Andreessen Horowitz. Cursor, which was last valued at $29 billion in November, has been on an acquisition spree. Last month, it purchased Growth by Design, a tech recruiting strategy company. In July, Cursor scooped up the talent from AI-powered CRM startup Koala for a post-money valuation of $129 million, according to PitchBook. "
"Yann LeCun confirms his new ‘world model’ startup, reportedly seeks $5B+ valuation",https://techcrunch.com/2025/12/19/yann-lecun-confirms-his-new-world-model-startup-reportedly-seeks-5b-valuation/,"Renowned AI scientist Yann LeCun confirmed on Thursday that he had launched a new startup — the worst-kept secret in the tech world — though he said he will not be running the new company as its CEO. His startup is called Advanced Machine Intelligence (AMI) and has hired Alex LeBrun, co-founder and CEO of medical transcription AI startup darling Nabla, as its CEO. Nabla disclosed LeBrun’s new job in a press release and LeCun confirmed it in a brief post on LinkedIn. “Yes, AMI Labs is my new startup. I’m the Executive Chairman. And Alex LeBrun is transitioning from CEO of Nabla to CEO of AMI Labs!” LeCun wrote. AMI Labs is also reportedly seeking to raise €500 million (about $586 million) at a €3 billion valuation (about $3.5 billion) right out of the gate, before even launching, the Financial Times reported, citing people familiar with the dealmaking. Given the kind of money that VCs are throwing at AI startups founded by world-recognized AI scientists these days, that’s not even an comparatively outrageous ask. For instance, former OpenAI CTO Mira Murati’s startup, Thinking Machines Lab, was valued at $12 billion for its seed round last year. And Murati doesn’t have the same kind of street cred as LeCun. LeCun, a professor at New York University who was formerly VP and Chief AI Scientist at Meta, won the prestigious A.M. Turing Award, for his work on reinforcement learning. The press release also confirms what everyone knew as well: that AMI Labs is working on world model AI. This is an alternative to LLMs where the AI attempts to understand its environment (aka the world) so it can simulate cause-and-effect and what-if scenarios to predict outcomes. World model creators believe it’s the answer to LLMs’ structural hallucination problems. LLMs can’t be trusted to never fabricate info because it is their very nature to be “non-deterministic” — that is, creative. Top labs and startups like Google DeepMind and Fei-Fei Li’s startup, World Labs, are also developing world models. By that comparison, the fundraising aspirations of AMI might appear a bit more audacious. When World Labs debuted, Li raised $230 million at a $1 billion valuation right out of the gate, which was considered a lot at the time. But that was way back in August 2024, or about 100 AI years ago. Meanwhile, Nabla says the company will be searching for a new CEO and will be, for now, run by its co-founder and COO, Delphine Groll, who has not been handed the reins permanently yet. Nabla also says it has signed a partnership to use AMI’s models as they are developed. Nabla has raised $120 million in total from an all-star list of backers, including a $70 million Series C in June. LeCun is one of Nabla’s investors, as is Tony Fadell’s Build Collective, HV Capital, Highland Europe, and Cathay Innovation. Nabla’s LeBrun could be a good choice for CEO. He’s been building multimodal AI since before anyone called it that, working at Nuance Communications in the early 2010s, which originally powered Apple’s Siri in those long-ago years when Siri was wow technology. (Microsoft eventually acquired Nuance.) He founded and sold a couple of natural language startups, including one to Facebook. Then he ran Facebook’s AI division before founding Nabla in 2018, according to his LinkedIn. LeBrun said that Nabla, a darling of the Paris-based AI startup community, is still growing well. “We have more than tripled our live ARR this year. Up next to $1B!” LeBrun wrote as he announced his departure as CEO. The founder says he will remain on at Nabla as chairman and chief AI scientist. Nabla declined further comment and AMI did not immediately respond to our request for comment. "
"Hardware’s brutal week: iRobot, Luminar, and Rad Power go bankrupt",https://techcrunch.com/podcast/hardwares-brutal-week-irobot-luminar-and-rad-power-go-bankrupt/,"The hardware world had a brutal week, with iRobot, Luminar, and Rad Power Bikes all filing for bankruptcy.  Each company faces its own mix of tariff pressures, supply chain issues, and shifting markets, but together they tell a larger story about the challenges of building physical products in an era of global trade tensions and cheap overseas competition. From the Roomba maker that almost got acquired by Amazon to the e-bike company that couldn’t escape its Chinese supply chain, this week’s bankruptcies are a warning sign for hardware startups everywhere.  Today on TechCrunch’s Equity podcast, hosts Anthony Ha, Rebecca Bellan, and Sean O’Kane discuss what went wrong for three once-promising hardware companies, plus Amazon’s massive OpenAI bet and Trump’s new approach to AI regulation.  Listen to the full episode to hear more news from the week, including:  Subscribe to Equity on YouTube, Apple Podcasts, Overcast, Spotify and all the casts. You also can follow Equity on X and Threads, at @EquityPod. "
OpenAI adds new teen safety rules to ChatGPT as lawmakers weigh AI standards for minors,https://techcrunch.com/2025/12/19/openai-adds-new-teen-safety-rules-to-models-as-lawmakers-weigh-ai-standards-for-minors/,"In its latest effort to address growing concerns about AI’s impact on young people, OpenAI on Thursday updated its guidelines for how its AI models should behave with users under 18, and published new AI literacy resources for teens and parents. Still, questions remain about how consistently such policies will translate into practice.  The updates come as the AI industry generally, and OpenAI in particular, faces increased scrutiny from policymakers, educators, and child-safety advocates after several teenagers allegedly died by suicide after prolonged conversations with AI chatbots.  Gen Z, which includes those born between 1997 and 2012, are the most active users of OpenAI’s chatbot. And following OpenAI’s recent deal with Disney, more young people may flock to the platform, which lets you do everything from ask for help with homework to generate images and videos on thousands of topics. Last week, 42 state attorneys general signed a letter to Big Tech companies, urging them to implement safeguards on AI chatbots to protect children and vulnerable people. And as the Trump administration works out what the federal standard on AI regulation might look like, policymakers like Sen. Josh Hawley (R-MO) have introduced legislation that would ban minors from interacting with AI chatbots altogether.  OpenAI’s updated Model Spec, which lays out behavior guidelines for its large language models, builds on existing specifications that prohibit the models from generating sexual content involving minors, or encouraging self-harm, delusions, or mania. This would work together with an upcoming age-prediction model that would identify when an account belongs to a minor and automatically roll out teen safeguards.  Compared with adult users, the models are subject to stricter rules when a teenager is using them. Models are instructed to avoid immersive romantic roleplay, first-person intimacy, and first-person sexual or violent roleplay, even when it’s non-graphic. The specification also calls for extra caution around subjects like body image and disordered eating behaviors, and instructs the models to prioritize communicating about safety over autonomy when harm is involved and avoid advice that would help teens conceal unsafe behavior from caregivers.  OpenAI specifies that these limits should hold even when prompts are framed as “fictional, hypothetical, historical, or educational” — common tactics that rely on role-play or edge-case scenarios in order to get an AI model to deviate from its guidelines.  OpenAI says the key safety practices for teens are underpinned by four principles that guide the models’ approach:  The document also shares several examples of the chatbot explaining why it can’t “roleplay as your girlfriend” or “help with extreme appearance changes or risky shortcuts.”  Lily Li, a privacy and AI lawyer and founder of Metaverse Law, said it was encouraging to see OpenAI take steps to have its chatbot decline to engage in such behavior.  Explaining that one of the biggest complaints advocates and parents have about chatbots is that they relentlessly promote ongoing engagement in a way that can be addictive for teens, she said: “I am very happy to see OpenAI say, in some of these responses, we can’t answer your question. The more we see that, I think that would break the cycle that would lead to a lot of inappropriate conduct or self-harm.” That said, examples are just that: cherry-picked instances of how OpenAI’s safety team would like the models to behave. Sycophancy, or an AI chatbot’s tendency to be overly agreeable with the user, has been listed as a prohibited behavior in previous versions of the Model Spec, but ChatGPT still engaged in that behavior anyway. That was particularly true with GPT-4o, a model that has been associated with several instances of what experts are calling “AI psychosis.” Robbie Torney, senior director of AI programs at Common Sense Media, a nonprofit dedicated to protecting kids in the digital world, raised concerns about potential conflicts within the Model Spec’s under-18 guidelines. He highlighted tensions between safety-focused provisions and the “no topic is off limits” principle, which directs models to address any topic regardless of sensitivity.  “We have to understand how the different parts of the spec fit together,” he said, noting that certain sections may push systems toward engagement over safety. His organization’s testing revealed that ChatGPT often mirrors users’ energy, sometimes resulting in responses that aren’t contextually appropriate or aligned with user safety, he said. In the case of Adam Raine, a teenager who died by suicide after months of dialogue with ChatGPT, the chatbot engaged in such mirroring, their conversations show. That case also brought to light how OpenAI’s moderation API failed to prevent unsafe and harmful interactions despite flagging more than 1,000 instances of ChatGPT mentioning suicide and 377 messages containing self-harm content. But that wasn’t enough to stop Adam from continuing his conversations with ChatGPT.  In an interview with TechCrunch in September, former OpenAI safety researcher Steven Adler said this was because, historically, OpenAI had run classifiers (the automated systems that label and flag content) in bulk after the fact, not in real time, so they didn’t properly gate the user’s interaction with ChatGPT.  OpenAI now uses automated classifiers to assess text, image, and audio content in real time, according to the firm’s updated parental controls document. The systems are designed to detect and block content related to child sexual abuse material, filter sensitive topics, and identify self-harm. If the system flags a prompt that suggests a serious safety concern, a small team of trained people will review the flagged content to determine if there are signs of “acute distress,” and may notify a parent. Torney applauded OpenAI’s recent steps toward safety, including its transparency in publishing guidelines for users under 18 years old.  “Not all companies are publishing their policy guidelines in the same way,” Torney said, pointing to Meta’s leaked guidelines, which showed that the firm let its chatbots engage in sensual and romantic conversations with children. “This is an example of the type of transparency that can support safety researchers and the general public in understanding how these models actually function and how they’re supposed to function.” Ultimately, though, it is the actual behavior of an AI system that matters, Adler told TechCrunch on Thursday.  “I appreciate OpenAI being thoughtful about intended behavior, but unless the company measures the actual behaviors, intentions are ultimately just words,” he said. Put differently: What’s missing from this announcement is evidence that ChatGPT actually follows the guidelines set out in the Model Spec.  Experts say with these guidelines, OpenAI appears poised to get ahead of certain legislation, like California’s SB 243, a recently signed bill regulating AI companion chatbots that goes into effect in 2027.  The Model Spec’s new language language mirrors some of the law’s main requirements around prohibiting chatbots from engaging in conversations around suicidal ideation, self-harm, or sexually explicit content. The bill also requires platforms to provide alerts every three hours to minors reminding them they are speaking to a chatbot, not a real person, and they should take a break.  When asked how often ChatGPT would remind teens that they’re talking to a chatbot and ask them to take a break, an OpenAI spokesperson did not share details, saying only that the company trains its models to represent themselves as AI and remind users of that, and that it implements break reminders during “long sessions.” The company also shared two new AI literacy resources for parents and families. The tips include conversation starters and guidance to help parents talk to teens about what AI can and can’t do, build critical thinking, set healthy boundaries, and navigate sensitive topics.  Taken together, the documents formalize an approach that shares responsibility with caretakers: OpenAI spells out what the models should do, and offers families a framework for supervising how it’s used.  The focus on parental responsibility is notable because it mirrors Silicon Valley talking points. In its recommendations for federal AI regulation posted this week, VC firm Andreessen Horowitz suggested more disclosure requirements for child safety, rather than restrictive requirements, and weighted the onus more toward parental responsibility. Several of OpenAI’s principles — safety-first when values conflict; nudging users toward real-world support; reinforcing that the chatbot isn’t a person — are being articulated as teen guardrails. But several adults have died by suicide and suffered life-threatening delusions, which invites an obvious follow-up: Should those defaults apply across the board, or does OpenAI see them as trade-offs it’s only willing to enforce when minors are involved? An OpenAI spokesperson countered that the firm’s safety approach is designed to protect all users, saying the Model Spec is just one component of a multi-layered strategy.   Li says it has been a “bit of a wild west” so far regarding the legal requirements and tech companies’ intentions. But she feels laws like SB 243, which requires tech companies to disclose their safeguards publicly, will change the paradigm.  “The legal risks will show up now for companies if they advertise that they have these safeguards and mechanisms in place on their website, but then don’t follow through with incorporating these safeguards,” Li said. “Because then, from a plaintiff’s point of view, you’re not just looking at the standard litigation or legal complaints; you’re also looking at potential unfair, deceptive advertising complaints.” "
Known uses voice AI to help you go on more in-person dates,https://techcrunch.com/2025/12/19/known-uses-voice-ai-to-help-you-go-on-more-in-person-dates/,"Celeste Amadon and Asher Allen were working on an app that used AI to book restaurants for dates when they stumbled on a bigger idea that encourages people to meet in person. And now it’s catching on with investors. The duo created a voice-powered AI onboarding system for their app that helped them learn more about users without them having to fill out a form. What they discovered: People loved to talk, and that increased the length of the onboarding session with the app clocking 26 minutes on average. That is how San Francisco-based dating startup Known was born.  “Our take is that for the first time, we could know enough about somebody to serve them a date that would make sense. And if we could do that much faster with less rejection rate, we could create a user experience that could get people out on more dates,” she said. And early results suggested they were on to something.  In its test phase in San Francisco, Known said it observed 80% of its introductions led to in-person dates, which is much higher than swipe-based dating apps. Buoyed by these signals, the startup has raised $9.7 million from investors, including Forerunner and NFX, along with Pear VC and Coelius Capital. Notably, this is the first dating app investment for Forerunner. “Celeste is a really thoughtful founder who understands the mindset of the consumer, which is a young female, to be honest. There are other people who can be focused on the male demographic, but she is focused on the young female who has a lot of unspoken desires and needs that, if you put them in a profile, they would never say, this versus that. And I think in a conversation, you can get a lot of those nuances out, but in the past, the conversation required a $10,000 matchmaker,” Eurie Kim, a partner at Forerunner, told TechCrunch. Amadon said she has always been very interested in social impact at scale and thinks dating is inherently one of the biggest problems facing her generation.  “There’ve been a million pieces written about the loneliness epidemic in the U.S. And I do really think that it’s our generation’s largest problem,” said Amadon, who, along with Allen, dropped out of Stanford to build the startup.  The app, which is being testedin San Francisco in beta, uses voice AI-powered onboarding to ask several questions to users without having them fill out any forms. Amadon said because of this modality, the startup is able to know more about users and provide them with great matches, with one user’s onboarding clocking in at an hour and 38 minutes.  According to Known, when people typed their responses out, they would edit them. With voice, the onboarding is more personable. The company’s AI can ask dynamic follow-ups based on the conversation. For instance, if someone has newly moved to the city, the AI can ask them what they like and dislike about their experience thus far. Once the onboarding is complete, the AI suggests potential matches to users. They can ask AI agents about those profiles. If they like a profile, they can tap on “interested.” When two people are matched, they have 24 hours to accept the introduction and 24 hours to agree to a date. The company said that with this mechanism, the app aims to avoid lingering chats and ghosting while encouraging people to meet in real life. After their dates, users can provide their feedback to the AI and get more refined recommendations for matches. Known hasn’t completely ditched the restaurant idea. The app also helps in picking restaurants based on user likes and dislikes. Using the AI chat and calendar integrations, users can also indicate their availability for the first dates. In the beta phase, the company charged $30 per successful date. However, the startup is not set on the price and said it will experiment with different models to find out what payment modality works the best. Today the startup has three full-time engineers and four people working on go-to-market, with several contractors working in all areas. Amadon, whose previous experience includes internships in politics, and Allen, who worked on product at the AI-powered online shopping app Phia, plan to bolster headcount with this funding.  Known is currently testing in San Francisco and plans to launch early next year. There are several other new startups, including Overtone, Hinge CEO Justin McLeod’s new app, that are trying to use AI to know more about users and try to find matches for them. Some of them claim to bring bespoke services of matchmakers that cost thousands of dollars at a fraction of the cost. Incumbents like Tinder, Bumble, and Hinge are also pushing AI features to keep their user base engaged. Despite the growing number of startups, Amadon welcomes the competition. “When it comes to other startup dating products, I’ve been so happy to see a lot of people building in the space because I think it shows that it’s time to shift away from a swipe-based model. And I think most of them that I’ve seen have been pretty different from what we’re building at Known,” she said."
"Meta is developing a new image and video model for a 2026 release, report says",https://techcrunch.com/2025/12/19/meta-is-developing-a-new-image-and-video-model-for-a-2026-release-report-says/,"It’s all hands on deck at Meta, as the company develops new AI models under its superintelligence lab led by Scale AI co-founder, Alexandr Wang. The company is now working on an image and video model codenamed “Mango” along with a new text-based model internally known as “Avocado,” The Wall Street Journal reported. The tech giant plans to release the new models in the first half of 2026, the publication said, citing an internal Q&A at Meta on Thursday, where Wang and chief product officer Chris Cox unveiled the new roadmap. Wang had said Meta aims to make the text-based model better at coding while also exploring new world models that understand visual information and can reason, plan, and act without needing to be trained on every possibility. Meta has more recently fallen behind its rivals, like OpenAI, Anthropic, and Google, in the AI race. The company’s AI division saw significant restructurings this year, which included leadership changes and the poaching of researchers from other top companies. However, several of the researchers who joined Meta Superintelligence Labs (MSL) have already left the company. Last month, the company’s chief AI scientist, Yann LeCun, also announced that he’s leaving to create his own startup. Meta doesn’t have a winning AI product as of yet. Instead, Meta AI assistant’s numbers are buoyed by the company’s existing social networks spanning billions of users, since the company places the assistant in the search bar of its apps. This means the first projects and models coming out of MSL will have a lot riding on them."
OpenAI is reportedly trying to raise $100B at an $830B valuation,https://techcrunch.com/2025/12/19/openai-is-reportedly-trying-to-raise-100b-at-an-830b-valuation/,"OpenAI is in talks to raise up to $100 billion in a funding round that could value the ChatGPT maker at up to $830 billion, The Wall Street Journal reported Thursday, citing anonymous sources. The company is aiming to raise the funding by the end of the calendar first quarter next year, and it may ask sovereign wealth funds to invest in the round, the WSJ reported. The Information first reported news of the deal, though it said the fundraise would land OpenAI a $750 billion price tag. The funding would come as OpenAI commits to spend trillions of dollars and strikes deals around the world as the company tries to stay ahead in the race to develop AI technology. The cash injection would also help the company with its spending on inferencing, which seems to be funded more by cash than cloud credits, suggesting the company’s compute costs have grown beyond what partnerships and credits can subsidize. And, as competition intensifies from rivals like Anthropic and Google, OpenAI has had to step on the gas to release new models and expand its presence in the developer and tooling ecosystem. Meanwhile, broader sentiment around AI has recently cooled as investors start doubting whether the pace of debt-fueled investment by giants like Amazon, Microsoft, Oracle, and OpenAI itself can be maintained in the long run. It also doesn’t help that the production of chips is being constrained by shortages in the supply of memory chips, which threatens to affect the broader tech sector. OpenAI has also been rumored to be working on an IPO as a way to raise tens of billions and fund its development efforts, which are currently said to be generating annual run-rate revenue of about $20 billion. There are also rumors that the company is courting Amazon for a $10 billion investment that would also give the AI lab access to the tech giant’s new AI computing chips. If the fundraise happens, it would add a substantial amount to OpenAI’s coffers, which currently have more than $64 billion, according to PitchBook data. The company was most recently valued at about $500 billion in a secondary transaction. OpenAI did not immediately return a request for comment.  "
"From Roombas to e-bikes, why are hardware startups going bankrupt? ",https://techcrunch.com/video/from-roombas-to-e-bikes-why-are-hardware-startups-going-bankrupt/," The hardware world had a brutal week, with iRobot, Luminar, and Rad Power Bikes all filing for bankruptcy.  Each company faces its own mix of tariff pressures, supply chain issues, and shifting markets, but together they tell a larger story about the challenges of building physical products in an era of global trade tensions and cheap overseas competition. From the Roomba maker that almost got acquired by Amazon to the e-bike company that couldn’t escape its Chinese supply chain, this week’s bankruptcies are a warning sign for hardware startups everywhere.  Today on TechCrunch’s Equity podcast, hosts Anthony Ha, Rebecca Bellan, and Sean O’Kane discuss what went wrong for three once-promising hardware companies, plus Amazon’s massive OpenAI bet and Trump’s new approach to AI regulation.  Subscribe to Equity on YouTube, Apple Podcasts, Overcast, Spotify and all the casts. You also can follow Equity on X and Threads, at @EquityPod. "
"ChatGPT launches an app store, lets developers know it’s open for business",https://techcrunch.com/2025/12/18/chatgpt-launches-an-app-store-lets-developers-know-its-open-for-business/,"App developers looking to launch their programs in ChatGPT can now submit them for review and potential publication, OpenAI said Wednesday. The company also introduced a new app directory within Chat’s tools menu that has swiftly been dubbed an “app store.”  In October, the company announced the arrival of apps in its chatbot, explaining that the move would bring a broader suite of capabilities to ChatGPT users. Major platforms — including Expedia, Spotify, Zillow, and Canva — announced integrations that would allow users to access their services directly from Chat conversations. Now, the company is opening up the field to a broader array of players. “Apps extend ChatGPT conversations by bringing in new context and letting users take actions like order groceries, turn an outline into a slide deck, or search for an apartment,” the company said Wednesday. OpenAI’s Apps SDK, which is still in beta, currently provides a toolkit for developers looking to create new experiences for ChatGPT users. Once developers are ready, they can submit their apps to the company’s OpenAI Developer platform, where they will be able to track its approval status, the company said. A number of approved apps will start launching within Chat in the coming year, it added.  This is a big step for OpenAI toward expanding the app ecosystem within Chat and, at the same time, giving users more reasons to use the app and stay on it. "
Pickle Robot adds Tesla veteran as first CFO,https://techcrunch.com/2025/12/18/pickle-robot-adds-tesla-veteran-as-first-cfo/,"Pickle Robot, which builds autonomous unloading robots for warehouses and distribution centers, announced a new chief financial officer just days after a report of a major deal with UPS. The Charlestown, Massachusetts-based company announced that it hired Jeff Evanson as its CFO on Thursday. Evanson had been consulting for the company since September and recently joined full time. Evanson previously served as the vice president of global investor relations and strategy at Tesla from 2011 to 2017. In that role, he worked directly with Elon Musk and helped the company raise debt and equity financing to support the launch of multiple Tesla vehicle lines and company acquisitions. Evanson will be Pickle’s first CFO and joins as the company — founded in 2018 with around $100 million in venture capital raised — reportedly expands its partnership with shipping giant UPS. According to Bloomberg, UPS is investing $120 million to purchase 400 of Pickle’s robots, with deployment beginning in late 2026 and early 2027. Pickle declined to comment on this week’s UPS news. A Pickle spokesperson did confirm that UPS has been a Pickle customer for a few years but wouldn’t confirm when the partnership started."
Why British politicians are flocking to American tech giants,https://techcrunch.com/2025/12/18/why-british-politicians-are-flocking-to-american-tech-giants/,"The AI talent wars show no signs of slowing, with companies making headlines weekly for their latest high-profile hires. This includes engineers they are poaching from each other or acqui-hiring but also, increasingly, senior executives that can support them as they scale up. Less than 10 days after Slack CEO Denise Dresser became OpenAI’s chief revenue officer, former British finance minister George Osborne announced he was joining Sam Altman’s company. Shortly thereafter, the crypto exchange Coinbase separately appointed Osborne to lead its internal advisory council. The announcements drew particular attention in the U.K., where commenters noted that Osborne joins a growing list of former British politicians now working for major U.S. tech companies. If you’re not familiar with him or this trend, here’s what you need to know. A former conservative Member of Parliament, George Osborne served as chancellor of the Exchequer from 2010 to 2016 — a role equivalent to that of a finance minister or treasury secretary in other countries, and currently held by Rachel Reeves. After Prime Minister David Cameron resigned following the 2016 Brexit vote, Osborne eventually left public office in 2017. Alongside multiple other engagements, including a part-time advisory role for the investment firm BlackRock, he served as editor of the Evening Standard from 2017 to 2020. During that period, he also co-founded a VC firm, 9yards Capital, with his brother Theo and Theo’s brother-in-law David Fisher as co-founders and managing partners. Several companies in 9yards’ portfolio have gone public since then — including Robinhood, Toast, and Coinbase.  Osborne announced on X that he was joining OpenAI “as managing director and head of OpenAI for [C]ountries, based here in London.” He will help expand existing partnerships and build new ones, OpenAI chief global affairs officer Chris Lehane wrote on LinkedIn. Introduced in May 2025, OpenAI for Countries is an initiative through which the AI company partners with governments looking to build in-country data center capacity and localize ChatGPT for their language and culture. OpenAI for Countries is an extension of the Stargate project, a $500 billion initiative through which OpenAI is currently building five new data centers across the U.S. with Oracle and SoftBank. But beyond infrastructure, its stated goal is to “support countries around the world that would prefer to build on democratic AI rails.” As OpenAI turns 10, it is only natural that it starts hiring the kind of talent that won’t get turned down at the Ritz for wearing sport shoes. An Oxford graduate and the son of a baronet, Osborne fits the bill — but his network and reach are even more valuable, and his podcast with former Labour shadow chancellor Ed Balls, called “Political Currency,” underscores his extensive political connections. His track record and contacts could be even more directly relevant for Coinbase, which he was already advising and where he will now “play a much more active role in helping us with policymakers around the world,” the company’s chief policy officer Faryar Shirzad told Reuters. Staying on the right side of regulators is particularly important for crypto exchanges such as Coinbase, which has been making efforts to influence governments in the U.S. and beyond. But this is also critical for OpenAI, which intends to weigh in as AI gains a foothold in governments’ agendas. According to Lehane’s LinkedIn post, Osborne’s decision to take the role “reflects a shared belief that AI is becoming critical infrastructure — and early decisions about how it’s built, governed, and deployed will shape economics and geopolitics for years to come.” Osborne’s latest role immediately drew parallels with other high-profile British politicians who went on to join major U.S. tech companies.  These include former U.K. deputy Prime Minister and Liberal Democrat leader Nick Clegg, who served as Meta’s policy chief for over six years, and, more recently, former Prime Minister Rishi Sunak taking on advisory roles with Microsoft and AI firm Anthropic. This trend raises different concerns depending on your perspective. Some critics worry about active Members of Parliament like Sunak potentially advocating for U.S. corporate interests while still serving in government. Others take issue with former officials like Osborne leveraging their government experience and connections to secure highly lucrative private sector positions. The “revolving door” phenomenon between government and the private sector isn’t new. But the practice has attracted heightened scrutiny in Europe, especially when controversial foreign companies — whether tech firms or retailers like Shein — hire former government officials to help navigate regulations and influence policy. Seen from the other side, this is simply a matter of leveraging skills and experience. In his bio on 9yards’ team page, the VC firm touts that “George devised many regulations that positioned the U.K. as a global fintech leader, including the open banking regime and the FCA ‘sandbox.’” Others, however, view Osborne’s career moves more critically. They point to his controversial austerity policies as chancellor, and note that he has a history of ethics concerns around the revolving door. For example, when he took the Evening Standard editor job in 2017, he failed to seek approval from the government’s ethics watchdog first — a move that led to the body being criticized as “toothless.” His attitude at the time was telling: “At the age of 45, I don’t want to spend the rest of my life just being an ex-chancellor,” Osborne declared. Either way, that mindset — transitioning quickly from public service to high-paying private roles — is precisely what makes his OpenAI and Coinbase appointments part of a broader pattern that concerns ethics watchdogs today."
ChatGPT’s mobile app hits new milestone of $3B in consumer spending,https://techcrunch.com/2025/12/18/chatgpts-mobile-app-hits-new-milestone-of-3b-in-consumer-spending/,"ChatGPT has hit a new milestone of $3 billion in worldwide consumer spending on mobile as of this week, according to estimates from app intelligence provider Appfigures. This figure represents the total spending on iOS and Android devices since the app’s launch in May 2023, when it first arrived, then only on iOS. What’s notable is that the bulk of that spending took place this year. Worldwide, consumers spent an estimated $2.48 billion in the ChatGPT mobile app in 2025, representing a 408% year-over-year increase from the $487 million spent in 2024. In 2023, the app’s first year of availability, it earned $42.9 million, before growing 1,036% to reach the 2024 figure. These numbers represent a sharp rise in consumer adoption, compared with other popular apps. For instance, it took ChatGPT 31 months to reach $3 billion in consumer spending, but the top earner, TikTok, took 58 months to do so, Appfigures told TechCrunch. ChatGPT also reached the milestone faster than top streaming apps like Disney+ and HBO Max, which hit the $3 billion figure in 42 months and 46 months, respectively. xAI’s Grok, however, is seeing a similar revenue trajectory to ChatGPT, compared with other AI rivals. Grok was released in late 2023 to X Premium Plus subscribers before becoming more broadly available last year. But if you compare the pace of consumer spending across AI apps, Grok came the closest to matching ChatGPT’s cumulative revenue at the same point, once it began monetizing. (You can see this on the chart below, which plots the AI apps’ spending aligned to when each app began monetizing.) While the $3 billion in spending represents a significant uptake by consumers, it’s not the only way to measure AI app adoption or potential long-term revenue. ChatGPT’s mobile customers are buying paid subscriptions, like the $20 per month ChatGPT Plus or the $200 per month ChatGPT Pro for advanced users. But AI apps can generate revenue in other ways, including through developer offerings and, perhaps soon for ChatGPT, ads. In addition, ChatGPT on Wednesday launched its own app store of sorts, which the company suggests will be monetized in some way in the future, its blog post noted. Google, meanwhile, is exploring the potential to transition its healthy search ads business to AI-powered search, placing ads in AI Mode, AI Overviews, AI shopping, and an increasingly AI-powered Discover page, among other things. Anthropic is aiming at the business market and is reportedly on track for $70 billion in revenue by 2028. "
Peripheral Labs taps into self-driving car sensors to bring sports fans right into the game,https://techcrunch.com/2025/12/18/peripheral-labs-taps-into-self-driving-car-sensors-to-bring-sports-fans-right-into-the-game/,"Multiple reports suggest that live sports viewing has declined for certain sports, especially among Gen Z. To solve this, leagues and broadcasters are trying to make sports more engaging for fans with different kinds of viewing experiences, stats, and analysis. One way to do this is using volumetric video generation that lets users view the play from various angles, giving an inside-the-video-game experience. The core technology uses numerous cameras to capture the footage in 3D for everyone to look at it from various viewpoints. Canada-based Peripheral Labs wants to make this technology affordable for leagues and teams so it can reach more broadcasters and fans. Peripheral Labs was founded by Kelvin Cui and Mustafa Khan in 2024. Both have worked on driverless cars for the University of Toronto’s team, winning several trophies. Khan has worked as a researcher at Huawei, and Cui has experience working on chassis systems as a software engineer at Tesla. “Both Mustafa and I are huge sports fans. He has been a massive Arsenal fan, and I grew up watching the Vancouver Canucks since I was seven. When Mustafa showed me his research about 3D reconstruction, my brain said it would be cool to watch hockey like this [in a free-flowing, multi-angle way]. This is how we started on Peripheral Labs,” Cui said in a call with TechCrunch. The company said the idea of volumetric generation isn’t new. But with the new AI models and advances in computer vision, its founders are confident the technology is ready for the masses. The duo is using their experience with self-driving cars to apply concepts of robotics perception and 3D vision for the 3D reconstruction of video in sports. This system can reduce the camera requirement from over 100 to as few as 32, helping decrease cost and operational overhead, according to Cui and Khan. The startup aims to keep the hardware cost as minimal as possible for teams and broadcasters and sign multi-year contracts for its platform. The software platform will bring biomechanical data of players and stats for teams and leagues using its own sensor stack, which is similar to the sensors on self-driving cars that capture the scene with depth. It will enable new ways to control the viewing of the play for broadcasters and fans using photorealistic 3D reconstruction technology. For instance, if fans wanted to track only the player with the ball, they could do that. They can also freeze a moment in-game to see different angles for a foul or a critical moment in play. “While we work with off-the-shelf cameras, the way we package it with our experience in robotics and ML is what gives us an edge both in terms of platforms and also scaling from small practice enclosures to big soccer and football stadiums,” Cui said. On the software side, the platform said it can observe different joints, including finger movements of players, to measure flexion. For instance, in the video above of two people playing football (soccer), the system measures flexion of knees and ankles. This could give coaches more ideas about body positioning and the flexibility of a player, and help them improve. The startup has raised a $3.6 million seed round led by Khosla Ventures, with participation from Daybreak Capital, Entrepreneurs First, and Transpose Platform. Joe Ros, a partner at Entrepreneurs First, noted the fund was surprised by how big a following the founders and their autonomous driving team have at the University of Toronto. He noted investors are often hesitant to invest in sports-related startups, but Peripheral Labs is also an entertainment play. “Their ultimate viewer is the consumer, and their demand for sports content is evergreen, not cyclical. With Peripheral, the new standard for that consumption will be immersive, volumetric video. And the work they’re doing now in sports will give them the data, tech, and deployment moat to be the only person in the market able to enable this,” he told TechCrunch over email. Peripheral Labs said the startup was selective about the VCs they were bringing in, who could help in different areas like product development and go-to-market advice. The company has 10 engineers on its staff and aims to increase headcount with a focus on platform and hardware development to reduce costs for the company, decrease the latency of the system, and also increase the resolution of 3D reconstruction. The startup hasn’t made any public announcements about the partners it is working with, but said it is in conversation with several teams and leagues in North America. The company competes with other startups like Arcturus Studios in the volumetric capture for sports. "
Luma releases a new AI model that lets users generate a video from a start  and end frame,https://techcrunch.com/2025/12/18/luma-releases-a-new-ai-model-that-lets-users-generate-a-video-from-a-start-and-end-frame/,"Luma, the a16z-backed AI video and 3D model company, released a new model called Ray3 Modify that allows users to modify existing footage by providing character reference images that preserve the performance of the original footage. Users can also provide a start and an end frame to guide the model to generate transitional footage. The company said Thursday the Ray3 Modify model solves the problems of preserving human performance while editing or generating effects using AI for creative studios. The startup said the model follows the input footage better, allowing studios to use human actors for creative or brand footage. Luma mentioned the new model retains the actor’s original motion, timing, eye line, and emotional delivery while transforming the scene. With Ray3 Modify, users can provide a character reference for transformation to the original footage and convert the human actor’s appearance into that character. This reference also allows creators to retain information like costumes, likeness, and identity across the shoot. What’s more, users can also provide start and end reference frames to create a video using the new Ray3 Modify model. This is helpful for creators in directing transitions or controlling character movements or behavior while maintaining continuity between scenes. “Generative video models are incredibly expressive but also hard to control. Today, we are excited to introduce Ray3 Modify that blends the real-world with the expressivity of AI while giving full control to creatives. This means creative teams can capture performances with a camera and then immediately modify them to be in any location imaginable, change costumes, or even go back and reshoot the scene with AI, without recreating the physical shoot,” Amit Jain, co-founder and CEO of Luma AI, said in a statement. Luma said the new model is available to users through the company’s Dream Machine platform. The company, which competes with the likes of Runway and Kling, released video modification capabilities in June 2025. The model release comes on the back of a fresh $900 million funding round, led by Saudi Arabia’s Public Investment Fund-owned AI company Humain, for the startup announced in November. Existing investors like a16z, Amplify Partners, and Matrix Partners also participated in the round. The startup is also planning to build a 2GW AI cluster in Saudi Arabia along with Humain. "
Vibe-coding startup Lovable raises $330M at a $6.6B valuation,https://techcrunch.com/2025/12/18/vibe-coding-startup-lovable-raises-330m-at-a-6-6b-valuation/,"Swedish vibe-coding startup Lovable has more than tripled its valuation in just five months. Stockholm-based Lovable on Thursday said it had raised $330 million in a Series B funding round that was led by CapitalG and Menlo Ventures, at a $6.6 billion valuation. Khosla Ventures, Salesforce Ventures, and Databricks Ventures also participated, as did other investors. This raise comes mere months after Lovable raised a $200 million Series A round that valued the company at $1.8 billion in July. One of the quickest to capitalize on the AI boom, Lovable has built a “vibe-coding” tool that lets people use text prompts to write code and build complete apps. The company launched in 2024, and has grown blazing fast: It reached the vaunted $100 million ARR milestone within eight months, and just four months later, doubled that to surpass $200 million in annual recurring revenue. The company counts major software names like Klarna, Uber, and Zendesk as customers, and claims that more than 100,000 new projects are built on its platform every day, and more than 25 million projects were created in its first year. Lovable said it would use the new funding for building deeper integrations with third-party apps, expanding its features for enterprise use-cases, and to flesh out its platform with the infrastructure needed — like databases, payments, and hosting — to build full-fledged applications and services. Lovable co-founder and CEO Anton Osika said onstage at this year’s Slush conference in Helsinki, Finland that he credits the company’s ability to scale to his decision to ignore calls from investors to relocate the company to Silicon Valley. “It was tempting, but I really resisted that,” Osika said onstage at the November conference. “I [can] sit here now and say, ‘Look, guys, you can build a global AI company from this country.’ There is more available talent if you have a strong mission, and you have a lot of urgency coming together as a group and working.” In November, the company was called out for not paying VAT, a tax that applies to most goods and services in the European Union (EU). Osika confirmed that this was true in a LinkedIn post, saying that the company would remedy the situation, and shut down comments saying taxes like this are why the EU isn’t a good home for high-growth startups. Vibe coding continues to be a hot area of investing for VCs. Cursor, another vibe-coding darling, raised $2.3 billion in November at a $29.3 billion valuation. Like Lovable, this was also the company’s second funding round of the year, seeing its valuation double between June and November. TechCrunch reached out to Lovable for any additional information. "
Amazon’s new Alexa+ feature adds conversational AI to Ring doorbells,https://techcrunch.com/2025/12/18/amazons-new-alexa-feature-adds-conversational-ai-to-ring-doorbells/,"Amazon is adding a new feature to Alexa+ that adds a conversational AI to Ring doorbells, letting users manage deliveries, turn down sales folks, and let family or friends leave a message when they are not around. Called Greetings, the feature helps Ring determine who is visiting your house based on their apparel, actions, and what they are holding, and responds accordingly. For example, if the system sees a person in a delivery uniform dropping off a package, it will respond based on your instructions. The feature adds settings that let you specify where delivery people can leave packages, and direct them toward water or snacks you might have kept out. If a delivery person needs a signature, Alexa can also ask them when they might return, and pass that message to the user. It can also handle sales reps or service vendors. You can set an instruction such as “If someone comes to the door trying to sell something, politely let them know we’re not interested.”  And if you’re busy or not home, Alexa can greet friends or family when they visit, and ask them to leave a message for you. It goes without saying that the tech presents the risk of misidentifying people and responding inappropriately — if, for example, a friend works in logistics and comes to see you after work in their delivery uniform, Ring may, via Alexa, ask them to leave a package somewhere instead of letting them leave a message. The new feature follows a controversial facial recognition feature for Ring called “Familiar Faces” that lets you create a catalog of the faces of up to 50 people who visit you regularly. Once labeled, these people will be named in the Ring app’s timeline and notifications when they visit. Amazon says Greetings uses Ring’s video descriptions to determine who the main subject in front of the camera is for generating responses, and it doesn’t identify who the person is. The feature is compatible with Ring Wired Doorbell Pro (3rd Gen) and Ring Wired Doorbell Plus (2nd Gen) and is available to users on the Ring Premium Plan who have enabled video descriptions. It is rolling out to Alexa+ Early access customers in the U.S. and Canada."
"Adobe hit with proposed class-action, accused of misusing authors’ work in AI training",https://techcrunch.com/2025/12/17/adobe-hit-with-proposed-class-action-accused-of-misusing-authors-work-in-ai-training/,"Like pretty much every other tech company in existence, Adobe has leaned heavily into AI over the past several years. The software firm has launched a number of different AI services since 2023, including Firefly — its AI-powered media-generation suite. Now, however, the company’s full-throated embrace of the technology may have led to trouble, as a new lawsuit claims it used pirated books to train one of its AI models. A proposed class-action lawsuit filed on behalf of Elizabeth Lyon, an author from Oregon, claims that Adobe used pirated versions of numerous books — including her own — to train the company’s SlimLM program. Adobe describes SlimLM as a small language model series that can be “optimized for document assistance tasks on mobile devices.” It states that SlimLM was pre-trained on SlimPajama-627B, a “deduplicated, multi-corpora, open-source dataset” released by Cerebras in June of 2023. Lyon, who has written a number of guidebooks for non-fiction writing, says that some of her works were included in a pretraining dataset that Adobe had used. Lyon’s lawsuit, which was originally reported on by Reuters, says that her writing was included in a processed subset of a manipulated dataset that was the basis of Adobe’s program: “The SlimPajama dataset was created by copying and manipulating the RedPajama dataset (including copying Books3),” the lawsuit says. “Thus, because it is a derivative copy of the RedPajama dataset, SlimPajama contains the Books3 dataset, including the copyrighted works of Plaintiff and the Class members.” “Books3” — a huge collection of 191,000 books that have been used to train GenAI systems — has been an ongoing source of legal trouble for the tech community. RedPajama has also been cited in a number of litigation cases. In September, a lawsuit against Apple claimed the company had used copyrighted material to train its Apple Intelligence model. The litigation mentioned the dataset and accused the tech company of copying protected works “without consent and without credit or compensation.” In October, a similar lawsuit against Salesforce also claimed the company had used RedPajama for training purposes.  Unfortunately for the tech industry, such lawsuits have, by now, become somewhat commonplace. AI algorithms are trained on massive datasets and, in some cases, those datasets have allegedly included pirated materials. In September, Anthropic agreed to pay $1.5 billion to a number of authors who had sued it and accused it of using pirated versions of their work to train its chatbot, Claude. The case was considered a potential turning point in the ongoing legal battles over copyrighted material in AI training data, of which there are many."
Amazon appoints longtime AWS exec Peter DeSantis to lead new AI org,https://techcrunch.com/2025/12/17/amazon-appoints-longtime-aws-exec-peter-desantis-to-lead-new-ai-org/,"Amazon CEO Andy Jassy announced in a message to staff on Wednesday that longtime AWS executive Peter DeSantis will lead a new AI-focused organization within the company. This organization will be responsible for Amazon’s AI models like Nova, as well as silicon development and quantum computing, which help make AI tools faster and more efficient. DeSantis has spent 27 years at Amazon, including eight years as an SVP for AWS, the cloud provider that powers about one-third of the internet. At AWS’s recent re:Invent event, Amazon hammered home its commitment to AI for enterprise use, so it makes sense that the company is spinning out a new team from AWS leadership. “With our Nova 2 models just launched at re:Invent, our custom silicon growing rapidly, and the advantages of optimizing across models, chips, and cloud software and infrastructure, we wanted to free Peter up to focus his energy, invention cycles, and leadership on these new areas,” Jassy wrote. Amazon’s increasing emphasis on AI comes at a time when the company is eager to strengthen its foothold in the AI race, perhaps more through investments than its own innovations. Last month, AWS announced a $50 billion investment in the U.S. government’s AI infrastructure. Amazon is also reportedly in talks to invest $10 billion in OpenAI, and has already invested $8 billion in OpenAI rival Anthropic."
"Google launches Gemini 3 Flash, makes it the default model in the Gemini app",https://techcrunch.com/2025/12/17/google-launches-gemini-3-flash-makes-it-the-default-model-in-the-gemini-app/,"Google today released its fast and cheap Gemini 3 Flash model, based on the Gemini 3 released last month, looking to steal OpenAI’s thunder. The company is also making this the default model in the Gemini app and AI mode in search. The new Flash model arrives six months after Google announced the Gemini 2.5 Flash model, offering significant improvements. On the benchmark, the Gemini 3 Flash model outperforms its predecessor by a significant margin and matches the performance of other frontier models, like Gemini 3 Pro and GPT 5.2, in some measures. For instance, it scored 33.7% without tool use on Humanity’s Last Exam benchmark, which is designed to test expertise across different domains. In comparison, Gemini 3 Pro scored 37.5%, Gemini 2.5 Flash scored 11%, and the newly released GPT-5.2 scored 34.5%. On the multimodality and reasoning benchmark MMMU-Pro, the new model outscored all competitors with an 81.2% score. Google is making Gemini 3 Flash the default model in the Gemini app globally, replacing Gemini 2.5 Flash. Users can still choose the Pro model from the model picker for math and coding questions. The company says the new model is good at identifying multimodal content and giving you an answer based on that. For instance, you can upload your pickleball short video and ask for tips; you can try drawing a sketch and have the model guess what you are drawing; or you can upload an audio recording to get analysis or generate a quiz. The company also said the model better understands the intent of users’ queries and can generate more visual answers with elements like images and tables. You can also use the new model to create app prototypes in the Gemini app using prompts. The Gemini 3 Pro is now available to everyone in the U.S. for search and more people in the U.S. can access the Nano Banana Pro image model in search, as well. Google noted that companies like JetBrains, Figma, Cursor, Harvey, and Latitude are already using the Gemini 3 Flash model, which is available through Vertex AI and Gemini Enterprise. For developers, the company is making the model available in a preview model through the API and in Antigravity, Google’s new coding tool released last month. The company said the Gemini 3 Pro scores 78% on the SWE-bench verified coding benchmark, only outperformed by GPT-5.2. It added that the model is ideal for video analysis, data extraction, and visual Q&A, and because of its speed, it is suited for quick and repeatable workflows. Model pricing is $0.50 per 1 million input tokens and $3.00 per 1 million output tokens. This is slightly more expensive than $0.30 per 1 million input tokens and $2.50 per 1 million output tokens of Gemini Flash 2.5. But Google claims that the new model outperforms the Gemini 2.5 Pro model while being three times faster. And, for thinking tasks, it uses 30% fewer tokens on average than 2.5 Pro. That means overall, you might save on the number of tokens for certain tasks. “We really position flash as more of your workhorse model. So if you look at, for example, even the input and output prices at the top of this table, Flash is just a much cheaper offering from an input and output price perspective. And so it actually allows for, for many companies, bulk tasks,” Tulsee Doshi, senior director & head of Product for Gemini Models, told TechCrunch in a briefing Since it released Gemini 3, Google has processed over 1 trillion tokens per day on its API, amid its fierce release and performance war with OpenAI. Earlier this month, Sam Altman reportedly sent an internal “Code Red” memo to the OpenAI team after ChatGPT’s traffic dipped as Google’s market share in consumers rose. Post that, OpenAI has released GPT-5.2 and a new image generation model. OpenAI also boasted about its growing enterprise use and said the ChatGPT messages volume has grown 8x since November 2024. While Google didn’t directly address the competition with OpenAI, it said that the release of new models is challenging all companies to be active. “Just about what’s happening across the industry is like all of these models are continuing to be awesome, challenge each other, push the frontier. And I think what’s also awesome is as companies are releasing these models,” Doshi said. “We’re also introducing new benchmarks and new ways of evaluating these models. And so that’s also encouraging us.”"
"Mozilla’s new CEO says AI is coming to Firefox, but will remain a choice",https://techcrunch.com/2025/12/17/mozillas-new-ceo-says-ai-is-coming-to-firefox-but-will-remain-a-choice/,"Mozilla has appointed Anthony Enzor-DeMeo as its CEO as the Firefox browser maker scrambles to adapt in a rapidly changing browser market. The appointment comes at a time when web browsers are seeing a revitalization of sorts as AI changes how people use the internet. After more than a decade of dominating the market, incumbents like Firefox, Google Chrome, and Apple’s Safari are facing a fresh challenge from companies like Perplexity, Arc, OpenAI, and Opera, which are focused on baking AI models and agents into their browsers to bring AI to users at the first point of contact with the internet: the web browser. These changes don’t seem to be lost on Mozilla, which consists of several organizations, one of which is the Mozilla Corporation, which develops Firefox and other technologies, and another of which is its nonprofit and tax-exempt Mozilla Foundation, which oversees Mozilla’s corporate governance structure and sets the browser maker’s policies. The company has had a tough time lately: It’s gone through a restructuring, and last year laid off 30% of its employees and dropped its advocacy and global programs. But the potential to make a comeback amid the modern browser wars doesn’t seem to be lost on the company. Mozilla will be investing in AI and will add AI features to Firefox, Enzor-DeMeo said in a blog post announcing his appointment. That said, Mozilla seems intent on not infuriating users who’ve chosen Firefox for its lack of AI features: Enzor-DeMeo said the company will make AI features optional within Firefox and its other products. “AI should always be a choice — something people can easily turn off. People should know why a feature works the way it does and what value they get from it,” he wrote. The company will also be investing in diversifying its revenue beyond search (in exchange for having Google as its default search engine, Mozilla makes a significant portion of its revenue from the search giant), and Enzor-DeMeo said Mozilla plans to flesh Firefox out into “a broader ecosystem of trusted software.” Currently, the company also develops the Thunderbird email client, a VPN, and last year launched an AI-powered website creator aimed at small businesses. Before this appointment, Enzor-DeMeo was general manager of Firefox, and is now taking over from interim CEO, Laura Chambers, who was in the role for the past couple of years. Enzor-DeMeo previously held product roles at Roofstock, Better, and Wayfair. "
Google’s vibe-coding tool Opal comes to Gemini,https://techcrunch.com/2025/12/17/googles-vibe-coding-tool-opal-comes-to-gemini/,"Google’s vibe-coding tool, Opal, is making its way to Gemini. The company on Wednesday said it is integrating the tool, which lets you build AI-powered mini apps, inside the Gemini web app, allowing users to create their own custom apps, which Google calls Gems. Introduced in 2024, Gems are customized versions of Gemini designed for specific tasks or scenarios. For instance, some of Google’s pre-made Gems include a learning coach, a brainstorming assistant, a career guide, a coding partner, and an editor. Opal, meanwhile, focuses on helping users create mini-apps or mix existing apps. To use the feature, users describe in natural language the app they want to make, and the tool will use the different Gemini models to create it. Now, Opal is directly available from Gemini on the web, where it’s found in the Gems manager. The tool has a visual editor that lays out the steps required to create an application. From the editor, users can rearrange steps and link them together, without writing code. Google notes that the visual editor also includes a new view in Gemini that will take the user’s written prompts and turn them into a list of steps. This makes it even easier to build apps and see how they work. For more advanced customization options, users can move from Gemini to the Advanced Editor at opal.google.com. The mini apps can be reused after they’re created. Known as “vibe-coding,” using AI to program and make apps has skyrocketed in popularity over the past couple of years. The market now has apps from startups like Lovable and Cursor, as well as offerings from AI providers like Anthropic and OpenAI. There are also tools focused more directly on consumers, like those from AI-powered app-building startup Wabi. Gemini’s web app is available at gemini.google.com."
Skana Robotics helps fleets of underwater robots communicate with each other,https://techcrunch.com/2025/12/17/skana-robotics-helps-fleets-of-underwater-robots-communicate-with-each-other/,"Underwater autonomous vessels and robots could play a substantial role in defense operations, but submersibles have historically had trouble communicating across large distances unless they rose to the surface. But coming up to transmit poses the very obvious risk of being exposed. Skana Robotics thinks it’s made a breakthrough with underwater communications using AI — but not the large language models the industry touts today. Tel Aviv-based Skana has developed a new capability for its fleet management software system, SeaSphere, that allows groups of vessels to communicate with each other underwater across long distances using AI. The system allows vessels to share data and react to what they hear from other robots. This, Skana says, gives individual units the ability to autonomously adapt to the information they receive and change their course or task while still working toward the same general mission as the fleet. The startup says its software can also be used to secure underwater infrastructure and supply chains. “Communication between vessels is one of the main challenges during the deployment of multi-domain, multi-vessel operations,” Idan Levy, the co-founder and CEO of Skana Robotics, told TechCrunch. “The problem that we tackle is how you can deploy hundreds of unmanned vessels in an operation, share data, communicate on the surface level and under the water.” Teddy Lazebnik, an AI scientist and professor at the University of Haifa in Israel, led the research to develop this new capability. Lazebnik told TechCrunch that to build this decision-making algorithm, they couldn’t turn to the latest AI technology, but had to use AI algorithms that are a bit older and more mathematically driven. “The new algorithms have two properties: they are more powerful, but as a result, are less predictable,” Lazebnik said. “Hypothetically, you’re paying in the performance or the ‘wow effect’ of the of this algorithm, but the older ones, you gain explainability, predictability, and actually generality.” Skana Robotics was founded in 2024 and exited stealth mode earlier this year. The company is currently focused on selling to governments and companies in Europe, as maritime threat levels increase due to the war between Russia and Ukraine. Levy said the company is in talks for a sizable government contract that it hopes to close by the end of the year. In 2026, Skana hopes to release the commercial version of its product and start proving its tech out in the wild. “We want to show we can use this in scale,” Lazebnik said. “We argue that our software can handle complex maneuvers, etc. We want to show it. We claim we know how to manage an operation. We want admirals from EU and in EU countries to actually check this argument and see by themselves that we actually get results.”"
Amazon reportedly in talks to invest $10B in OpenAI as circular deals stay popular,https://techcrunch.com/2025/12/17/amazon-reportedly-in-talks-to-invest-10b-in-openai-as-circular-deals-stay-popular/,"Amazon is in early discussions to invest as much as $10 billion in OpenAI in a deal that would see the AI lab using the e-commerce giant’s AI chips, CNBC reported. If it materializes, the deal would value OpenAI at more than $500 billion, Bloomberg reported, citing an anonymous source. The Information was first to report on the story. Amazon has been looking to diversify its bets in the AI race, which has so far seen it partner up with and invest $8 billion in Anthropic, a rival to OpenAI. The e-commerce giant earlier this month also unveiled the latest iteration in its Trainium series of chips, and outlined the development of the next installment of those chips, complementing its cloud computing offerings via Amazon Web Services. News of the deal comes a couple months after OpenAI completed its transition to a for-profit model, which gives it more freedom to strike deals with investors other than Microsoft, one of the company’s earliest backers with a stake of 27%. Amazon investing in OpenAI would mark the latest in a series of circular deals in the AI space — major hardware manufacturers and cloud providers strike deals with young AI companies to use their products, while the upstarts commit to using their data centers and chips for training their AI models. This past March, OpenAI invested $350 million of equity into CoreWeave, which used the funds to buy chips from its backer Nvidia. Those same chips provide compute to OpenAI, which increases CoreWeave’s revenue and in the end makes OpenAI’s stake more valuable. Then in October, OpenAI signed a deal to pick up a 10% stake in AMD and committed to using the chipmaker’s AI GPUs, and also signed a chip usage agreement with Broadcom that month. And in November, the ChatGPT maker signed a $38 billion cloud computing deal with Amazon. OpenAI and Amazon did not immediately respond to requests for comment."
"Weeks after raising $100M, investors pump another $180M into hot Indian startup MoEngage",https://techcrunch.com/2025/12/16/weeks-after-raising-100m-investors-pump-another-180m-into-hot-indian-startup-moengage/,"MoEngage, a customer engagement platform used by consumer brands across 75 countries, has announced a Series F follow-on transaction just over a month after securing $100 million, with a majority of the latest funding providing liquidity to investors and employees through secondary transactions. In the latest raise, where $180 million traded hands altogether, about $123 million was secondary, including a $15 million employee tender that provided liquidity to 259 current and former employees, while the remaining $57 million was raised as primary capital and went into the business. The round was led by ChrysCapital and Dragon Funds, with participation from Schroders Capital and existing investors TR Capital and B Capital. Early backers, including Eight Roads Ventures, Helion Venture Partners, Z47, and Ventureast, sold shares in the secondary transactions. The deal valued MoEngage at “well over” $900 million post-money, per a person close to the deal, who added that the startup was tracking toward $100 million in annualized recurring revenue this year. MoEngage did not disclose these figures. MoEngage plans to use the fresh capital to invest further in its Merlin AI suite and expand its use of AI agents to improve decision-making and efficiency for marketing teams, said Raviteja Dodda (pictured above), co-founder and chief executive, in an interview. The startup is also pushing deeper into product and engineering teams by bundling its analytics and transactional messaging tools into a broader offering, a move it expects to lift average contract values and expand its addressable market. “When you look at customer engagement, it is not necessarily focused on marketing teams. There are product and engineering teams, which also focus on how to make sense of customer behavior and data,” Dodda said. MoEngage also plans to use part of its fresh capital raise to pursue strategic acquisitions, particularly in the U.S. and Europe, targeting software companies that complement its customer engagement platform or help accelerate its expansion in those markets. It also targets small AI teams to bolster its intelligence-led offerings. The 11-year-old startup, which has its headquarters in Bengaluru and San Francisco, already gets more than 30% of its revenue from North America, about 25% from Europe and the Middle East, and the remaining 45% from India and Southeast Asia. MoEngage’s secondary-heavy structure of the raise reflects its late-stage position, allowing early investors and employees to take liquidity without forcing the company into a near-term public listing. This approach gives MoEngage flexibility to choose its next steps based on business priorities rather than investor exit timelines. “It gives us the opportunity not to have an urgency with regard to going IPO,” Dodda said, adding that the startup still aims to go public in a couple of years, depending on market conditions and other factors. MoEngage expects to turn earnings before interest, taxes, depreciation, and amortization (EBITDA) positive this quarter and is targeting compound annual growth of about 35% over the next three years, Dodda said. Bhavin Turakhia, co-founder and chief executive of fintech firm Zeta, a MoEngage customer, said the startup’s analytics and messaging tools have helped it improve onboarding, activation, and cross-sell across key customer journeys. The secondary component of the round also enabled some early investors to exit fully. Ventureast, which backed MoEngage in 2018, is one of them. The VC firm recorded a roughly 10-times return on its investment on a blended basis, its partner Vinay Rao told TechCrunch. Rao said that while many global customer engagement companies operate with cost structures geared toward the U.S. market, MoEngage has retained an India-based cost structure, which he said has helped it compete more effectively in the U.S. while scaling the business. With the latest round, MoEngage has raised about $307 million in primary funding to date. Avendus advised MoEngage for the transaction."
"DoorDash rolls out Zesty, an AI social app for discovering new restaurants",https://techcrunch.com/2025/12/16/doordash-rolls-out-zesty-an-ai-social-app-for-discovering-new-restaurants/,"DoorDash is launching a new AI-powered social app that’s designed to help users quickly find local restaurants. The app, called Zesty, is initially available in the San Francisco Bay Area and New York. With the app, DoorDash is branching out beyond food delivery and stepping into the social and discovery space. The idea behind the app is to get rid of the need to read a bunch of different reviews, look up different menus, or browse TikTok when looking for a new place to eat. Once people open the app and sign in with their DoorDash accounts, they can ask an AI chatbot for personalized recommendations based on what they’re looking for. In an Instagram promo post, the company shared that users can type prompts like, “A low-key dinner in Williamsburg that’s actually good for introverts” to find specific recommendations. Users will also see suggested prompts, such as “Brunch spots good for groups,” and “Romantic dinner with a vintage feel.” DoorDash co-founder Andy Fang wrote in an X post that the app aggregates info across DoorDash, Google Maps, TikTok, and more to “curate the best suggestions from the web.” The app also learns your tastes to figure out what you do and don’t like. Once you come across a recommendation you’re interested in, you can save it and share it with others. Users can view and share photos and comments about restaurants they’ve visited, discover content from others, and follow people just like on any social network. “At DoorDash, we’re always looking for new ways to help people connect with the best of their communities,” a DoorDash spokesperson confirmed to TechCrunch. “We’re piloting an app called Zesty to make it easier to discover great nearby restaurants, coffee shops, bars, and more through personalized search and social sharing. We’re excited to learn from early testers as we keep shaping what local discovery can look like.” News of the app’s launch was first reported by Bloomberg. Of course, some people may not want to download a whole new app to find new restaurants when they could simply use Google. For people who have already embedded AI into their daily lives, they may already be using services like ChatGPT and Gemini to discover new restaurants. However, the app could be a welcome launch for people who want to be part of a social network that’s all about discovering new restaurants. The launch of the new app marks DoorDash’s latest effort to branch beyond delivery services, as the company earlier this year launched features that allow customers to make reservations for in-person dining and earn in-store rewards."
Meta’s AI glasses can now help you hear conversations better,https://techcrunch.com/2025/12/16/metas-ai-glasses-can-now-help-you-hear-conversations-better/,"Meta announced on Tuesday an update to its AI glasses that will allow you to better hear people talking when you’re in a noisy environment. The feature will initially become available on Ray-Ban Meta and Oakley Meta HSTN smart glasses in the U.S. and Canada, the company says. In addition, the glasses are getting another update that lets you use Spotify to play a song that matches what’s in your current view. For instance, if you’re looking at an album cover, the glasses could play a song by that artist. Or if you’re looking at your Christmas tree with a pile of gifts, you could play holiday music. This addition is more of a gimmick, of course, but it demonstrates how Meta is thinking about connecting what people see with actions they can take in their apps. The conversation-focus feature, meanwhile, seems more practical. First announced at Meta’s Connect conference earlier this year, the feature uses the AI glasses’ open-ear speakers to amplify the voice of the person you’re talking to. Meta says smart glasses wearers will also be able to adjust the amplification level by swiping the right temple of their glasses, or via the device settings. This will allow them to set the level more precisely to match their current environment, whether that’s a busy restaurant or bar, club, commuter train, or anything else. How well the feature works, of course, will still need to be tested. However, the idea of using smart accessories as tools to help with hearing isn’t limited to Meta. Apple’s AirPods already offer a Conversation Boost feature designed to help you focus on the person you’re talking to, and the Pro models more recently added support for a clinical-grade Hearing Aid feature as well. While the conversation-focus feature is limited to the U.S. and Canada, the Spotify feature is offered in English in a larger number of markets, including Australia, Austria, Belgium, Brazil, Canada, Denmark, Finland, France, Germany, India, Ireland, Italy, Mexico, Norway, Spain, Sweden, the United Arab Emirates, the U.K., and the U.S. The software update (v21) will first become available to those who are enrolled in Meta’s Early Access Program, which requires first joining a waitlist and being approved. It will later roll out more broadly. "
OpenAI continues on its ‘code red’ warpath with new image generation model,https://techcrunch.com/2025/12/16/openai-continues-on-its-code-red-warpath-with-new-image-generation-model/,"OpenAI is rolling out a new version of ChatGPT Images that promises better instruction-following, more precise editing, and up to 4x faster image generation speeds. The new model, dubbed GPT Image 1.5, is available starting Tuesday to all ChatGPT users and via the API. It’s the latest escalation in the competition with Google’s Gemini after OpenAI CEO Sam Altman last month declared a “code red” in a leaked internal memo. The memo detailed OpenAI’s plans to regain its position as the AI leader after Google had begun to take market share following the release of Gemini 3, its latest flagship model, and Nano Banana Pro, the newest version of Google’s viral image generator — both of which have topped the LMArena leaderboard across multiple benchmarks.  Google maintains its lead even after OpenAI responded to its success last week with the launch of GPT-5.2, pitching it as its most advanced model yet for developers and everyday professional use. OpenAI had reportedly been planning to release a new image generator in early January, accelerating those plans with this week’s announcement. Its last image model release was GPT Image 1 in April.  GPT Image 1.5 arrives as image and video generators advance beyond prototypes and gain more production-ready capabilities. Like Nano Banana Pro, ChatGPT Image offers post-production features, providing more granular edit controls to maintain visual consistency, like facial likeness, lighting, composition, and color tone across edits.  Most GenAI image tools are bad at iteration, so this would be a huge step up. Asked for a specific change, like “adjust the facial expression” or “make lighting colder,” models will often reinterpret the entire image, leading to a lack of consistency.  The update isn’t just about new features. ChatGPT images will also now be accessible via a dedicated entry point in the ChatGPT sidebar that works “more like a creative studio,” Fidji Simo, OpenAI’s CEO of applications, wrote in a blog post Tuesday.  “The new image viewing and editing screens make it easier to create images that match your vision or get inspiration from trending prompts and preset filters,” Simo wrote. On top of the new image generator, OpenAI is introducing new ways to improve the ChatGPT experience with more visual elements. The plan is to make search queries display more visuals with clear sources, which could be helpful for tasks like converting measurements or checking sports scores, per Simo.  “When you’re creating, you should be able to see and shape the thing you’re making. When visuals tell a story better than words alone, ChatGPT should include them,” Simo wrote. “When you need a quick answer or the next step lives in another tool, it should be right there. As we do this, we can keep closing the distance between what’s in your mind and your ability to bring it to life.” pic.twitter.com/PwG1F4TT6Q"
Uber Eats alum lands $14M seed from a16z to fix WhatsApp chaos for LatAm’s doctors,https://techcrunch.com/2025/12/16/uber-eats-alum-lands-14m-seed-from-a16z-to-fix-whatsapp-chaos-for-latams-doctors/,"Caroline Merin, who spent nearly a decade developing on-demand services as the first Latin American general manager for Uber Eats and later the COO of Rappi, recognized how badly healthcare tech lagged behind. While patients expected doctors to respond as quickly as their delivery apps, most medical professionals on the continent are forced to rely on WhatsApp for all patient communication. “I thought, as a patient, especially as an American, how incredible that I can text my doctor on WhatsApp, and they’ll respond,” she told TechCrunch. But Merin also realized just how overwhelming this communication method had become for physicians. “A doctor who sees 20 patients during the day, gets home, has 100 messages and is expected to answer immediately and remember who the patient is without the health record in front of them,” she said. Merin, who had long been interested in building her own startup, saw an opportunity to improve doctors’ communication challenges. So, two years ago, she launched Leona Health, an AI-copilot integrated with doctors’ WhatsApp accounts. On Tuesday, Leona revealed that it raised $14 million in seed funding led by Andreessen Horowitz, with participation from General Catalyst; Accel; Maven Clinic CEO Kate Ryder; Nubank CEO David Vélez; and Rappi CEO Simón Borrero. The startup also announced that its service is now available to doctors in 14 Latin American countries across 22 medical specialties. With Leona, patients continue to send messages on WhatsApp, but doctors receive and manage that communication through the startup’s mobile app. The app sorts all messages in order of priority, suggests responses, and allows other team members (like doctors or nurses) to reply to patients on the doctor’s behalf. The startup will also soon launch a fully autonomous agent that will handle conversational scheduling and simple intake. Solving the WhatsApp communication challenge in Latin America is critical because, according to Merin, patients in Latin America often choose their doctors based on their willingness to communicate using this channel. “These poor doctors, they’re receiving requests for very serious medical consults to, ‘I need a letter for my kids’ school,’ or, ‘I want a receipt for my appointment last week,’” Merin said. Since these messages can arrive in the evenings and on weekends, physicians are often forced to monitor their WhatsApp around the clock. Leona solves this by immediately alerting doctors only to the most serious health requests and allowing them to deprioritize more routine or administrative questions. “The idea is to help the doctor regain time,” Merin said. “We’re hearing from our users that they’re saving two to three hours a day by using Leona.” While Leona is starting by serving Latin America, the company’s long-term mission is to expand its services to other geographies, where, unlike in the U.S., patients also demand and are permitted to communicate with their doctors via WhatsApp, rather than through electronic medical records systems like Epic. Leona’s team of 13 is currently split between Mexico City and Silicon Valley, where, according to Merin, the best AI engineers are located."
Google tests an email-based productivity assistant,https://techcrunch.com/2025/12/16/google-tests-an-email-based-productivity-assistant/,"Productivity is one space where companies keep wanting to experiment with AI assistants in the hope that they will save time for users, and as a result, they will want to use those assistants more. Google today launched one such experimental email-based assistant called CC through a Google Labs experiment. CC, which is powered by Gemini, can connect with your account, such as Gmail, Google Drive, and Google Calendar, and provide you with a daily brief via email. This “Your Day Ahead” email makes users aware of their tasks, summarizes their calendar, and provides key updates for the day from these accounts. You can also reply to or email CC at any time with requests such as adding to-dos, teaching it to your preferences, remembering notes, or searching for information. At the moment, CC is available to AI Pro and Ultra users in the U.S. and Canada who are 18 or above. The company said that the assistant is only available to consumer Google accounts at the moment and not Workspace accounts. There are several examples of AI-powered email-based briefs and assistants. Sequoia-backed Mindy, which now works in the creator and marketing space, started as an email assistant. Other meeting notetakers like Read AI and Fireflies also send users a daily brief, but they might not have context from email and Drive. Huxe, an audio app created by former Google NotebookLM makers, creates a daily brief in the form of a podcast with data from your email, calendar, and news preferences. "
Databricks raises $4B at $134B valuation as its AI business heats up,https://techcrunch.com/2025/12/16/databricks-raises-4b-at-134b-valuation-as-its-ai-business-heats-up/,"The IPO window may have cracked open, but it seems some former startups have no intention of going public. Makes sense, in a way: IPOs were traditionally a way to raise money, and if you can manage to raise ungodly amounts without having to put your company through public scrutiny, why do it? Databricks is proving that point: The data intelligence company has just raised more than $4 billion in a Series L funding round at a $134 billion valuation — up 34% from the $100 billion valuation that it achieved just three months ago. This is Databricks’ third major venture fundraise in less than a year, and it comes as the company focuses on building products that address the needs of the AI revolution: a database for AI agents, an AI agent platform, and apps that let companies build and deploy data and AI applications. The company is investing heavily in its database for AI agents, known as Lakebase, which is based on the open source database Postgres (enabled by the $1 billion acquisition of a startup called Neon), and is aimed at corporate developers’ vibe-coding projects. Meanwhile, its AI agent platform, Agent Bricks, is aimed at helping businesses build and deploy AI agents that can tap into their data. The company has also struck hefty deals worth hundreds of millions with AI labs Anthropic and OpenAI to offer their models within its enterprise products. Series L rounds aren’t really common, but the fact that Databricks has managed to raise venture funding at ever-increasing valuations (it was valued at $60 billion around this time last year) indicates how strongly investors believe in the power of helping companies use data to fuel their AI efforts. Indeed, Databricks on Tuesday said it now generates run-rate revenue of more than $4.8 billion, up 55% from a year earlier, of which more than $1 billion came from its AI products. “The parallel rise of vibe coding and generative AI is accelerating the development of data-intelligent applications in the enterprise. Databricks will use this new capital to help customers build AI apps and agents on their proprietary data, leveraging Lakebase as the system of record, Databricks Apps as the user experience layer, and Agent Bricks to power multi-agent systems,” the company said in a press release. The Wall Street Journal reports that the company will also use the new money to add thousands of new jobs in Asia, Europe, and Latin America, as well as bring on more AI researchers. “Enterprises are rapidly reimagining how they build intelligent applications, and the convergence of generative AI with new coding paradigms is opening the door to entirely new workloads,” Databricks’ co-founder and CEO Ali Ghodsi said in a statement. The round was led by Insight Partners, Fidelity, and J.P. Morgan Asset Management. Andreessen Horowitz, BlackRock, Blackstone, Coatue, GIC, MGX, NEA, Ontario Teachers Pension Plan, Robinhood Ventures, T. Rowe Price Associates, Temasek, Thrive Capital, and Winslow Capital also participated. "
"Adobe Firefly now supports prompt-based video editing, adds more third-party models",https://techcrunch.com/2025/12/16/adobe-firefly-now-supports-prompt-based-video-editing-adds-more-third-party-models/,"Adobe is updating its AI video-generation app, Firefly, with a new video editor that supports precise prompt-based edits, as well as adding new third-party models for image and video generation, including Black Forest Labs’ FLUX.2 and Topaz Astra. Until now, Firefly only supported prompt-based generation, so you would have to recreate the entire clip if any part of the video was not to your liking. With the new editor, you can use text prompts to edit video elements, colors, and camera angles, and we also get a new timeline view that lets you adjust frames, sounds, and other characteristics easily. The company first announced the new video editor in October in private beta, and now it is rolling out to all users. The company said that using Runway’s Aleph model, users can give Firefly specific instructions, such as “Change the sky to overcast and lower the contrast” or “Zoom in slightly on the main subject.” And with Adobe’s own Firefly Video model, users can now do stuff like upload a start frame and a reference video of a camera motion and tell it to recreate that camera angle for the video they’re working on. The company also said users can now use the Topaz Labs’ Astra model to upscale videos to 1080p or 4K. Black Forest Labs’ FLUX.2 image generation model is coming to the app, too, along with a collaborative boards feature. The company said FLUX.2 will be available on Firefly across platforms immediately, and Adobe Express users will be able to use FLUX.2 from January. With competitors releasing new models for image and video generation, Adobe wants to lure users into engaging with its app more. Along with new updates to the Firefly app, the company said subscribers of the Firefly Pro, Firefly Premium, 7,000-credit, and 50,000-credit plans will get unlimited generations from all image models and the Adobe Firefly Video Model in the Firefly app until January 15. Adobe has made a ton of changes to its Firefly models and apps this year. In February, the company launched a subscription that let users access various levels of image and video generation; then it launched a new Firefly web app along with mobile apps later in the year, and has added support for more third-party models within the Firefly app."
Everbloom built an AI to turn chicken feathers into cashmere,https://techcrunch.com/2025/12/16/everbloom-built-an-ai-to-turn-chicken-feathers-into-cashmere/,"Cashmere sweaters are everywhere these days, often at unbelievably low prices. The appeal is obvious: If you’ve ever worn cashmere, you know it’s soft, light, and warm — an impressive fiber that’s hard to give up. Unfortunately, those bargain prices usually come with a catch. Cashmere comes from the fine undercoat of a handful of goat breeds. Typically, one goat will be sheared twice a year, producing just four to six ounces (113 to 170 grams) of cashmere annually. That’s not a lot of supply for a growing market. “The producers of raw materials are actually under a lot of stress,” Sim Gulati, co-founder and CEO of Everbloom, told TechCrunch. “What you’re seeing now, especially with the advent of $50 cashmere sweaters, is that they’re being sheared way more often. The quality of the fiber is not as good, and it’s creating unsustainable herding practices.” Rather than try to change herding practices or convince consumers to only buy high-quality cashmere, Gulati and his team at Everbloom had a different idea. The startup, which has raised over $8 million from investors, including Hoxton Ventures and SOSV, set out to create an upcycled material that’s nearly indistinguishable from the real thing. To do this, Everbloom has created a material science AI called Braid.AI. The model can fine-tune various parameters to create fibers with different qualities. Cashmere is one target, but so are other materials widely used in the textile industry. At its core, Everbloom’s process is the same regardless of final product. To make its material, the company currently collects waste from across the fiber supply chain, including cashmere and wool farms and mills, as well as down bedding suppliers. In the future, it plans to expand to other waste sources, including feathers from the poultry industry. These waste streams share one thing in common: They’re all made of keratin, the key protein that underpins Everbloom’s process. The company then chops the waste to size and combines it with proprietary compounds. The mix is pressed through a plastic extrusion machine (which shapes material by forcing it through a die), and the pellets that come out the other end are fed through spinning machines that are normally used to produce polyester fiber. “That equipment is used for 80% of the textile market,” Gulati said. “You have to be a drop in replacement.” To transform waste into new fiber, all of the necessary chemical reactions occur within those two machines. Everbloom can create fibers that replicate everything from polyester to cashmere by using its AI to tweak the formulation and how the two machines process it. The startup said every fiber it produces should be biodegradable, even the polyester replacement.  “All the components that we’re using are biodegradable,” Gulati said, adding that his company is currently running its products through accelerated testing to prove the hypothesis. And because Everbloom uses waste products, the environmental impact will be dramatically lower, he said. Plus, it should be cheaper. “We want it to be more economically viable for brands and consumers,” Gulati said. “I don’t believe in a ‘sustainable premium’” — the idea that eco-friendly products should cost more. “In order for a material to be successful — both in the supply chain [and for] the consumer — you have to have both a product benefit and an economic benefit to everyone who touches the product. That’s what we’re aiming for.”"
VCs discuss why most consumer AI startups still lack staying power,https://techcrunch.com/2025/12/15/vcs-discuss-why-most-consumer-ai-startups-still-lack-staying-power/,"Even three years after the generative AI boom started, most AI startups are still making money by selling to businesses, not individual consumers. Although consumers quickly adopted general-purpose LLMs like ChatGPT, most specialized consumer GenAI applications have yet to resonate. “A lot of early AI applications around video, audio, and photo were super cool,” said Chi-Hua Chien, co-founder and managing partner at Goodwater Capital, onstage at TechCrunch’s StrictlyVC event in early December. “But then Sora and Nano Banana came out, and the Chinese open sourced their video models. And so, a lot of those opportunities disappeared.” Chien compares some of those applications to the simple flashlight, which was initially a popular third-party download after the iPhone launched in 2008 but was quickly integrated into iOS itself. He argued that, just as it took a few years for the smartphone platform to solidify before game-changing consumer apps emerged, AI platforms need a similar period of “stabilization” for lasting AI consumer products to flourish. “I think we’re right on the cusp of the equivalent to mobile of the 2009-2010 era,” Chien said. That period was the birth of massive mobile-first consumer businesses like Uber and Airbnb. We could be seeing inklings of that stabilization with Google’s Gemini reaching technological parity with ChatGPT, Chien said. Elizabeth Weil, founder and partner at Scribble Ventures, echoed Chien’s sentiment about the early days of GenAI, describing the current state of consumer AI applications as being in an “awkward teenage middle ground.” What will it take for consumer AI startups to grow up? Possibly a new device beyond the smartphone. “It’s unlikely that a device that you pick up 500 times a day but only sees 3% to 5% of what you see is going to be what ultimately introduces the use cases that take full advantage of AI’s capabilities,” Chien said. Weil agreed that a smartphone may be too limiting for reimagining consumer AI products in large part because it is not ambient. “I don’t think we’re going to be building for this in five years,” she said, indicating her iPhone as she showed it to the audience. Startups and incumbent tech companies have been racing to build a new personal device that can supplant smartphones. OpenAI and Apple’s former design chief, Jony Ive, are working on what’s rumored to be a “screenless,” pocket-sized device. Meta’s Ray-Ban smart glasses are controlled by a wristband that detects subtle gestures. Meanwhile, a number of startups are trying, with often disappointing results, to introduce a pin, pendant, or ring that uses AI in a way different from how smartphones do.   However, not every AI consumer product will be dependent on a new device. Chien suggested that one such offering could be a personal AI financial adviser customized to the user’s specific needs. Similarly, Weil anticipates that a personalized, “always-on” tutor will become ubiquitous, with its specialized tutelage delivered directly from a smartphone. Though excited by AI’s potential, Weil and Chien expressed skepticism about the emergence of several, still-stealthy AI-powered social network startups. Chien said these companies are building networks where thousands of AI bots are interacting with the user’s content. “It turns social into a single-player game. I’m not sure that it works,” he said. “The reason that people enjoy social networking is the understanding that there are real humans on the other side.” "
OpenAI-backed biotech firm Chai Discovery raises $130M Series B at $1.3B valuation,https://techcrunch.com/2025/12/15/openai-backed-biotech-firm-chai-discovery-raises-130m-series-b-at-1-3b-valuation/,"Chai Discovery, a biotech startup with backing from OpenAI, announced a $130 million Series B round at a $1.3 billion valuation on Monday. The round was led by General Catalyst and Oak HC/FT, the company said. Other participants include Menlo Ventures, OpenAI, Dimension, Thrive Capital, Neo, Yosemite venture fund, Lachy Groom, SV Angel, and new investors Glade Brook and Emerson Collective. The firm’s total funding now stands at over $225 million. The company is one in a growing industry that sees AI as a faster route toward drug development. In August, Menlo Ventures announced it was leading Chai’s $70 million Series A round. The investor described Chai as a startup that was building foundation models tuned for drug discovery, specifically to predict interactions between biochemical molecules so they could be reprogramed for cures. Chai says that its ambition is to “build the ‘computer-aided design suite’ for molecules.” Last year, the startup announced the Chai 1 AI model and is now offering Chai 2, it’s latest model. The company says Chai 2 is achieving significant improvements in success rates over other methods for de novo antibody design, meaning building custom antibodies from scratch, not modifying existing ones. “Our latest models can design molecules that have properties we’d want from actual drugs, and tackle challenging targets that have been out of reach,” Josh Meier, Chai’s co-founder and CEO said in a prepared statement. Previously, Meier, whose background is in machine learning, worked in research and engineering at Facebook and, prior to that, worked for OpenAI, according to his LinkedIn. Chai Discovery was founded in 2024, the profile notes.  "
Disney’s OpenAI deal is exclusive for just one year — then it’s open season,https://techcrunch.com/2025/12/15/disneys-openai-deal-is-exclusive-for-just-one-year-then-its-open-season/,"Disney’s three-year licensing partnership with OpenAI includes just one of exclusivity, Disney CEO Bob Iger told CNBC. The company signed the partnership with OpenAI last week that will bring its iconic characters to the AI firm’s Sora video generator. Once that exclusive year is up, Disney is free to sign similar deals with other AI companies. The deal gives OpenAI a high-profile content partner, allowing users to draw on more than 200 characters from Disney, Marvel, Pixar, and Star Wars to create content on Sora. For now, it’s the only AI platform that’s legally permitted to do so. For Disney, the deal offers a way to test the waters with generative AI and its intellectual property, letting the company assess how its partnership with OpenAI goes before pursuing additional agreements. “No human generation has ever stood in the way of technological advance, and we don’t intend to try,” Iger told CNBC. “We’ve always felt that if it’s going to happen, including disruption of our current business models, then we should get on board.” Tellingly, the same day that Disney announced its deal with OpenAI, the company sent a cease-and-desist letter to Google, alleging that the tech giant has infringed on its copyrights. Google didn’t confirm or deny Disney’s allegations but did say it will “engage” with the company."
Nvidia bulks up open source offerings with an acquisition and new open AI models ,https://techcrunch.com/2025/12/15/nvidia-bulks-up-open-source-offerings-with-an-acquisition-and-new-open-ai-models/,"Nvidia continues to expand its footprint in open source AI on two fronts: an acquisition and a new model release. The semiconductor giant announced Monday it acquired SchedMD, the leading developer of popular open source workload management system Slurm. Nvidia said the company will continue to operate the program, which is designed for high-performance computing and AI, as an open source, vendor-neutral software. Slurm was originally launched in 2002 and SchedMD was founded in 2010 by the lead Slurm developers Morris Jette and Danny Auble. Auble is the current CEO of SchedMD. Terms of the deal weren’t disclosed. Nvidia declined to comment on the news beyond the company’s blog post. Nvidia has been working with SchedMD for more than a decade and said in its blog post the technology is critical infrastructure for generative AI. The company plans to keep investing in the technology and “accelerate” its access to different systems. The semiconductor company also released a new family of open AI models on Monday. The company claimed this group of models, called Nvidia Nemotron 3, is the most “efficient family of open models” for building accurate AI agents. This model family includes the Nemotron 3 Nano, a small model for targeted tasks, the Nemotron 3 Super, a model built for multi-AI agent applications, and Nemotron 3 Ultra, built for more complicated tasks. “Open innovation is the foundation of AI progress,” Jensen Huang, founder and CEO of Nvidia, wrote in the company’s press release. “With Nemotron, we’re transforming advanced AI into an open platform that gives developers the transparency and efficiency they need to build agentic systems at scale.” In recent months, Nvidia has pushed to bolster its open source and open AI offerings. Last week, the company announced a new open reasoning vision language model, Alpamayo-R1, which is focused on autonomous driving research. The company also said at the time it added more workflows and guides covering its Cosmos world models, which are open source under a permissive license, to help developers better use the models to develop physical AI. The activity is reflective of Nvidia’s bet that physical AI will be the next frontier for its GPUs. Nvidia wants to be the go-to supplier for the many robotics — or self-driving vehicle — companies looking for the AI and software to develop the brains behind the technology. "
Creative Commons announces tentative support for AI ‘pay-to-crawl’ systems,https://techcrunch.com/2025/12/15/creative-commons-announces-tentative-support-for-ai-pay-to-crawl-systems/,"After announcing earlier this year a framework for an open AI ecosystem, the nonprofit Creative Commons has come out in favor of “pay-to-crawl” technology — a system to automate compensation of website content when accessed by machines, like AI web crawlers. Creative Commons (CC) is best known for spearheading the licensing movement that allows creators to share their works while retaining copyright. In July, the organization announced a plan to provide a legal and technical framework for dataset sharing between companies that control the data and the AI providers that want to train on it. Now, the nonprofit is tentatively backing pay-to-crawl systems, saying it is “cautiously supportive.” “Implemented responsibly, pay-to-crawl could represent a way for websites to sustain the creation and sharing of their content, and manage substitutive uses, keeping content publicly accessible where it might otherwise not be shared or would disappear behind even more restrictive paywalls,” a CC blog post said. Spearheaded by companies like Cloudflare, the idea behind pay-to-crawl would be to charge AI bots every time they scrape a site to collect its content for model training and updates. In the past, websites freely allowed web crawlers to index their content for inclusion into search engines like Google. They benefited from this arrangement by seeing their sites listed in search results, which drove visitors and clicks. With AI technology, however, the dynamic has shifted. After a consumer gets their answer via an AI chatbot, they’re unlikely to click through to the source. This shift has already been devastating for publishers by killing search traffic, and it shows no sign of letting up. A pay-to-crawl system, on the other hand, could help publishers recover from the hit AI has had on their bottom line. Plus, it could work better for smaller web publishers that don’t have the pull to negotiate one-off content deals with AI providers. Major deals have been struck between companies like OpenAI and Condé Nast, Axel Springer and others; as well as between Perplexity and Gannett; Amazon and The New York Times; and Meta and various media publishers, among others. CC offered several caveats to its support for pay-to-crawl, noting that such systems could concentrate power on the web. It could also potentially block access to content for “researchers, nonprofits, cultural heritage institutions, educators, and other actors working in the public interest.” It suggested a series of principles for responsible pay-to-crawl, including not making pay-to-crawl a default setting for all websites and avoiding blanket rules for the web. In addition, it said that pay-to-crawl systems should allow for throttling, not just blocking, and should preserve public interest access. They should also be open, interoperable, and built with standardized components. Cloudflare isn’t the only company investing in the pay-to-crawl space. Microsoft is also building an AI marketplace for publishers, and smaller startups like ProRata.ai and TollBit have started to do so, as well. Another group called the RSL Collective announced its own spec for a new standard called Really Simple Licensing (RSL) that would dictate what parts of a website crawlers could access but would stop short of actually blocking the crawlers. Cloudflare, Akamai, and Fastly have since adopted RSL, which is backed by Yahoo, Ziff Davis, O’Reilly Media, and others. CC was also among those that announced its support for RSL, alongside CC signals, its broader project to develop technology and tools for the AI era. "
Lightspeed raises record $9B in fresh capital,https://techcrunch.com/2025/12/15/lightspeed-raises-record-9b-in-fresh-capital/,"After a surge of VC investments from the 2021 bubble failed to yield strong returns from many venture firms, limited partners, such as endowments, pension plans, and sovereign wealth funds began to funnel a greater share of their capital into a select group of established firms with proven track records. The latest huge capital haul has come to Lightspeed Venture Partners. The 25-year-old venture firm announced Monday that it raised a total of $9 billion in fresh funds, the largest fundraise in firm’s history. At a time when very few companies have managed to IPO, Lightspeed was an early investor in Rubrik, Netskope, and Navan, all of which have recently made their public market debuts. The firm has also positioned itself as a predominantly AI-focused investor. Lightspeed claims to have backed 165 AI-native companies, including Anthropic, xAI, Databricks, Mistral, Glean, Abridge, and Skild AI. Armed with its giant new fund, the firm can continue to make massive investments into capital-intensive AI companies. For instance, Lightspeed reportedly wrote a $1 billion check to Anthropic when it co-led the LLM-maker’s $13 billion investment in September. Lightspeed’s new capital is spread across six funds, including a $3.3 billion opportunity fund dedicated to follow-on investments in its fastest-growing portfolio companies. Other large VC firms that have recently raised enormous capital pools include Founders Fund, which earlier this year amassed $4.6 billion for a growth fund, as well as General Catalyst’s $8 billion capital haul and Andreessen Horowitz’s $7.2 billion, both secured in 2024. Meanwhile, younger and smaller VC firms are struggling to attract fresh funds. According to PitchBook data, 2025 is on pace to record the fewest VC fund closings in the past 10 years."
Merriam-Webster names ‘slop’ the word of the year,https://techcrunch.com/2025/12/15/merriam-webster-names-slop-the-word-of-the-year/,"AI’s impact on our social media feeds has not gone unnoticed by one of America’s top dictionaries. Amidst the onslaught of content that has swept the web over the past 12 months, Merriam-Webster announced Sunday that its word of the year for 2025 is “slop.” The dictionary defines the term as “digital content of low quality that is produced usually in quantity by means of artificial intelligence.” “Like slime, sludge, and muck, slop has the wet sound of something you don’t want to touch. Slop oozes into everything,” the dictionary writes, adding that, in an age of AI anxiety, it is a term designed to communicate “a tone that’s less fearful, more mocking” of the technology. “It’s such an illustrative word,” Merriam-Webster’s president, Greg Barlow, told The Associated Press. “It’s part of a transformative technology, AI, and it’s something that people have found fascinating, annoying, and a little bit ridiculous.” The word “slop” has certainly been everywhere this year, as journalists and commentators have sought to describe the ways in which platforms like OpenAI’s Sora and Google Gemini’s Veo are transforming the internet. Thanks to this new breed of media generator, there are now AI-generated books, podcasts, pop songs, TV commercials — even entire movies. One study in May claimed that nearly 75% of all new web content from the previous month had involved some kind of AI. These new tools have even led to what has been dubbed a “slop economy,” in which gluts of AI-generated content can be milked for advertising money. Critics worry that this trend is further polarizing digital communities, dividing them into those who can afford paywalled, higher-quality content, and those who can only afford a digital diet of slop, which — as you might imagine — can be quite light on informational value.  But “slop” has also been used to describe AI’s impact on a large variety of fields that don’t have much to do with traditional media consumption, including cybersecurity reports, legal briefings, and the college essay, among other things. Its impact is broad, to say the least. Relatedly, tech words have been big winners in the WOTY (word of the year) category this year. Macquarie Dictionary already beat out Merriam-Webster to make “AI slop” its annual term, while Oxford Dictionary chose “ragebait.” Collins Dictionary went with “vibe coding.”    "
First Voyage raises $2.5M for its AI companion that helps you build habits,https://techcrunch.com/2025/12/15/first-voyage-raises-2-5m-for-its-ai-companion-helps-you-build-habits/,"In a world that’s rapidly filling up with AI-generated content, a startup called First Voyage wants to help people avoid all the AI slop blasted their way and instead build the habits they want. And it’s doing that by way of an AI companion app: Called Momo Self Care, the app offers a digital pet called Momo that you can take care of, and in return, it’ll remind you to complete habit-building tasks. Users can set up reminders for what tasks they want to complete, and Momo will remind you of them. Similar to the hit productivity app Focus Friend, Momo also rewards you with coins for completing tasks that can be used to purchase items within the app to further customize the pet. Users can also talk to Momo about self-care, and the AI companion will recommend habits and tasks based on what you want to achieve. “Momo helps users become the best versions of themselves, and users reward Momo with care, affection, and cute accessories,” co-founder and CEO Besart Çopa told TechCrunch. He launched the company with Egehan Ozsoy, who serves as CTO. On Monday, First Voyage said it had raised $2.5 million in a seed funding round from a16z speedrun, SignalFire, True Global, and other investors. Copa said Momo users have already created more than 2 million tasks on the platform, and the most popular habits relate to productivity, spirituality, and mindfulness. But with the wave of AI apps and toys hitting the market, not to mention the burgeoning influence of AI chatbots like ChatGPT, Claude, and Grok, there’s increasing concern that these new, so-called “companions” can lead to more harm than good. Çopa, for one, believes that relationships between AI characters and humans will only increase in the next few years. However, he noted that the increasing number of AI apps aimed at wellness and self-care is at least better than those that target base urges. “We are happy so many founders [and] startups are working in the AI self-care wellness space instead of building waifus,” he said, adding that the “personalization capability of AI will take the impact of these relationships to another level.” He noted that Momo has baked in safety guardrails, such as prompt filters to make sure that conversations between the AI and users stay within appropriate boundaries. The fresh cash from the fundraise will be used to help launch Momo on the Android app store (it’s already available on iOS). The First Voyage team also hopes to make Momo more intelligent in how it interacts with people.   “We hope Momo and the community around it become a defining consumer brand that uses the best of AI, animation, and gamification to improve as many lives as possible,” Çopa said. "
Nvidia reportedly weighs ramping up H200 production to meet surging demand in China,https://techcrunch.com/2025/12/15/nvidia-is-reportedly-weighs-ramping-up-h200-production-to-meet-surging-demand-in-china/,"After successfully lobbying the Trump administration to approve the sale of its H200 chips to China, Nvidia is now thinking of ramping up production of the chips as Chinese companies rush to place orders, Reuters reported, citing anonymous sources. The most powerful of Nvidia’s previous Hopper generation of graphics processing units (GPUs) made for training large language models, the H200 chips previously could not be sold in China, as the previous Biden administration had proposed rules limiting sales of advanced AI chips in the country. But the Department of Commerce last week gave Nvidia the nod to sell H200 GPUs in China, in exchange for a 25% cut of sales of those chips. Nvidia is now seeing such strong demand from Chinese companies that it is considering adding more capacity, Reuters reported. However, Chinese officials are still deciding whether to allow the import of the H200 chips, which are said to be significantly more powerful than the H20 GPUs Nvidia had customized to sell in China. For the chipmaker, expanding production of the H200 GPUs would let it tap latent demand in a country that is racing to develop its own homegrown AI chips. Competition and national security concerns in the West have hampered the availability of the latest and most powerful hardware for training AI models in China, where companies have resorted to focusing on efficiency over sheer scale. Chinese companies, including Alibaba and ByteDance, which are developing their own AI models, have already been in touch with Nvidia to figure out large orders for the H200 chips, which are being produced in limited quantities, the report added. “We are managing our supply chain to ensure that licensed sales of the H200 to authorized customers in China will have no impact on our ability to supply customers in the United States,” an Nvidia spokesperson said in an emailed statement."
Mirelo raises $41M from Index and a16z to solve AI video’s silent problem,https://techcrunch.com/2025/12/15/mirelo-raises-41m-from-index-and-a16z-to-solve-ai-videos-silent-problem/,"AI lets anyone create videos, but many AI video creation tools lack support for audio. Mirelo is building AI that adds soundtracks to match the video’s action. Earlier this year, the Berlin-based startup released Mirelo SFX v1.5, an AI model that interprets videos to add synced sound effects (SFX).  This attracted attention from VCs gearing up for a generative AI revolution in games. The two-year-old German startup has raised a $41 million seed round led by Index Ventures and Andreessen Horowitz, TechCrunch learned exclusively. This new capital will help Mirelo compete more effectively in its emerging category. While it was still in stealth mode and resource-constrained, large companies such as Sony and Tencent released video-to-SFX models. So did Kuaishou-owned Kling AI, out of China, and ElevenLabs, which is also backed by a16z. While Mirelo already differs from them by its narrower focus, beating these models in the long run requires the startup to make additional hires. Altogether, the startup expects its team of 10 people to “double if not triple” in headcount by the end of next year, Mirelo CEO and co-founder CJ Simon-Gabriel told TechCrunch. These new hires will support Mirelo’s R&D, as well as its product and go-to-market strategy. The startup published its models on Fal.ai and Replicate, and expects API usage to drive most of its revenue in the short term, Simon-Gabriel said. But it is also investing in building out its workspace for creators, Mirelo Studio, which could eventually support full professional use. As Mirelo prepares to scale, the startup and its investors are also anticipating concerns around training data that have dogged other generative AI companies. According to Georgia Stevenson, who led Index’s investments, Mirelo based its models on public and purchased sound libraries, and is signing revenue-sharing partnerships that respect artists’ rights.  It’s a tension inherent to generative AI tools, but Mirelo isn’t displacing musicians and sound designers — at least not yet. With a freemium model including a recommended plan for creators priced at €20/month (approximately $23.50), the startup is mostly targeting amateurs and prosumers hoping to unmute AI-generated videos. According to Simon-Gabriel, creators can’t fully benefit from this new potential without audio. “George Lucas said that sound is 50% of the movie-going experience. It’s not an overstatement,” he said. “If anything, it’s an understatement. You can take exactly the same images, and the sound will shape a completely different ambience, depending on the sound and the music that you put in there.”  He and his co-founder, Florian Wenzel, are both AI researchers and musicians themselves, and the startup has AI music generation on its roadmap. But Mirelo is seeing more pull for sound effects, in part because there is less research happening than in other AI fields, Simon-Gabriel said. “It’s easier to build a real moat here, and then to capitalize on it,” he noted. This could pay off for Mirelo. Simon-Gabriel declined to disclose its new valuation, but said it had increased “very significantly” compared to its previously undisclosed pre-seed round. That earlier round was led by Berlin-based firm Atlantic, which also participated in the new funding, bringing Mirelo’s total raised to $44 million and helping close its resource gap. The startup is also backed by angels who lend credibility to its technology and could open new doors, including Mistral CEO Arthur Mensch, Hugging Face chief science officer Thomas Wolf, Fal.ai co-founder Burkay Gur, and others. Still, the team is aware that AI-generated videos may not be mute for long. For instance, Gemini’s video generator now incorporates soundtracks powered by DeepMind’s Veo 3.1 video-to-audio model. But if anything, Simon-Gabriel sounds vindicated. “Now, suddenly, people realize, ‘Oh, maybe we should add sound.’ But, of course, you should add some. It’s a bit like silent movies versus talkies, right? It does make quite a difference!”"
Grok got crucial facts wrong about Bondi Beach shooting,https://techcrunch.com/2025/12/14/grok-gets-the-facts-wrong-about-bondi-beach-shooting/,"Grok, the chatbot built by Elon Musk’s xAI and popularized on his social media platform X, appears to have repeatedly spread misinformation about today’s mass shooting at Bondi Beach in Australia. Gizmodo pointed to a number of posts where Grok misidentified the bystander — 43-year-old Ahmed al Ahmed — who disarmed one of the gunmen, and where it questioned the authenticity of videos and photos capturing al Ahmed’s actions. In one post, the chatbot misidentified the man in a photo as an Israeli hostage, and in another post brought up irrelevant information about the Israeli army’s treatment of Palestinians. In another post, it claimed a “43-year-old IT professional and senior solutions architect” named Edward Crabtree was the one who actually disarmed a gunman. Grok does appear to be fixing some of its mistakes. At least one post that reportedly claimed a video of the shooting actually showed Cyclone Alfred has been corrected “upon reevaluation.” And the chatbot subsequently acknowledged al Ahmed’s identity, writing that the “misunderstanding arises from viral posts that mistakenly identified him as Edward Crabtree, possibly due to a reporting error or a joke referencing a fictional character.” (The article in question appeared on a largely non-functional news site that may be AI-generated.)"
AI data center boom could be bad news for other infrastructure projects,https://techcrunch.com/2025/12/13/ai-data-center-boom-could-be-bad-news-for-other-infrastructure-projects/,"Improvements to roads, bridges, and other infrastructure could take a hit as data center construction accelerates, according to Bloomberg. In 2025, state and local governments reportedly sold a record amount of debt for the second year in a row, with strategists predicting another $600 billion in sales next year. Most of that money is expected to fund infrastructure projects.  Meanwhile, Census Bureau data reportedly shows that private spending on data center construction was running at an annualized run rate of more than $41 billion — roughly the same as state and local government spending on transportation construction. All these projects are likely to compete for construction workers just as the industry faces labor shortages from retirements and President Donald Trump’s immigration crackdown. Andrew Anagnost, CEO of architecture and design software maker Autodesk, told Bloomberg there’s “absolutely no doubt” that data center construction “sucks resources from other projects. “I guarantee you a lot of those [infrastructure] projects are not going to move as fast as people want,” he said."
"OK, what’s going on with LinkedIn’s algo?",https://techcrunch.com/2025/12/12/ok-whats-going-on-with-linkedins-algo/,"One day in November, a product strategist we’ll call Michelle (not her real name), logged into her LinkedIn account and switched her gender to male. She also changed her name to Michael, she told TechCrunch.  She was partaking in an experiment called #WearthePants where women tested the hypothesis that LinkedIn’s new algorithm was biased against women.  For months, some heavy LinkedIn users complained about seeing drops in engagement and impressions on the career-oriented social network. This came after the company’s vice president of engineering, Tim Jurka, said in August that the platform had “more recently” implemented LLMs to help surface content useful to users.  Michelle (whose identity is known to TechCrunch) was suspicious about the changes because she has more than 10,000 followers and ghostwrites posts for her husband, who has only around 2,000. Yet she and her husband tend to get around the same number of post impressions, she said, despite her larger following.  “The only significant variable was gender,” she said.  Marilynn Joyner, a founder, also changed her profile gender. She’s been posting on LinkedIn consistently for two years and noticed in the last few months that her posts’ visibility declined. “I changed my gender on my profile from female to male, and my impressions jumped 238% within a day,” she told TechCrunch. Megan Cornish reported similar results, as did Rosie Taylor, Jessica Doyle Mekkes, Abby Nydam, Felicity Menzies, Lucy Ferguson, and so on.   LinkedIn said that its “algorithm and AI systems do not use demographic information such as age, race, or gender as a signal to determine the visibility of content, profile, or posts in the Feed” and that “a side-by-side snapshot of your own feed updates that are not perfectly representative, or equal in reach, do not automatically imply unfair treatment or bias” within the Feed.  Social algorithm experts agree that explicit sexism may not have been a cause, although implicit bias may be at work.   Platforms are “an intricate symphony of algorithms that pull specific mathematical and social levers, simultaneously and constantly,” Brandeis Marshall, a data ethics consultant, told TechCrunch.   “The changing of one’s profile photo and name is just one such lever,” she said, adding that the algorithm is also influenced by, for example, how a user has and currently interacts with other content.   “What we don’t know of is all the other levers that make this algorithm prioritize one person’s content over another. This is a more complicated problem than people assume,” Marshall said.  The #WearthePants experiment began with two entrepreneurs — Cindy Gallop and Jane Evans. They asked two men to make and post the same content as them, curious to know if gender was the reason so many women were feeling a dip in engagement. Gallop and Evans both have sizable followings — more than 150,000 combined compared to the two men who had around 9,400 at the time.  Gallop reported that her post reached only 801 people, while the man who posted the exact same content reached 10,408 people, more than 100% of his followers. Other women then took part. Some, like Joyner, who uses LinkedIn to market her business, became concerned. “I’d really love to see LinkedIn take accountability for any bias that may exist within its algorithm,” Joyner said.  But LinkedIn, like other LLM-dependent search and social media platforms, offers scant details on how content-picking models were trained. Marshall said that most of these platforms “innately have embedded a white, male, Western-centric viewpoint” due to who trained the models. Researchers find evidence of human biases like sexism and racism in popular LLM models because the models are trained on human-generated content, and humans are often directly involved in post-training or reinforcement learning.  Still, how any individual company implements its AI systems is shrouded in the secrecy of the algorithmic black box.  LinkedIn says that the #WearthePants experiment could not have demonstrated gender bias against women. Jurka’s August statement said — and LinkedIn’s Head of Responsible AI and Governance, Sakshi Jain, reiterated in another post in November — that its systems are not using demographic information as a signal for visibility.  Instead, LinkedIn told TechCrunch that it tests millions of posts to connect users to opportunities. It said demographic data is used only for such testing, like seeing if posts “from different creators compete on equal footing and that the scrolling experience, what you see in the feed, is consistent across audiences,” the company told TechCrunch. LinkedIn has been noted for researching and adjusting its algorithm to try to provide a less biased experience for users. It’s the unknown variables, Marshall said, that probably explain why some women saw increased impressions after changing their profile gender to male. Partaking in a viral trend, for example, can lead to an engagement boost; some accounts were posting for the first time in a long time, and the algorithm could have possibly rewarded them for doing so.  Tone and writing style might also play a part. Michelle, for example, said the week she posted as “Michael,” she adjusted her tone slightly, writing in a more simplistic, direct style, as she does for her husband. That’s when she said impressions jumped 200% and engagements rose 27%. She concluded the system was not “explicitly sexist,” but seemed to deem communication styles commonly associated with women “a proxy for lower value.”  Stereotypical male writing styles are believed to be more concise, while the writing style stereotypes for women are imagined to be softer and more emotional. If an LLM is trained to boost writing that complies with male stereotypes, that’s a subtle, implicit bias. And as we previously reported, researchers have determined that most LLMs are riddled with them. Sarah Dean, an assistant professor of computer science at Cornell, said that platforms like LinkedIn often use entire profiles, in addition to user behavior, when determining content to boost. That includes jobs on a user’s profile and the type of content they usually engage with. “Someone’s demographics can affect ‘both sides’ of the algorithm — what they see and who sees what they post,” Dean said.  LinkedIn told TechCrunch that its AI systems look at hundreds of signals to determine what is pushed to a user, including insights from a person’s profile, network, and activity.  “We run ongoing tests to understand what helps people find the most relevant, timely content for their careers,” the spokesperson said. “Member behavior also shapes the feed, what people click, save, and engage with changes daily, and what formats they like or don’t like. This behavior also naturally shapes what shows up in feeds alongside any updates from us.” Chad Johnson, a sales expert active on LinkedIn, described the changes as deprioritizing likes, comments, and reposts. The LLM system “no longer cares how often you post or at what time of day,” Johnson wrote in a post. “It cares whether your writing shows understanding, clarity, and value.” All of this makes it hard to determine the true cause of any #WearthePants results. Nevertheless, it seems like many people, across genders, either don’t like or don’t understand LinkedIn’s new algorithm — whatever it is.  Shailvi Wakhlu, a data science consultant, told TechCrunch that she’s averaged at least one post a day for five years and used to see thousands of impressions. Now she and her husband are lucky to see a few hundred. “It’s demotivating for content creators with a large loyal following,” she said. One man told TechCrunch he saw about a 50% drop in engagement over the past few months. Still, another man said he’s seen post impressions and reach increase more than 100% in a similar time span. “This is largely because I write on specific topics for specific audiences, which is what the new algorithm is rewarding,” he told TechCrunch, adding that his clients are seeing a similar increase.  But in Marshall’s experience, she, who is Black, believes posts about her experiences perform more poorly than posts related to her race. “If Black women only get interactions when they talk about black women but not when they talk about their particular expertise, then that’s a bias,” she said.  The researcher, Dean, believes the algorithm may simply be amplifying “whatever signals there already are.” It could be rewarding certain posts, not because of the demographics of the writer, but because there’s been more of a history of response to them across the platform. While Marshall may have stumbled into another area of implicit bias, her anecdotal evidence isn’t enough to determine that with certainty. LinkedIn offered some insights into what works well now. The company said the user base has grown, and as a result, posting is up 15% year-over-year while comments are up 24% YOY. “This means more competition in the feed,” the company said. Posts about professional insights and career lessons, industry news and analysis, and education or informative content around work, business, and the economy are all doing well, it said.  If anything, people are just confused. “I want transparency,” Michelle said.  However, as content-picking algorithms have always been closely guarding secrets by their companies, and transparency can lead to gaming them, that’s a big ask. It’s one that’s unlikely ever to be satisfied.  This article was updated to correct the spelling of Wakhlu’s name."
Trump’s AI executive order promises ‘one rulebook’ — startups may get legal limbo instead,https://techcrunch.com/2025/12/12/trumps-ai-executive-order-promises-one-rulebook-startups-may-get-legal-limbo-instead/,"President Donald Trump signed an executive order Thursday evening that directs federal agencies to challenge state AI laws, arguing that startups need relief from a “patchwork” of rules. Legal experts and startups meanwhile say the order could prolong uncertainty, sparking court battles that leave young companies navigating shifting state requirements while waiting to see if Congress can agree on a single national framework.  The order, titled “Ensuring a National Policy Framework for Artificial Intelligence,” directs the Department of Justice to set up a task force within 30 days to challenge certain state laws on the grounds that AI is interstate commerce and should be regulated federally. It gives the Commerce Department 90 days to compile a list of “onerous” state AI laws, an assessment that could affect states’ eligibility for federal funds, including broadband grants. The order also asks the Federal Trade Commission and Federal Communications Commission to explore federal standards that could preempt state rules and instructs the administration to work with Congress on a uniform AI law.  The order lands amid a broader push to rein in state-by-state AI rules after efforts in Congress to pause state regulation stalled. Lawmakers in both parties have argued that without a federal standard, blocking states from acting could leave consumers exposed and companies largely unchecked. “This David Sacks-led executive order is a gift for Silicon Valley oligarchs who are using their influence in Washington to shield themselves and their companies from accountability,” said Michael Kleinman, head of U.S. Policy at the Future of Life Institute, which focuses on reducing extreme risks from transformative technologies, in a statement.  Sacks, Trump’s AI and crypto policy czar, has been a leading voice behind the administration’s AI preemption push. Even supporters of a national framework concede the order doesn’t create one. With state laws still enforceable unless courts block them or states pause enforcement, startups could face an extended transition period. Sean Fitzpatrick, CEO of LexisNexis North America, U.K., and Ireland, tells TechCrunch that states will defend their consumer protection authority in court, with cases likely escalating to the Supreme Court.  While supporters argue the order could reduce uncertainty by centralizing the fight over AI regulation in Washington, critics say the legal battles will create immediate headwinds for startups navigating conflicting state and federal demands.  “Because startups are prioritizing innovation, they typically do not have … robust regulatory governance programs until they reach a scale that requires a program,” Hart Brown, principal author of Oklahoma governor Kevin Stitt’s Task Force on AI and Emerging Technology recommendations, told TechCrunch. “These programs can be expensive and time-consuming to meet a very dynamic regulatory environment.” Arul Nigam, co-founder at Circuit Breaker Labs, a startup that performs red-teaming for conversational and mental health AI chatbots, echoed those concerns. “There’s uncertainty in terms of, do [AI companion and chatbot companies] have to self-regulate?” Nigam told TechCrunch, noting that the patchwork of state AI laws does hurt smaller startups in his field. “Are there open source standards they should adhere to? Should they continue building?” He added that he is hopeful Congress can move more quickly now to pass a stronger federal framework.  Andrew Gamino-Cheong, CTO and co-founder of AI governance company Trustible, told TechCrunch the EO will backfire on AI innovation and pro-AI goals: “Big Tech and the big AI startups have the funds to hire lawyers to help them figure out what to do, or they can simply hedge their bets. The uncertainty does hurt startups the most, especially those that can’t get billions of funding almost at will,” he said. He added that legal ambiguity makes it harder to sell to risk-sensitive customers like legal teams, financial firms, and healthcare organizations, increasing sales cycles, systems work, and insurance costs. “Even the perception that AI is unregulated will reduce trust in AI,” which is already low and threatens adoption, Gamino-Cheong said. Gary Kibel, a partner at Davis + Gilbert, said businesses would welcome a single national standard, but “an executive order is not necessarily the right vehicle to override laws that states have duly enacted.” He warned that the current uncertainty leaves open two extremes: highly restrictive rules or no action at all, either of which could create a “Wild West” that favors Big Tech’s ability to absorb risk and wait things out. Meanwhile, Morgan Reed, president of The App Association, urged Congress to quickly enact a “comprehensive, targeted, and risk-based national AI framework. We can’t have a patchwork of state AI laws, and a lengthy court fight over the constitutionality of an Executive Order isn’t any better.”"
Google Translate now lets you hear real-time translations in your headphones,https://techcrunch.com/2025/12/12/google-translate-now-lets-you-hear-real-time-translations-in-your-headphones/,"Google is rolling out a beta experience that lets you hear real-time translations in your headphones, the company announced on Friday. The tech giant is also bringing advanced Gemini capabilities to Google Translate and expanding its language-learning tools in the Translate app. The new real-time headphone translations experience keeps each speaker’s tone, emphasis, and cadence intact, so it’s easier to follow the conversation and tell who’s saying what, Google says. The new capability essentially turns any pair of headphones into a real-time, one-way translation device. “Whether you’re trying to have a conversation in a different language, listen to a speech or lecture while abroad, or watch a TV show or film in another language, you can now put in your headphones, open the Translate app, tap ‘Live translate’ and hear a real-time translation in your preferred language,” said Rose Yao, Google VP Product Management, Search Verticals, in the blog post. The beta is rolling out now in the Translate app on Android in the U.S., Mexico, and India. The feature works with any pair of headphones and supports more than 70 languages. The company plans to bring the capability to iOS and more countries in 2026. As for the advanced Gemini capabilities coming to Translate, Google says they will enable smarter, more natural, and accurate text translations. They’ll also enable improved translations of phrases with more nuanced meanings, like slang, idioms, or local expressions. For example, if you’re trying to translate an English idiom like “stealing my thunder,” you’ll now get a more accurate translation instead of a literal word-for-word translation, as Gemini will parse the context to capture what the idiom really means. This update is rolling out now in the U.S. and India, translating between English and nearly 20 languages, including Spanish, Arabic, Chinese, Japanese, and German. The update is available in the Translate app on Android, iOS, and on the web. Google is also expanding its language learning tools to almost 20 new countries, including Germany, India, Sweden, and Taiwan. English speakers can now practice German, while Bengali, Mandarin Chinese (Simplified), Dutch, German, Hindi, Italian, Romanian, and Swedish speakers can practice English. The tech giant is also adding improved feedback so you can get helpful tips based on your speaking practice. Additionally, Google is adding a feature that tracks how many days in a row you’ve been learning, making it easier to see your progress and stay consistent. While the tools were already designed to take on Duolingo, this new feature brings the experience even closer to the popular language-learning app."
Google launched its deepest AI research agent yet — on the same day OpenAI dropped GPT-5.2,https://techcrunch.com/2025/12/11/google-launched-its-deepest-ai-research-agent-yet-on-the-same-day-openai-dropped-gpt-5-2/,"Google released on Thursday a “reimagined” version of its research agent Gemini Deep Research based on its much-ballyhooed state-of-the-art foundation model, Gemini 3 Pro.   This new agent isn’t just designed to produce research reports — although it can still do that. It now allows developers to embed Google’s SATA-model research capabilities into their own apps. That capability is made possible through Google’s new Interactions API, which is designed to give devs more control in the coming agentic AI era.  The new Gemini Deep Research tool is an agent equipped to synthesize mountains of information and handle a large context dump in the prompt. Google says it’s used by customers for tasks ranging from due diligence to drug toxicity safety research.  Google also says it will soon be integrating this new deep research agent into services, including Google Search, Google Finance, its Gemini App, and its popular NotebookLM. This is another step toward preparing for a world where humans don’t Google anything anymore — their AI agents do.  The tech giant says that Deep Research benefits from Gemini 3 Pro’s status as its “most factual” model that is trained to minimize hallucinations during complex tasks. AI hallucinations — where the LLM just makes stuff up — are an especially crucial issue for long-running, deep reasoning agentic tasks, in which many autonomous decisions are made over minutes, hours, or longer. The more choices an LLM has to make, the greater the chance that even one hallucinated choice will invalidate the entire output.  To prove its progress claims, Google has also created yet another benchmark (as if the AI world needs another one). The new benchmark is unimaginatively named DeepSearchQA and is intended to test agents on complex, multi-step information-seeking tasks. Google has open sourced this benchmark.   It also tested Deep Research on Humanity’s Last Exam, a much more interestingly named, independent benchmark of general knowledge filled with impossibly niche tasks; and BrowserComp, a benchmark for browser-based agentic tasks. As you might expect, Google’s new agent bested the competition on its own benchmark, and Humanity’s. However, OpenAI’s ChatGPT 5 Pro was a surprisingly close second all the way around and slightly bested Google on BrowserComp.  But those benchmark comparisons were obsolete almost the moment Google published them. Because on the same day, OpenAI launched its highly anticipated GPT 5.2 — codenamed Garlic. OpenAI says its newest model bests its rivals — especially Google — on a suite of the typical benchmarks, including OpenAI’s homegrown one.  Perhaps one of the most interesting parts of this announcement was the timing. Knowing that the world was awaiting the release of Garlic, Google dropped some AI news of its own."
1X struck a deal to send its ‘home’ humanoids to factories and warehouses,https://techcrunch.com/2025/12/11/1x-struck-a-deal-to-send-its-home-humanoids-to-factories-and-warehouses/,"Robotics company 1X found some big potential buyers for its humanoid robots designed for consumers — the portfolio companies of one of its investors. The company announced a strategic partnership to make thousands of its humanoid robots available for EQT’s portfolio companies on Thursday. EQT is a large Swedish multi-asset investor, and its venture fund EQT Ventures, is one of 1X’s backers. This deal involves shipping up to 10,000 1X Neo humanoid robots between 2026 and 2030 to EQT’s more than 300 portfolio companies with a concentration on manufacturing, warehousing, logistics, and other industrial use cases. 1X will sign individual deals with each of EQT’s interested portfolio companies, 1X confirmed to TechCrunch. This partnership is particularly interesting because 1X’s Neo has been marketed as a humanoid for personal use and tagged as the “first consumer-ready humanoid robot designed to transform life at home.” Unlike some of 1X’s peers, like Figure, it has not been marketed as a bot for commercial purposes. 1X does have a robot designed for industrial purposes, Eve Industrial, but this deal specifically involves the Neo humanoid. When the company opened up preorders for the $20,000 robot in October, the announcement was focused on how the robot would operate in someone’s home from descriptions of the different chores that the robot is able to perform and how it interacts with people. This deal is quite a different use case. That’s likely because humanoids for the home will remain a hard sell for quite some time while industrial use cases are an easier sell. The $20,000 price tag automatically limits the potential pool of consumer customers too. The Neo specifically also comes with a privacy element that would be hard to swallow for many people — human operators from 1X are able to look through the robots eyes into someone’s home. Humanoids also come with potential safety issues around pets and small children due to their size and instability. Multiple VCs and scientists in the robotics field told TechCrunch this summer that humanoid adoption wouldn’t be for multiple years, if not a decade away. The company declined to share how many preorders it received for its Neo bot but a spokesperson said preorders “far exceeded” the company’s goal. Founded in 2014, 1x has since raised more than $130 million in venture capital from firms, including EQT Ventures, Tiger Global, and the OpenAI Startup Fund, among others."
Disney hits Google with cease-and-desist claiming ‘massive’ copyright infringement,https://techcrunch.com/2025/12/11/disney-hits-google-with-cease-and-desist-claiming-massive-copyright-infringement/,"Disney sent a cease-and-desist letter to Google on Wednesday, alleging that the tech giant has infringed on its copyrights, Variety reports. Disney is accusing the tech giant of copyright infringement on a “massive scale,” claiming it has used AI models and services to commercially distribute unauthorized images and videos, according to the letter seen by Variety. “Google operates as a virtual vending machine, capable of reproducing, rendering, and distributing copies of Disney’s valuable library of copyrighted characters and other works on a mass scale,” the letter reads. “And compounding Google’s blatant infringement, many of the infringing images generated by Google’s AI Services are branded with Google’s Gemini logo, falsely implying that Google’s exploitation of Disney’s intellectual property is authorized and endorsed by Disney.” The letter alleges that Google’s AI systems infringe characters from “Frozen,” “The Lion King,” “Moana,” “The Little Mermaid,” “Deadpool,” and more. Google didn’t confirm or deny Disney’s allegations but did say it will “engage” with the company. “We have a longstanding and mutually beneficial relationship with Disney, and will continue to engage with them. More generally, we use public data from the open web to build our AI and have built additional innovative copyright controls like Google-extended and Content ID for YouTube, which give sites and copyright holders control over their content,” a spokesperson said. Disney’s move comes the same day that it signed a $1 billion, three-year deal with OpenAI that will bring its iconic characters to the company’s Sora AI video generator. "
Google’s AI try-on feature for clothes now works with just a selfie,https://techcrunch.com/2025/12/11/googles-ai-try-on-feature-for-clothes-now-works-with-just-a-selfie/,"Google is updating its AI try-on feature to let you virtually try on clothes using just a selfie, the company announced on Thursday. In the past, users had to upload a full-body picture of themselves to virtually try on a piece of clothing. Now they can use a selfie and Nano Banana, Google’s Gemini 2.5 Flash Image model, to generate a full-body digital version of themselves for virtual try-ons. Users can select their usual clothing size, and the feature will then generate several images. From there, users can choose one to make it their default try-on photo. If desired, users still have the option to use a full-body photo or select from a range of models with diverse body types. The new capability is launching in the United States today. Google first launched the try-on feature in July, allowing users to try on apparel items from its Shopping Graph across Search, Google Shopping, and Google Images. To use the feature, users need to tap on a product listing or apparel product result and select the “try it on” icon. The move comes as Google has been investing in the virtual AI try-on space, as the company has a separate app dedicated specifically to that purpose. The app, called Doppl, is designed to help visualize how different outfits might look on you using AI. Earlier this week, the tech giant updated it with a shoppable discovery feed that displays recommendations so users can discover and virtually try on new items. Nearly everything in the feed is shoppable, with direct links to merchants. The discovery feed features AI-generated videos of real products and suggests outfits based on your personalized style. While some may not be fond of an AI-generated feed, Google likely views it as a way to showcase products in a format that people are already familiar with, thanks to platforms like TikTok and Instagram."
OpenAI fires back at Google with GPT-5.2 after ‘code red’ memo,https://techcrunch.com/2025/12/11/openai-fires-back-at-google-with-gpt-5-2-after-code-red-memo/,"OpenAI launched its latest frontier model, GPT-5.2, on Thursday amid increasing competition from Google, pitching it as its most advanced model yet and one designed for developers and everyday professional use.  OpenAI’s GPT-5.2 is coming to ChatGPT paid users and developers via the API in three flavors: Instant, a speed-optimized model for routine queries like information-seeking, writing, and translation; Thinking, which excels at complex structured work like coding, analyzing long documents, math, and planning; and Pro, the top-end model aimed at delivering maximum accuracy and reliability for difficult problems.  “We designed 5.2 to unlock even more economic value for people,” Fidji Simo, OpenAI’s chief product officer, said Thursday during a briefing with journalists. “It’s better at creating spreadsheets, building presentations, writing code, perceiving images, understanding long context, using tools and then linking complex, multi-step projects.” GPT-5.2 lands in the middle of an arms race with Google’s Gemini 3, which is topping LMArena’s leaderboard across most benchmarks (apart from coding — which Anthropic’s Claude Opus-4.5 still has on lock). Early this month, The Information reported that CEO Sam Altman released an internal “code red” memo to staff amid ChatGPT traffic decline and concerns that it is losing consumer market share to Google. The code red called for a shift in priorities, including stalling on commitments like introducing ads and instead focusing on creating a better ChatGPT experience.  GPT-5.2 is OpenAI’s push to reclaim leadership, even as some employees reportedly asked for the model release to be pushed back so the company could have more time to improve it. And despite indications that OpenAI would focus its attention on consumer use cases by adding more personalization and customization to ChatGPT, the launch of GPT-5.2 looks to beef up its enterprise opportunities.  The company is specifically targeting developers and the tooling ecosystem, aiming to become the default foundation for building AI-powered applications. Earlier this week, OpenAI released new data showing enterprise usage of its AI tools has surged dramatically over the past year.  This comes as Gemini 3 has become tightly integrated into Google’s product and cloud ecosystem for multimodal and agentic workflows. Google this week launched managed MCP servers that make its Google and Cloud services like Maps and BigQuery easier for agents to plug into. (MCPs are the connectors between AI systems and data and tools.) OpenAI says GPT-5.2 sets new benchmark scores in coding, math, science, vision, long-context reasoning, and tool use, which the company claims could lead to “more reliable agentic workflows, production-grade code, and complex systems that operate across large contexts and real-world data.” Those capabilities put it in direct competition with Gemini 3’s Deep Think mode, which has been touted as a major reasoning advancement targeting math, logic, and science. On OpenAI’s own benchmark chart, GPT-5.2 Thinking edges out Gemini 3 and Anthropic’s Claude Opus 4.5 in nearly every listed reasoning test, from real-world software engineering tasks (SWE-Bench Pro) and doctoral-level science knowledge (GPQA Diamond) to abstract reasoning and pattern discovery (ARC-AGI suites).  Research lead Aidan Clark said that stronger math scores aren’t just about solving equations. Mathematical reasoning, he explained, is a proxy for whether a model can follow multi-step logic, keep numbers consistent over time, and avoid subtle errors that could compound over time.  “These are all properties that really matter across a wide range of different workloads,” Clark said. “Things like financial modeling, forecasting, doing an analysis of data.” During the briefing, OpenAI product lead Max Schwarzer said GPT-5.2 “makes substantial improvements to code generation and debugging” and can walk through complex math and logic step by step. Coding startups like Windsurf and CharlieCode, he added, report “state-of-the-art agent coding performance” and measurable gains on complex multi-step workflows. Beyond coding, Schwarzer said that GPT-5.2 Thinking responses contain 38% fewer errors than its predecessor, making the model more dependable for day-to-day decision-making, research, and writing.  GPT-5.2 appears to be less a reinvention and more of a consolidation of OpenAI’s last two upgrades. GPT-5, which dropped in August, was a reset that laid the groundwork for a unified system with a router to toggle the model between a fast default model and a deeper “Thinking” mode. November’s GPT-5.1 focused on making that system warmer, more conversational, and better suited to agentic and coding tasks. The latest model, GPT-5.2, seems to turn up the dial on all of those advancements, making it a more reliable foundation for production use.  For OpenAI, the stakes have never been higher. The company has made commitments to the tune of $1.4 trillion for AI infrastructure buildouts over the next few years to support its growth — commitments it made when it still had the first-mover advantage among AI companies. But now that Google, which lagged behind at the start, is pushing ahead, that bet might be what’s driving Altman’s “code red.”  OpenAI’s renewed focus on reasoning models is also a risky flex. The systems behind its Thinking and Deep Research modes are more expensive to run than standard chatbots because they chew through more compute. By doubling down on that kind of model with GPT-5.2, OpenAI may be setting up a vicious cycle: spend more on compute to win the leaderboard, then spend even more to keep those high-cost models running at scale. OpenAI is already reportedly spending more on compute than it had previously let on. As TechCrunch reported recently, most of OpenAI’s inference spend — the money it spends on compute to run a trained AI model — is being paid in cash rather than through cloud credits, suggesting the company’s compute costs have grown beyond what partnerships and credits can subsidize. During the call, Simo suggested that as OpenAI scales, it is able to offer more products and services to generate more revenue to pay for additional compute. “But I think it’s important to place that in the grand arc of efficiency,” Simo said. “You are getting, today, a lot more intelligence for the same amount of compute and the same amount of dollars as you were a year ago.” For all its focus on reasoning, one thing that’s absent from today’s launch is a new image generator. Altman reportedly said in his code red memo that image generation would be a key priority moving forward, particularly after Google’s Nano Banana (the nickname for Google’s Gemini 2.5 Flash Image model) had a viral moment following its August release. Last month, Google launched Nano Banana Pro (aka Gemini 3 Pro Image), an upgraded version with even better text rendering, world knowledge, and an eerie, real-life, unedited vibe to its photos. It also integrates better across Google’s products, as demonstrated over the past week as it pops up in tools and workflows like Google Labs Mixboard for automated presentation generation. OpenAI reportedly plans to release another new model in January with better images, improved speed, and better personality, though the company didn’t confirm these plans Thursday. OpenAI also said Thursday it’s rolling out new safety measures around mental health use and age verification for teens, but didn’t spend much of the launch pitching those changes. This article has been updated with more information about OpenAI’s compute efficiency status. Got a sensitive tip or confidential documents? We’re reporting on the inner workings of the AI industry — from the companies shaping its future to the people impacted by their decisions. Reach out to Rebecca Bellan at rebecca.bellan@techcrunch.com or Russell Brandom at russell.brandom@techcrunch.com. For secure communication, you can contact them via Signal at @rebeccabellan.491 and russellbrandom.49."
"Google debuts ‘Disco,’ a Gemini-powered tool for making web apps from browser tabs",https://techcrunch.com/2025/12/11/google-debuts-disco-a-gemini-powered-tool-for-making-web-apps-from-browser-tabs/,"Google on Thursday introduced a new AI experiment for the web browser: the Gemini-powered product Disco, which helps to turn your open tabs into custom applications. With Disco, you can create what Google is calling “GenTabs,” a tool that proactively suggests interactive web apps that can help you complete tasks related to what you’re browsing and allows you to build your own apps via written prompts. For instance, if you’re studying a particular subject, GenTabs might suggest building a web app to visualize the information, which could help you better understand the core principles. Or, in a less academic scenario, you could use GenTabs to help you create a meal plan from a series of online recipes or help you plan a trip when you’re researching travel. These are things that you can already do today with some AI-powered chatbots, but GenTabs builds these custom experiences on the fly using Gemini 3, using the information in your browser and in your Gemini chat history. After the app is built, you can also continue to refine it using natural language commands. The resulting generative elements in the GenTabs experience will link back to the original sources, Google notes. Like others in the AI market, Google has been experimenting with bringing AI deeper into the web-browsing experience. Instead of building its own stand-alone AI browser, like Perplexity’s Comet or ChatGPT Atlas, Google integrated its AI assistant Gemini into the Chrome browser, where it can optionally be used to ask questions about the web page you’re on. With GenTabs, the focus is not only on what you’re currently viewing, but also on your overall browsing, spanning multiple tabs — whether that’s research, learning, or something else. However, the feature is only initially going to be available to a small number of testers through Google Labs, who will offer feedback about the experience. The company says that interesting ideas that are developed through Disco may one day find their way into other, larger Google products. It also suggests that GenTabs will be one of many Disco features to come over time, noting that GenTabs is the “first feature” being tested. To access Disco, users will need to join a waitlist to download the app, starting on macOS."
"Runway releases its first world model, adds native audio to latest video model",https://techcrunch.com/2025/12/11/runway-releases-its-first-world-model-adds-native-audio-to-latest-video-model/,"The race to release world models is on as AI image and video generation company Runway joins an increasing number of startups and Big Tech companies by launching its first one. Dubbed GWM-1, the model works through frame-by-frame prediction, creating a simulation with an understanding of physics and how the world actually behaves over time, the company said. A world model is an AI system that learns an internal simulation of how the world works so it can reason, plan, and act without needing to be trained on every scenario possible in real life. Runway, which earlier this month launched its Gen 4.5 video model that surpassed both Google and OpenAI on the Video Arena leaderboard, said its GWM-1 world model is more “general” than Google’s Genie-3 and other competitors. The firm is pitching it as a model that can create simulations to train agents in different domains like robotics and life sciences. “To build a world model, we first needed to build a really great video model. We believe that the right path to building a world model is teaching models to predict pixels directly is the best way to achieve general-purpose simulation. At sufficient scale and with the right data, you can build a model that has sufficient understanding of how the world works,” the company’s CTO, Anastasis Germanidis, said during the livestream. Runway released specific slants or versions to the new world model called GWM-Worlds, GWM-Robotics, and GWM-Avatars. GWM-Worlds is an app for the model that lets you create an interactive project. Users can set a scene through a prompt or an image reference, and as you explore the space, the model generates the world with an understanding of geometry, physics, and lighting. The company mentioned that the simulation runs at 24 fps and 720p resolution. Runway said that while Worlds could be useful for gaming, it’s also well-positioned to teach agents how to navigate and behave in the physical world. With GWM-Robotics, the company aims to use synthetic data enriched with new parameters like changing  weather conditions or obstacles. Runway says this method could also reveal when and how robots might violate policies and instructions in different scenarios. Runway is also building realistic avatars under GWM-Avatars to simulate human behavior. Companies like D-ID, Synthesia, Soul Machines, and even Google have worked on creating human avatars that look real and work in areas like communication and training. The company noted that technically Worlds, Robotics, and Avatars are separate models, but eventually it plans to merge all these into one model. Besides releasing a new world model, the company is also updating its foundational Gen 4.5 model released earlier in the month. The new update brings native audio and long-form, multi-shot generation capabilities to the model. The company said that with this model, users can generate one-minute videos with character consistency, native dialogue, background audio, and complex shots from various angles. The company said that you can also edit existing audio and add dialogues. Plus, you can edit multi-shot videos of any length. The Gen 4.5 update nudges Runway closer to competitor Kling’s all-in-one video suite, which also launched earlier this month, particularly around native audio and multi-shot storytelling. It also signals that video generation models are moving from prototype to production-ready tools. Runway’s updated Gen 4.5 model is available to all paid plan users. The company said that it will make GWM-Robotics available through an SDK. It added that it is in active conversation with several robotics firms and enterprises for the use of GWM-Robotics and GWM-Avatars."
Disney signs deal with OpenAI to allow Sora to generate AI videos featuring its characters,https://techcrunch.com/2025/12/11/disney-signs-deal-with-openai-to-allow-sora-to-generate-ai-videos-featuring-its-characters/,"The Walt Disney Company announced on Thursday that it has signed a three-year partnership with OpenAI that will bring its iconic characters to the company’s Sora AI video generator. Disney is also making a $1 billion equity investment in OpenAI. Disney CEO Bob Iger told CNBC that the deal comes with about a year of exclusivity. After the year is up, Disney can license its IP to other AI companies. Launched in September, Sora allows users to create short videos using simple prompts. With this new agreement, users will be able to draw on more than 200 animated, masked, and creature characters from Disney, Marvel, Pixar, and Star Wars, including costumes, props, vehicles, and more. These characters include iconic faces like Mickey Mouse, Ariel, Belle, Cinderella, Baymax, and Simba, as well as characters from Encanto, Frozen, Inside Out, Moana, Monsters, Inc., Toy Story, Up, and Zootopia. Users will also be able to draw on animated or illustrated versions of Marvel and Lucasfilm characters like Black Panther, Captain America, Deadpool, Groot, Iron Man, Darth Vader, Han Solo, Stormtroopers, and more. Users will also be able to draw on these characters while using ChatGPT Images, the feature in ChatGPT that allows users to create visuals using text prompts. The agreement does not include any talent likenesses or voices, Disney says. “The rapid advancement of artificial intelligence marks an important moment for our industry, and through this collaboration with OpenAI we will thoughtfully and responsibly extend the reach of our storytelling through generative AI, while respecting and protecting creators and their works,” said Disney CEO Bob Iger in a statement. Disney says that alongside the agreement, it will “become a major customer of OpenAI,” as it will use its APIs to build new products, tools, and experiences, including for Disney+. “Disney is the global gold standard for storytelling, and we’re excited to partner to allow Sora and ChatGPT Images to expand the way people create and experience great content,” said Sam Altman, co-founder and CEO of OpenAI, in a statement. “This agreement shows how AI companies and creative leaders can work together responsibly to promote innovation that benefits society, respect the importance of creativity, and help works reach vast new audiences.” It’s worth noting that Disney has sued the generative AI platform Midjourney for ignoring requests to stop violating its intellectual property rights. Disney also sent a cease-and-desist letter to Character.AI, urging the chatbot company to remove Disney characters from among the millions of AI companions on its platform. Disney’s agreement with OpenAI indicates the company isn’t fully closing the door on AI platforms."
TIME names ‘Architects of AI’ its Person of the Year,https://techcrunch.com/2025/12/11/time-names-architects-of-ai-its-person-of-the-year/,"Each December, TIME Magazine names a person of the year — someone who has most influenced the news and world, for good or ill. Last year, TIME chose President Donald Trump for the second time. The year before that, it was Taylor Swift, who many claimed saved the economy from a recession with her Eras Tour. In 1938, the magazine chose Adolf Hitler.  This year, TIME has chosen to bestow its award on not just one person, but a group of people: the so-called “Architects of AI,” comprising the CEOs shaping the global AI race from the U.S. With AI on everyone’s minds, embodying hope for a small minority and economic anxiety for a majority, per recent Edelman data, this tracks. “For decades, humankind steeled itself for the rise of thinking machines,” the article reads. “Leaders striving to develop the technology, including Sam Altman and Elon Musk, warned that the pursuit of its powers could create unforeseen catastrophe […] This year, the debate about how to wield AI responsibly gave way to a sprint to deploy it as fast as possible.” Based on one of TIME’s two cover photos, some of those people appear to be Nvidia’s Jensen Huang, Tesla’s Elon Musk, OpenAI’s Sam Altman, Meta’s Mark Zuckerberg, AMD’s Lisa Su, Anthropic’s Dario Amodei, Google DeepMind’s Demis Hassabis, and World Labs’ Fei-Fei Li — all individuals who raced “both beside and against each other.”  TIME writes that these individuals, through their multibillion-dollar bets on “one of the biggest physical infrastructure projects of all time,” have reshaped government policy, turned up the heat on geopolitical competition, and pushed AI adoption forward.  This is the story of how AI changed our world in 2025, in new and exciting and sometimes frightening ways. It is the story of how Huang and other tech titans grabbed the wheel of history, developing technology and making decisions that are reshaping the information landscape, the climate, and our livelihoods… AI emerged as arguably the most consequential tool in great-power competition since the advent of nuclear weapons. TIME only announced the news on Thursday morning, but images of the cover photo were leaked on prediction market Polymarket on Wednesday evening. BREAKING: TIME Person of the Year reportedly leaked. pic.twitter.com/oe3okxsXoZ"
Opera wants you to pay $20 a month to use its AI-powered browser Neon,https://techcrunch.com/2025/12/11/opera-wants-you-to-pay-20-a-month-to-use-its-ai-powered-browser-neon/,"Following a couple of months’ testing, Norway-based browser company Opera has finally made its AI-powered browser, Neon, available to the public — though you’ll have to shell out $19.90 per month to use it. Opera first unveiled Neon earlier this year in May and launched it in early access to select users in October. Similar to other AI-first browsers like Perplexity’s Comet, OpenAI’s Atlas, and The Browser Company’s Dia, Neon bakes in an AI chatbot into its interface, letting you ask it answers about pages, use it to create mini apps and videos, and get it to do tasks for you. The browser uses your browsing history as context, so you can do things like ask it to fetch details from a YouTube video you watched last week or the post that you read yesterday. You can also build “Cards” for repeatable tasks using prompts, and the browser offers a deep research agent that can get you detailed information about any topic. The browser also has a new tab organizational feature called Tasks, which are contained workspaces of AI chats and tabs. This feature is more like Tab Groups combined with Arc Browser’s Spaces feature, which has its own context for AI. In addition to the AI features, the subscription gives users access to top models like Gemini 3 Pro, GPT-5.1, Veo 3.1, and Nano Banana Pro. Subscribers will also get access to Opera’s Discord community and direct access to its developers. “Opera Neon is a product for people who like to be the first to the newest AI tech. It’s a rapidly evolving project with significant updates released every week. We’ve been shaping it with our Founders community for a while and are now excited to share the early access to it with a larger audience,” Krystian Kolondra, EVP of browsers at Opera, said in a statement. The company noted that its other products, like Opera One, Opera GX, and Opera Air, also have free AI features, like a chat-based assistant. Meanwhile, browser incumbents are taking a slower approach to adding AI features to their products. Earlier this week, Google detailed the security work it is doing to protect users against different attack surfaces that agentic features are prone to, and Brave said on Wednesday it is previewing its agentic features in a nightly build, and provides an isolated browsing profile for using AI features so users can keep their regular, non-AI usage separate."
Interest in Spoor’s bird-monitoring AI software is soaring,https://techcrunch.com/2025/12/11/interest-in-spoors-bird-monitoring-ai-software-is-soaring/,"Spoor launched in 2021 with the goal of using computer vision to help reduce the impact of wind turbines on local bird populations. Now the startup has proven its technology works and is seeing demand from wind farms and beyond. Oslo, Norway-based Spoor has built software that uses computer vision to track and identify bird populations and migration patterns. The software can detect birds within a 2.5-kilometer radius (about 1.5 miles) and can work with any off-the-shelf high-resolution camera. Wind farm operators can use this information to better plan where wind farms should be located and to help them better navigate migration patterns. For example, a wind farm could slow down its turbines, or even stop them entirely, during heavy periods of local migration. Ask Helseth (pictured above left), the co-founder and CEO of Spoor, told TechCrunch last year that he got interested in this space after learning that wind farms lacked effective tracking methods, despite many countries having strict rules around where wind farms can be built and how they can operate due to local bird populations. “The expectations from the regulators are growing but the industry doesn’t have a great tool,” Helseth said at the time. “A lot of people [go out] in the field with binoculars and trained dogs to find out how many birds are colliding with the turbines.” Helseth told TechCrunch last week that since then, the company has proven the need for this technology and worked to make it better. At the time of its seed raise in 2024, Spoor was able to track birds in a 1-kilometer range, which has since doubled. As the company has collected more data to feed into its AI model, it has been able to improve its bird identification accuracy to about 96%. “Identifying the species of the bird for some of the clients, you add another layer,” Helseth said. “Is it a bird or not a bird? We have an in-house ornithologist to help train the model to train the new types of birds or a new type of species. Having deployment in other countries [means] having rare species in the database.” Spoor now works across three continents and with more than 20 of the world’s largest energy companies. It has also started to see interest from other industries such as airports and aquaculture farms. Spoor has a partnership with Rio Tinto, a London-based mining giant, to track bats. The company has also received interest in using its tech to track other objects of similar size — but Helseth said they aren’t thinking of pivoting into those areas quite yet. “Drones are of course a plastic bird in our mind,” Helseth joked. “They move in a different way and have a different shape and size. Currently we are discarding that data but we are getting interest in it.” Spoor recently raised an €8 million ($9.3 million) Series A round led by SET Ventures with participation from Ørsted Ventures, EnBW New Ventures, and Superorganism in addition to strategic investors. Helseth predicts that interest in this type of technology will only grow as regulators continue to crack down on wind farms. For example, French regulators shut down a wind farm in April due to its impact on the local bird population and imposed hundreds of millions of fines. “Our mission is to enable industry and nature to coexist,” Helseth said. “We have started on that journey, but we are still a small startup with a lot to prove. In the coming years, we want to really cement our position in the wind industry and become a global leader to tackle these challenges. At the same time, we want to build some proof points that this technology has value beyond that main category.”"
Port raises $100M at $800M valuation to take on Spotify’s Backstage,https://techcrunch.com/2025/12/11/port-raises-100m-at-800m-valuation-to-take-on-spotifys-backstage/,"Spotify may be synonymous with music streaming, but it’s also got a wildly popular developer-tool side hustle called Backstage.   Backstage is an open source project that helps companies build their own internal developer portals: a catalog of their developer tools along with quick visualizations of the work the tools have done, and other metrics. But like many open source projects, Backstage is a build-it-yourself option.   Israeli startup Port has been gaining big-name customers like GitHub, British Telecom, and LG with a proprietary Backstage competitor: a dev tool portal that’s also now been geared to manage AI agents.   On Thursday, Port, founded in 2022, said it raised a fresh $100 million Series C round led by General Atlantic, with participation from Accel, Bessemer Venture Partners, and Team8. The round values Port at $800 million and brings its total funding to date to $158 million. This Series C follows the company’s $35 million Series B led by Accel and Bessemer, announced in May.  Of all the industries that LLM-based tech has infiltrated, coding is where it has the deepest roots. So, not surprisingly, developers are also on the cutting edge of building and adopting agents that can automate entire repeated processes — work far beyond asking AI to write some code.  But the problem here, according to Port co-founder and CEO Zohar Einy, it’s the Wild West right now for such dev tool agents at companies: finding them, sharing them, ensuring their work follows company standards, and so on. Developers “want to take AI beyond just coding. They want it to resolve incidents, resolve security issues. They want it to take care of the release management,” Einy told TechCrunch.  But if agents are connected to all kinds of different tools and data sources, if the data is scattered among them, if they have no way to collaborate, and have no corporate standards and guardrails, “it creates chaos,” his product pitch goes.  Port therefore offers more than just a catalog of dev and agent tools (although it does offer those). It supplies a layer of orchestration with features that measure agent performance and add a human in the loop, as desired, to approval processes.   A feature called “context lake” defines the data sources, context memory, and guardrails for agents. “It’s where you manage what agents ‘need to know’ to do their job safely and correctly,” Einy explained.  In addition to using Port to catalog agents devs have already created using other tools, they can use Port to create new agents. Plus, Port also offers a few of its own ready-made agents, which can do things like resolving help desk tickets and dealing with provisioning.  Einy describes his product as handling the other 90% of what software programmers do that isn’t writing code. “It gives the engineers a user interface to control the agent, to iterate with the agent, to approve what it does that is not coding, that is all the 90%.”  With its giant new war chest of cash, big name customers and tier-one VCs, Port looks like an agentic management startup to watch. But to say it faces competition is an understatement. The entire category of agentic management and orchestration is flooded with hopefuls, from Big Tech companies to startups, and they’re all coming at the various new problems in the space from different angles. A few of these include LangChain, UiPath, Cortex, and more.  "
Harness hits $5.5B valuation with $240M raise to automate AI’s ‘after-code’ gap,https://techcrunch.com/2025/12/11/harness-hits-5-5b-valuation-with-240m-to-automate-ais-after-code-gap/,"AI DevOps tool Harness, founded in 2017 by serial entrepreneur Jyoti Bansal, is on track to exceed $250 million in annual recurring revenue in 2025, Bansal tells TechCrunch. The startup just raised a fresh $240 million Series E funding round that values the company at $5.5 billion post-money. The round includes a $200 million primary investment led by Goldman Sachs and a planned $40 million tender offer with participation from IVP, Menlo Ventures, and Unusual Ventures. The tender offer is intended to provide some liquidity to its long-term employees, Bansal said. The new valuation is a 49% jump from its $3.7 billion valuation in a $230 million round in April 2022. With this funding, the startup has raised $570 million of equity to date. As AI accelerates code production, it is widening a bottleneck in the far larger “after-code” phase of software development — the testing, security checks, and deployment work that still consumes nearly 70% of engineering time. Harness’s tools help automate this sprawling, error-prone layer, even as enterprises grapple with rising AI code volume and the risks of shipping even a single line of faulty software into production systems. Bansal is well known among developers for building and selling app performance company AppDynamics to Cisco for $3.7 billion in 2017. So the post-coding world is an area Bansal knows well. Harness uses AI agents to automate functions like testing, verification, security, and governance. It is built on a software delivery knowledge graph that maps code changes, services, deployments, tests, environments, incidents, policies, and costs. The knowledge graph helps differentiate Harness from other AI platforms, Bansal said, because it gives the system a deep understanding of each customer’s software delivery processes and architecture. “This knowledge graph is the context that our AI agents use,” he told TechCrunch. The purpose-built agents draw on that context to generate pipelines that match each customer’s specific policies, architecture, and operational requirements. Harness also uses an orchestration engine that turns the AI’s recommendations into automated actions, with checks in place to make sure those changes are applied safely. As AI is not foolproof, Bansal said the system is designed with human oversight, noting that AI-generated tests or fixes are reviewed by engineers, compliance teams, or auditors before being put into use. Microsoft’s GitHub, GitLab, Jenkins, and CloudBees are among the key competitors for Harness. But Harness has plenty of traction, claiming more than 1,000 enterprise customers, including United Airlines, Morningstar, Keller Williams, and National Australia Bank. So far, the startup has handled 128 million deployments, 81 million builds, protected 1.2 trillion API calls, and helped customers optimize $1.9 billion in cloud spending over the past year, Bansal touts. The San Francisco–based company employs over 1,200 people across 14 offices worldwide, including in Europe and the U.K. Around 33% of its workforce is in India, where it has a large engineering team in Bengaluru and a corporate office in Gurugram. Moreover, the Bengaluru site is Harness’s biggest development center outside the U.S. Harness plans to use the new funding to expand its R&D efforts, hire “hundreds of engineers” at its Bengaluru office, and build out additional automated testing, deployment, and security capabilities while improving the accuracy of its AI systems. The company also intends to strengthen its U.S. go-to-market operations and significantly expand its presence in international markets. It should also be noted that earlier this year, Bansal merged his software observability firm Traceable with Harness, and that move has helped the startup grow its ARR projection. “We brought the two companies together because we started to see that DevOps and application security are coming together in a very, very deep way,” said Bansal. “We have seen that turned out to be a very, very successful thesis this year … that’s driving a lot of growth for both of our DevOps and application security set of products.” While this raise has allowed some employees to cash out a bit,  Bansal still plans on taking Harness public one day, he said, though he did not share a specific timeline. “That’s what our goals and plans depend on,” he said of an eventual IPO. “Our business is very, very healthy, very strong, high growth and margins, and it will be a great public company when the timing is right.”"
Baby delivered in Waymo continues proud tradition of not making it to the hospital,https://techcrunch.com/2025/12/10/baby-delivered-in-waymo-continues-proud-tradition-of-not-making-it-to-the-hospital/,"A pregnant woman in San Francisco gave birth inside a Waymo robotaxi Monday night en route to UCSF Medical Center, marking the latest milestone in the driverless car saga that no one saw coming — except everyone with more than six months of experience behind the wheel of a ride-share vehicle. According to The SF Standard, Waymo’s remote team detected “unusual activity” and called 911, though the vehicle beat emergency services to the hospital. Some traditions, it seems, are immune to disruption. For decades, expectant mothers have been racing against biology in the back seats of taxis and Ubers from London to Los Angeles. There was the mother in India who named her son Uber after giving birth to him en route to the hospital (the driver reportedly helped in the delivery). There was also the California couple in 2017 who welcomed their baby in an Uber during Shabbat. “Everyone is telling us to name the baby Uber,” the father joked, before adding, “But we can’t do that.” (Ah, though, they could have!) The stories go on and on. Now, Silicon Valley has automated the experience, at least partially. The vehicle in San Francisco was promptly removed for cleaning. Further, this wasn’t Waymo’s first birth — the company told the Standard that a Phoenix baby got there first. “While this is a very rare occurrence,” a Waymo spokesperson deadpanned, “some of our newest riders just can’t wait to experience their first Waymo ride.”"
Google’s answer to the AI arms race — promote the guy behind its data center tech,https://techcrunch.com/2025/12/10/googles-answer-to-the-ai-arms-race-promote-the-guy-behind-its-data-center-tech/,"Google just made a major move in the AI infrastructure arms race, elevating Amin Vahdat to chief technologist for AI infrastructure, a newly created position reporting directly to CEO Sundar Pichai, according to a memo first reported by Semafor and later confirmed by TechCrunch. It’s a signal of just how critical this work has become as Google pours up to $93 billion into capital expenditures by the end of 2025 — a number that parent company Alphabet expects will be a whole lot bigger next year. Vahdat isn’t new to the game. The computer scientist, who holds a PhD from UC Berkeley and started as a research intern at Xerox PARC back in the early ’90s, has been quietly building Google’s AI backbone for the past 15 years. Before joining Google in 2010 as an engineering fellow and VP, he was an associate professor at Duke University and later a professor and SAIC Chair at UC San Diego. His academic credentials are formidable — with what appears to be around 395 published papers — and his research has always focused on making computers work more efficiently at massive scale. Vahdat already maintains a high profile with Google. Just eight months ago, at Google Cloud Next, he took the stage to unveil the company’s seventh-generation TPU, called Ironwood, in his role as VP and GM of ML, Systems, and Cloud AI. The specs he rattled off at the event were staggering, too: over 9,000 chips per pod delivering 42.5 exaflops of compute — more than 24 times the power of the world’s No. 1 supercomputer at the time, he said. “Demand for AI compute has increased by a factor of 100 million in just eight years,” he told the audience. Behind the scenes, as noted by Semafor, Vahdat has been orchestrating the unglamorous and essential work that keeps Google competitive, including those custom TPU chips for AI training and inference that give Google an edge over rivals like OpenAI, as well as the Jupiter network, the super-fast internal network that allows all its servers to talk to each other and move massive amounts of data around. (In a blog post late last year, Vahdat said that Jupiter now scales to 13 petabits per second, explaining that’s enough bandwidth to theoretically support a video call for all 8 billion people on Earth simultaneously.) Vahdat has also been deeply involved in the ongoing development of the Borg software system, Google’s cluster management system that acts as the brain coordinating all the work happening across its data centers. And he has said he oversaw the development of Axion, Google’s first custom Arm-based general-purpose CPUs designed for data centers, which the company unveiled last year and continues to build. In short, Vahdat is central to Google’s AI story. Indeed, in a market where top AI talent commands astronomical compensation and constant recruitment, Google’s decision to elevate Vahdat to the C-suite may also be about retention. When you’ve spent 15 years building someone into a linchpin of your AI strategy, you make sure they stay."
"State attorneys general warn Microsoft, OpenAI, Google, and other AI giants to fix ‘delusional’ outputs",https://techcrunch.com/2025/12/10/state-attorneys-general-warn-microsoft-openai-google-and-other-ai-giants-to-fix-delusional-outputs/,"After a string of disturbing mental health incidents involving AI chatbots, a group of state attorneys general have sent a letter to the AI industry’s top companies, with a warning to fix “delusional outputs” or risk being in breach of state law.  The letter, signed by dozens of AGs from U.S. states and territories with the National Association of Attorneys General, asks the companies, including Microsoft, OpenAI, Google, and 10 other major AI firms, to implement a variety of new internal safeguards to protect their users. Anthropic, Apple, Chai AI, Character Technologies, Luka, Meta, Nomi AI, Perplexity AI, Replika, and xAI were also included in the letter. The letter comes as a fight over AI regulations has been brewing between state and federal government. Those safeguards include transparent third-party audits of large language models that look for signs of delusional or sycophantic ideations, as well as new incident reporting procedures designed to notify users when chatbots produce psychologically harmful outputs. Those third parties, which could include academic and civil society groups, should be allowed to “evaluate systems pre-release without retaliation and to publish their findings without prior approval from the company,” the letter states. “GenAI has the potential to change how the world works in a positive way. But it also has caused—and has the potential to cause—serious harm, especially to vulnerable populations,” the letter states, pointing to a number of well-publicized incidents over the past year — including suicides and murder — in which violence has been linked to excessive AI use, the letter states. “In many of these incidents, the GenAI products generated sycophantic and delusional outputs that either encouraged users’ delusions or assured users that they were not delusional.” AGs also suggest companies treat mental health incidents the same way tech companies handle cybersecurity incidents — with clear and transparent incident reporting policies and procedures. Companies should develop and publish “detection and response timelines for sycophantic and delusional outputs,” the letter states. In a similar fashion to how data breaches are currently handled, companies should also “promptly, clearly, and directly notify users if they were exposed to potentially harmful sycophantic or delusional outputs,” the letter says.  Another ask is that the companies develop “reasonable and appropriate safety tests” on GenAI models to “ensure the models do not produce potentially harmful sycophantic and delusional outputs.” These tests should be conducted before the models are ever offered to the public, it adds.   TechCrunch was unable to reach Google, Microsoft, or OpenAI for comment prior to publication. The article will be updated if the companies respond. Tech companies developing AI have had a much warmer reception at the federal level. The Trump administration has made it known it is unabashedly pro-AI, and, over the past year, multiple attempts have been made to pass a nationwide moratorium on state-level AI regulations. So far, those attempts have failed — thanks, in part, to pressure from state officials. Not to be deterred, Trump announced Monday he plans to pass an executive order next week that will limit the ability of states to regulate AI. The president said in a post on Truth Social he hoped his EO would stop AI from being “DESTROYED IN ITS INFANCY.” "
Nvidia is reportedly testing tracking software as chip-smuggling rumors swirl,https://techcrunch.com/2025/12/10/nvidia-is-reportedly-testing-tracking-software-as-chip-smuggling-rumors-swirl/,"Nvidia is allegedly testing software that can track the location of its AI chips as reports of its chips being smuggled into China are on the rise. Nvidia has built location verification technology that would allow it to track which country a chip is located in, Reuters originally reported, citing anonymous sources. This software tracks computing performance but the delay in communication between servers also offers a sense of a chip’s location. This software will be optional for customers to use and will be made available for Blackwell chips first, Reuters said. Multiple reports have surfaced in the last few days that allege China’s DeepSeek AI models have been trained on smuggled Nvidia Blackwell chips. Nvidia responded to these reports by saying it hasn’t seen evidence of this type of smuggling. “We haven’t seen any substantiation or received tips of ‘phantom data centers’ constructed to deceive us and our OEM partners, then deconstructed, smuggled, and reconstructed somewhere else. While such smuggling seems far-fetched, we pursue any tip we receive,” an Nvidia spokesperson told TechCrunch. This news comes just days after Nvidia got the green light from the U.S. government to start selling its H200 AI chips to approved customers in China on Monday. That announcement pertains only to older H200 chips and not the company’s Blackwell chips."
"Spotify tests more personalized, AI-powered ‘Prompted Playlists’",https://techcrunch.com/2025/12/10/spotify-tests-more-personalized-ai-powered-prompted-playlists/,"Spotify announced on Wednesday that, for the first time, it’s giving users more control over the streaming service’s algorithm. That’s at least how the company is framing the launch of its new “Promoted Playlists,” a feature that will initially be available to Premium subscribers in New Zealand. The feature, which is currently available in English only, is still in beta and will evolve before rolling out to other markets, according to Spotify. The new tool allows users to describe what they want to hear in a personalized playlist that reflects the “full arc” of their tastes, according to the company. That means the playlist focuses not only on the songs you like now, but your entire Spotify listening history from day one — something that differentiates the feature from other playlists, the company says. The feature is an evolution from Spotify’s existing AI playlist option, which debuted last year, and also works through written prompts. As with AI playlists, the new Prompted Playlists allow users to request what they want to hear with written instructions. However, they can now write much longer prompts with more specific instructions. That’s because the new AI feature factors in world knowledge, a rep from Spotify explained to TechCrunch. In addition, the ability to go further back in your listening history and schedule how often the playlist refreshes makes it different from Spotify’s other AI playlist offerings. For instance, Spotify suggests subscribers can use the new feature to ask for something like, “music from my top artists from the last five years,” then amend the prompt to include a request for “deep cuts I haven’t heard yet.” In another example of a longer prompt, Spotify said you could ask for “high-energy pop and hip-hop for a 30-minute 5K run that keeps a steady pace before easing into relaxing songs for a cool-down” or “music from this year’s biggest films and most-talked-about TV shows that match my taste.” In addition, you can continue to fine-tune the prompt to make it even more specific, and can set how often you want it to refresh, like daily or weekly. The idea is that users can essentially make their own version of something like Spotify’s flagship playlist, Discover Weekly, but one that’s focused on a type of music, genre, or time period they’d like to track, or their own version of something like Spotify’s genre-focused Daily Mixes. The company says the playlist will include descriptions and context so you know why you’re getting the recommendation. Plus, it will offer a set of prompts to help users get started. Spotify isn’t the only social app pitching how it’s letting users take control of its algorithm. Instagram today also introduced a new feature that lets users control what type of reels they see. Bluesky, a decentralized X competitor, also lets users swap out its algorithm for one of their own."
Google is testing AI-powered article overviews on select publications’ Google News pages,https://techcrunch.com/2025/12/10/google-is-testing-ai-powered-article-overviews-on-select-publications-google-news-pages/,"Google is testing AI-powered article overviews on participating publications’ Google News pages as part of a new pilot program, the search giant announced on Wednesday. News publishers participating in the pilot program include Der Spiegel, El País, Folha, Infobae, Kompas, The Guardian, The Times of India, The Washington Examiner, and The Washington Post, among others. The purpose of the new commercial partnership program is to “explore how AI can drive more engaged audiences,” Google said in a blog post. As part of the new AI pilot program, the company will work with publishers to experiment with new features in Google News. By adding AI-powered article overviews, Google says users will get more context before they click through to read an article. While AI-generated summaries may lead to fewer clicks on news articles, publications participating in the commercial pilot program will receive direct payments from Google, which could make up for the potential decrease in traffic to their sites. The AI-powered article overviews will only appear on participating publications’ Google News pages, and not anywhere else on Google News or in Search. This isn’t the first time that Google has introduced AI summaries for news. In July, the company rolled out AI summaries in Discover, the main news feed inside Google’s search app. With this change, users no longer see a single headline from a major publication in the feed. Instead, they see the logos of multiple news publishers in the top-left corner, followed by an AI-generated summary that cites those sources. Google is also experimenting with audio briefings for people who prefer listening to the news rather than reading it, as part of the new pilot program. The company says these features will include clear attribution and a link to articles. Additionally, Google is partnering with organizations such as Estadão, Antara, Yonhap, and The Associated Press to incorporate real-time information and enhance results in the Gemini app. “As the way people consume information evolves, we’ll continue to improve our products for people around the world and engage with feedback from stakeholders across the ecosystem,” Google wrote in its blog post. “We’re doing this work in collaboration with websites and creators of all sizes, from major news publishers to new and emerging voices.” As part of Google’s Wednesday announcement, the company said that it’s launching its “Preferred Sources” feature globally after first launching it in the U.S. and India in August. The feature allows users to select their favorite news sites and blogs to appear in the Top Stories section of Google search results. In the coming days, the feature will be available for English-language users worldwide, and Google plans to roll it out to all supported languages early next year. Google will now also highlight links from your news subscriptions and show these links in a dedicated carousel in the Gemini app in the coming weeks, with AI Overviews and AI Mode to follow. While these features make it easy for users to access news from their preferred sources, they also risk confining them to an ideological bubble that limits their exposure to different perspectives. Google also announced that it’s increasing the number of inline links in AI Mode. Additionally, it’s introducing “contextual introductions” for embedded links, which are brief explanations that explain why a link could be useful to explore."
ElevenLabs just hit a $6.6B valuation. Its CEO says the real money isn’t in voice anymore.,https://techcrunch.com/podcast/elevenlabs-just-hit-a-6-6b-valuation-its-ceo-says-the-real-money-isnt-in-voice-anymore/,"ElevenLabs has made a name for itself building realistic AI voices.   What started as two Polish engineers annoyed by terrible movie dubbing has grown into a profitable company now valued at $6.6 billion, doubling from just nine months ago. The company recently announced a $100 million tender offer led by Sequoia and ICONIQ, with participation from a16z and others, as its tech powers everything from Fortnite characters to customer service bots and goes toe-to-toe with OpenAI to become the default voice of AI.  Today on TechCrunch’s Equity podcast, we’re bringing you a conversation with CEO Mati Staniszewski from this year’s Disrupt, where he made a surprising admission: He thinks voice models will be commoditized in just a couple of years. So what’s ElevenLabs’ plan when everyone else catches up?  Listen to the full episode to hear about:   Subscribe to Equity on Apple Podcasts, Overcast, Spotify and all the casts. You also can follow Equity on X and Threads, at @EquityPod. "
ChatGPT is Apple’s most downloaded app of 2025 in the US,https://techcrunch.com/2025/12/10/chatgpt-is-apples-most-downloaded-app-of-2025-in-the-us/,"Apple on Wednesday released its annual list of the most downloaded apps and games for the year. For the U.S. market, OpenAI’s ChatGPT topped the ranks of free iPhone apps (not including games) with the most installs in 2025. The AI app was followed by Threads, Google, TikTok, WhatsApp, Instagram, YouTube, Google Maps, Gmail, and Google’s Gemini. ChatGPT made it to No. 4 last year, but the top spot was taken by Chinese shopping app Temu. In 2023, the AI app didn’t make the top-10 list despite being released on the iPhone in May 2023 to a strong debut. The fact that ChatGPT is outpacing social networking standbys, and much-needed utilities like Google Maps, indicates how deeply AI has penetrated people’s everyday lives here in the U.S. It also demonstrates the potential for OpenAI to disrupt Google’s tight hold on the search market on mobile devices, as more people turn to a chatbot for answers first. There were signs that ChatGPT was on its way to No. 1 earlier in the year — it became the most-downloaded app globally in March, outpacing other top apps like TikTok and Instagram. Apple also released its list of the top paid apps, the top free and paid games for iPhone and iPad, as well as the top Apple Arcade games. Block Blast! was the top free game this year, while Minecraft took the crown as the top paid game. On iPad, YouTube was the No. 1 free app, and users downloaded the creativity app Procreate as the top paid game on iPad. Roblox was the top free iPad game. The full list of top apps and games is below:"
Google launches managed MCP servers that let AI agents simply plug into its tools,https://techcrunch.com/2025/12/10/google-is-going-all-in-on-mcp-servers-agent-ready-by-design/,"AI agents are being sold as the solution for planning trips, answering business questions, and solving problems of all kinds, but getting them to work with tools and data outside their chat interfaces has been tricky. Developers have to patch together various connectors and keep them running, but that’s a fragile approach that’s hard to scale and creates governance headaches. Google claims it’s trying to solve that by launching its own fully managed, remote MCP servers that would make its Google and Cloud services — like Maps and BigQuery — easier for agents to plug into. The move follows the launch of Google’s latest Gemini 3 model, and the company is looking to pair stronger reasoning with more dependable connections to real-world tools and data. “We are making Google agent-ready by design,” Steren Giannini, product management director at Google Cloud, told TechCrunch.  Instead of spending a week or two setting up connectors, developers can now essentially paste in a URL to a managed endpoint, Giannini said. At launch, Google is starting with MCP servers for Maps, BigQuery, Compute Engine, and Kubernetes Engine. In practice, this might look like an analytics assistant querying BigQuery directly, or an ops agent interacting with infrastructure services.  In the case of Maps, Giannini said, without the MCP, developers would rely on the model’s built-in knowledge. “But by giving your agent […] a tool like the Google Maps MCP server, then it gets grounded on actual, up-to-date location information for places or trips planning,” he added. While the MCP servers will eventually be offered across all of Google’s tools, they are initially launching under public preview, meaning they’re not yet fully covered by Google Cloud terms of service. They are, however, being offered at no extra cost to enterprise customers that already pay for Google services.  “We expect to bring them to general availability very soon in the new year,” Giannini said, adding that he expects more MCP servers to trickle in every week. MCP, which stands for Model Context Protocol, was developed by Anthropic about a year ago as an open source standard to connect AI systems with data and tools. The protocol has been widely adopted across the agent tooling world, and Anthropic earlier this week donated MCP to a new Linux Foundation fund dedicated to open sourcing and standardizing AI agent infrastructure.  “The beauty of MCP is that, because it’s a standard, if Google provides a server, it can connect to any client,” Giannini said. “I’m looking forward to seeing how many more clients will emerge.” One can think of MCP clients as the AI apps on the other end of the wire that talk to MCP servers and call the tools they offer. For Google, that includes Gemini CLI and AI Studio. Giannini said he’s also tried it with Anthropic’s Claude and OpenAI’s ChatGPT as clients, and “they just work.” Google argues this isn’t just about connecting agents to its services. The bigger enterprise play is Apigee, its API management product, which many companies already use to issue API keys, set quotas, and monitor traffic.  Giannini said Apigee can essentially “translate” a standard API into an MCP server, turning endpoints like a product catalog API into tools an agent can discover and use, with existing security and governance controls layered on top.  In other words, the same API guardrails companies use for human-built apps could now apply to AI agents, too.  Google’s new MCP servers are protected by a permission mechanism called Google Cloud IAM, which explicitly protects what an agent can do with that server. They are also protected by Google Cloud Model Armor, which Giannini describes as a firewall dedicated to agentic workloads that defends against advanced agentic threats like prompt injection and data exfiltration. Administrators can also rely on audit logging for additional observability.  Google plans to expand MCP support beyond the initial set of servers. In the next few months, the company will roll out support for services across areas like storage, databases, logging and monitoring, and security. “We built the plumbing so that developers don’t have to,” Giannini said."
AI startup Tavus founder says users talk to its AI Santa ‘for hours’ per day,https://techcrunch.com/2025/12/10/ai-startup-tavus-founder-says-users-talk-to-its-ai-santa-for-hours-per-day/,"A new helper has arrived at the North Pole in recent years: AI. Tavus, the AI startup that creates digital replicas using voice and face cloning technology, has launched its AI Santa experience for the second year in a row. This allows parents and children to video chat with a virtual version of the jolly old Saint Nick. After signing up for a free account, users can interact with AI Santa via text, phone, or video chat. Users can tell AI Santa what they want for Christmas, share their holiday plans, and find out if they’re on the naughty or nice list.  This year, the company debuted an improved version of AI Santa, designed to be more expressive and emotionally aware. Santa is now a “Tavus PAL,” the company’s name for its real-time AI agents that are built to see, hear, respond, and appear human. AI Santa can now see users’ expressions and gestures and respond to them. It also remembers users’ conversations and interests, creating a more personalized experience. Notably, it now can take actions of its own, including searching the web for present ideas or even perform everyday tasks like drafting emails. During testing, the conversation with AI Santa was engaging for the most part. When we mentioned wanting a new PlayStation for Christmas, Santa followed up with questions about our favorite video games, showing knowledge of specific titles like Baldur’s Gate 3. It also smiled back when we did. (We didn’t like that part very much, but maybe others will.) Users appear to be enjoying the improved experience so far. Founder and CEO Hassaan Raza said that many people are engaging with the platform frequently, spending hours chatting with AI Santa and often reaching their daily limits. “Last year’s AI Santa drew millions of hits, and we’re on pace to surpass that by a wide margin as Christmas approaches,” he noted. While this level of engagement marks a milestone for Tavus, it also raises questions about the impact of such interactions, especially for young children. Children may struggle to distinguish between AI and a real person. Spending hours in conversation with an AI has already been linked to negative effects in adults, making the potential effects on children who strongly believe in Santa a concern for some parents. During our testing, there were subtle cues that the AI Santa does yet appear fully human-like, such as long pauses and a flat voice. We also found that if a user were to question whether it’s real, the programmed response was: “I’m an AI Santa powered by Tavus’ magic and technology. I might not be the physical Santa, but I’ve got the spirit and the cheer.” Still, the experience launches amid growing concerns about AI’s effects on young users. There have been reports linking chatbot interactions to serious harm, including cases where chatbots were implicated in the suicide deaths of teenagers. Character.AI removed access to its chatbots for users under 18 in October.  Raza emphasized that the AI Santa experience is designed for families to enjoy together, with safety measures in place to ensure appropriate interactions. Safety features, such as content filters, have been implemented to maintain family-friendly discussions.  In certain situations, conversations can be terminated, and users are directed to mental health resources if necessary.  “The vast majority of interactions have been family-friendly and true to the Santa experience,” he said.  Additionally, when asked about data collection, Raza said the company “collects logs, session timestamps, metadata, and other information users choose to share during their chats. This data is used to provide and maintain a safe experience, and users can request data deletion at any point in time.” "
Figma launches new AI-powered object removal and image extension,https://techcrunch.com/2025/12/10/figma-launches-new-ai-powered-object-removal-and-image-extension/,"Design tool Figma launched new AI-powered image-editing features today, including the ability to remove and isolate objects and expand images. The company said that these features will save the hassle of exporting images to other tools for editing and importing them back. It added that generation models like Nano Banana are good for creating images, but users often need granular tools for editing that work without any text prompts. Figma has improved its lasso tool for selection. Now you can use it to select an object, remove it, or isolate it to move it around. When you move around the object, the image still retains other characteristics, such as background and color. Users can also select an object to adjust factors like lighting, shadow, color, or focus. The company is also bringing an image-expansion feature to its design suite. This feature is handy when you are adjusting a creative for a particular format and need to fill in the background or other details. For instance, creating a web banner or mobile banner from a 1×1 image. It essentially saves you from constantly cropping an image and adjusting elements within it. Besides adding these features, Figma is collating all its image-editing tools in one toolbar for easier access. You can select objects or parts of images, change background color, and add annotations or text using this toolbar. The company said removing background is one of the most common actions on the platform, and that is why it is getting a prominent spot on the new toolbar. Rivals like Adobe and Canva have had object removal for a few years now. Figma is finally catching up to offer these features. The company said the new image-editing features are available on Figma Design and Draw, with plans to make them available across Figma tools next year. Figma’s launch comes on the same day as Adobe making some of these features available to users within ChatGPT. Figma was one of the launch partners of the app, calling on ChatGPT in October. It is not clear if these new functions will be available to users using Figma within OpenAI’s tool.  "
Google launches sub-$5 AI Plus plan in India to compete with ChatGPT Go,https://techcrunch.com/2025/12/10/google-launches-sub-5-ai-plus-plan-in-india-to-compete-with-chatgpt-go/,"Google on Wednesday launched its more affordable AI Plus plan in India as it seeks to compete on pricing with other low-cost AI offerings, like OpenAI’s ChatGPT Go subscription. For new users in India, Google is offering AI Plus for ₹199 ($2.21) per month, for the first six months, after which you’ll have to pay ₹399 ($4.44) a month. The AI Plus plan gives users higher limits for Gemini 3 Pro and image editing model Nano Banana Pro; access to video generation in the Gemini and Flow apps; expanded access to deep research in NotebookLM; and 200GB of storage across Photos, Drive, and Gmail. Subscribers can give access to up to five family members, too. Before this, Google’s cheapest AI subscription available in the country was AI Pro, which was priced at ₹1,950 per month ($21.69). But Google is late to customize its pricing for India, as the AI Plus plan was first introduced in Indonesia in September and offered it in other countries that same month. OpenAI debuted its sub-$5 ChatGPT Go plan in India in August and made it available in other countries in subsequent months. The plan allows users to have 10 times more limits than the free plan for messages, image generation, and file uploads. AI companies have been busy offering freebies in India as they seek to tap its huge population for users. First, Perplexity partnered with telco Airtel to offer its Pro plan for a year to all Airtel customers for free. OpenAI also offered ChatGPT Go free for a year to existing subscribers of Go and new users. Meanwhile, Google teamed up with telco Reliance Jio to offer its AI Pro plan for 18 months at no cost to users on a certain carrier plan. "
CoreWeave CEO defends AI circular deals as ‘working together’,https://techcrunch.com/2025/12/09/coreweave-ceo-defends-ai-circular-deals-as-working-together/,"It’s been quite the year for CoreWeave. In March, the AI cloud infrastructure provider went public in one of the biggest and most anticipated IPOs of the year that didn’t live up to its hype. Another setback took place in October, when a planned acquisition of the cloud provider’s business partner, Core Scientific, faltered due to skepticism from the acquisition target’s shareholders.  In the meantime, the firm has acquired a number of different companies, its stock has gone up and down, and it’s been both criticized and lauded for its role in the booming AI data center market.  In an interview at the Fortune Brainstorm AI summit in San Francisco on Tuesday, CoreWeave’s co-founder and CEO, Michael Intrator, defended his company’s performance from critics, noting that it was in the midst of creating a “new business model” for how cloud computing can be built and run. Their collection of Nvidia GPUs is so valuable, they borrow against it to help finance their business. The executive seemed to imply: If you’re charting a new path, you’re destined to encounter some road bumps along the way.   “I think people are myopic a lot of times,” Intrator said when questioned about his company’s occasionally unstable stock price. “Yes, it is seesawing,” he admitted, while noting that the CoreWeave IPO took place not long before President Trump’s tariffs went into effect — a notably uncertain moment for the overall economy.  “We came out into one of the most challenging environments, right around Liberation Day and, in spite of the incredible headwinds, were able to launch a successful IPO,” the CEO told Brainstorm editorial director Andrew Nusca. “I couldn’t be prouder of what the company has accomplished,” he added.  CoreWeave’s stock may have debuted amid the economic doldrums of March but its price has gone on quite the journey since then. It debuted at $40 and, over the past eight months, has climbed to well over $150, but currently rests at around $90. Its more wary critics have compared it to a meme stock due to its penchant for going up and down.  Some of the uncertainty around CoreWeave’s stock has been credited to the company’s hefty level of debt. Not long after CoreWeave announced a deal on Monday to issue even more debt to finance its data center buildout, its stock dropped some 8%. Intrator seems to see his company as a disruptor, one whose unconventional tactics may take some getting used to. “When you introduce a new model, when you introduce a new way of doing business, when you disrupt what has been a static environment, it’s going to take some people some time,” he said during his appearance Tuesday.  CoreWeave actually started its corporate life as a crypto miner but in short order built itself into a pivotal provider of “AI infrastructure” to some of the tech industry’s most major players. In that role, it provides GPUs to AI developers and has made major partnerships with Microsoft, OpenAI, Nvidia, Meta, and other tech titans.   Another topic broached Tuesday was the notion of “circularity” within the AI industry. “Circular” business deals, in which a small number of powerful AI companies invest in one another, have frequently been criticized and have raised questions about the industry’s long-term economic stability. Perhaps not surprisingly, since Nvidia is one of its investors and its supplier of GPUs, Intrator swatted away such concerns. “Companies are trying to address a violent change in supply and demand,” he said. “You do that by working together.” Since the IPO, CoreWeave has continued to make efforts to expand its business. After it acquired Weights & Biases, an AI developer platform, in March, it went on to acquire OpenPipe, a startup that helps companies create and deploy AI agents through reinforcement learning. In October, it also made deals to acquire Marimo (the creator of an open source notebook) and Monolith, another AI company. It also recently announced an expansion of its cloud partnership with OpenAI and said it has plans to move into the federal market, where it wants to provide cloud infrastructure to U.S. government agencies and the defense industrial base. "
Unconventional AI confirms its massive  $475M seed round,https://techcrunch.com/2025/12/09/unconventional-ai-confirms-its-massive-475m-seed-round/,"Naveen Rao, the former head of AI at Databricks, has raised $475 million in seed capital at a $4.5 billion valuation for his new startup, Unconventional AI. The round was led by Andreessen Horowitz and Lightspeed Ventures, with participation from Lux Capital and DCVC. The funding is a first installment toward the goal of up to $1 billion for the round, Rao told Bloomberg. TechCrunch was first to report, back in October, that Unconventional AI was seeking this mega funding for Rao’s new startup, although the final valuation is marginally lower than the $5 billion sources told us he was seeking. If he does eventually raise as much as $1 billion, we’ll see how that impacts his company’s value. Unconventional AI is set on building a new, energy-efficient computer for AI. Rao previously wrote on X that his goal is to create a computer that is “as efficient as biology.” Databricks acquired Rao’s previous startup, MosaicML in 2023, for $1.3 billion. Prior to MosaicML, Rao co-founded the machine learning platform Nervana Systems, which Intel Corp. acquired in 2016 for reportedly more than $400 million. "
Cashew Research is going after the $90B market research industry with AI,https://techcrunch.com/2025/12/09/cashew-research-is-going-after-the-90b-market-research-industry-with-ai/,"Market research is a $90 billion industry that helps brands figure out how to best present themselves to potential customers. But that market insight isn’t cheap, nor is it quick. Cashew Research wants to change that using AI. Calgary, Alberta-based Cashew uses AI to develop market research plans and surveys for brands based on what information they are looking for — like what their brand recognition is for a specific population or how a marketing tagline resonates with customers. Cashew then sends the survey to real people and uses AI to summarize and digest the findings. Cashew was one of the 200 startups chosen for TechCrunch’s Startup Battlefield competition in 2025 and won the Enterprise Stage pitch competition at TechCrunch Disrupt. “You can use an LLM to try to do deep research and get answers to your questions, or you could use a firm that’s going to be really expensive,” Addy Graves, co-founder and CEO of Cashew, told TechCrunch in describing the current market research industry. “Now there’s Cashew that exists in the middle. It creates custom, fresh data to answer your question instead of you just using an LLM that’s surfacing the same recycled pool of data that everybody’s finding on the internet.” Graves has more than a decade of market research experience. The original idea for Cashew was sparked by an issue she ran into frequently: Clients wanted full research projects — with real-world data from humans — done within a few days. For years, shortening that timeline while still producing the same quality of research results wasn’t possible, Graves said, because the technology to speed up the process wasn’t ready yet. “That was definitely the aha moment,” Graves said. “And it wasn’t until the onset of AI that we were actually able to automate these processes that we use as researchers, best practices, these data science-backed methodologies, as well as the formatting of reports that we know that everybody wants.” Bringing automation to the process also brings the cost down, which makes Cashew an option for small and medium-size brands that wouldn’t have been able to afford to work with a traditional market research firm, Graves added. Graves founded Cashew in 2023 alongside Rose Wong, chief operating officer, with an initial focus on consumer packaged goods, specifically food and beverage. Graves said she thinks Cashew can stand out in the increasingly crowded AI marketing tools category because it isn’t fully automated. Each Cashew client gets fresh human data with each project, which requires market research expertise, Graves said. Cashew’s competitive advantage may only grow as the company matures. The company takes all of the real-world data it collects from its clients’ projects, anonymizes it, and puts it in a database, which can help add additional proprietary data to future research projects, too. The company has raised C$1.5 million in pre-seed funding and is gearing up to launch its seed round in early 2026 with the hope of raising up to $5 million, Graves said. That capital will be put toward continuing to develop the product’s tech. Graves said the company’s two main areas of focus heading into next year are increasing the company’s presence in the U.S. and also working to build up its B2B business. “The people who are already buying research, that’s already a massive category, but that doesn’t even include all the people that could be buying research but just can’t afford it or can’t do it right now because they don’t have the timelines,” Graves said. “We’re actually creating this new category for marketers to gain access to answers to these questions that they’ve had.”"
Max Hodak is more worried about Twitter than brain-computer interface hacking,https://techcrunch.com/podcast/max-hodak-is-more-worried-about-twitter-than-brain-computer-interface-hacking/,"This week on StrictlyVC Download, Connie Loizos speaks with Science Corp. founder Max Hodak to discuss how brain-computer interfaces are arriving faster than anyone realizes. The Neuralink co-founder and former president shares how his company recently achieved what may be the biggest breakthrough in vision restoration in decades, enabling 80% of blind patients to read again with a tiny retinal implant smaller than a grain of rice. In this conversation, the two also explore the near-term commercial path for BCIs through medical applications, the long-term potential for cognitive enhancement, and “binding” multiple brains together, and why Science, which has so far raised $260 million from investors, is keen to generate revenue while it invests in its future products. Not last, Hodak addresses the practical and ethical questions around hacking, enhancement, and why he thinks it may well be possible in the not-too-distant future to “move consciousness” outside of the body. StrictlyVC Download posts every Tuesday. Subscribe on Apple, Spotify, or wherever you listen to podcasts to be alerted when new episodes drop."
B Capital founding partner Kabir Narang leaves to launch new investment platform,https://techcrunch.com/2025/12/09/b-capital-founding-partner-kabir-narang-leaves-to-launch-new-investment-platform/,"Kabir Narang, a founding general partner at B Capital and an early backer of several Indian startups, has left the global venture firm, TechCrunch has learned and confirmed with the company. Narang is laying the groundwork for a new investment platform slated for 2026 that will focus on “compounding at the intersection of technology, AI, and global capital flows,” per a note shared with founders and reviewed by TechCrunch. After joining B Capital in March 2017, Narang co-led the firm’s Asia strategy from Singapore and chaired its global investment committee. During his tenure, he backed Indian startups such as Meesho, Khatabook, CredAvenue, Bounce, and Bizongo. “We are living through one of the most profound technological revolutions in history, and one of the toughest tests of investor discipline,” Narang wrote. “AI scales thought itself, compressing the gap between idea and output. The founders who pair that speed with pricing power and improving unit economics will define the next generation of enduring value.” Alongside developing the new investment platform, Narang told founders that he is taking 1% to 2% personal stakes in companies he believes can “compound intelligently.” This suggests he plans to stay active in early-stage investing while setting up a broader vehicle. B Capital confirmed Narang’s exit to TechCrunch and noted that Eduardo Saverin, Karan Mohla, and Howard Morgan would manage its Asia portfolio alongside the existing team in South and Southeast Asia. “After more than eight years with the firm, Kabir Narang, who focused on later stage growth investing efforts in Asia, has left his role to pursue other opportunities,” a B Capital spokesperson said. “We are grateful for his contributions, and we wish him continued success in the future.” Founded in 2015 by Facebook co-founder Eduardo Saverin and former Bain Capital executive Raj Ganguly, B Capital is a multi-stage investor focused on technology, healthcare, and resilience tech. The San Francisco–based firm manages more than $9 billion across nine offices in the U.S. and Asia. Through a partnership with Boston Consulting Group, B Capital also provides portfolio companies with strategic and operational support. Before joining B Capital, Narang spent nearly nine years at Fidelity-backed Eight Roads Ventures India, where he was a managing director. “B Capital remains deeply committed to our strategy in Asia and our broader global platform,” the B Capital spokesperson said. “With strong leadership and an experienced team across the region, we are well-positioned to capitalize on the next wave of innovation and continue backing category-defining companies across our core markets.” Narang did not respond to a request for comment. "
